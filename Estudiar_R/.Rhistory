library(readxl)
library(dplyr)
library(caret) # para matriz de confusión
library(rpart) #Para realizar el árbol
library(rpart.plot) #Para dibujar el árbol
library(factoextra) # para clusteres
library(NbClust)
library(zoo) # para ts diario
library(forecast)
getwd()
#| include: false
getwd()
setwd("/Users/alejandrocamposlamas/Proyectos/ACTIVIDADES_UNIR/actividad-3-AnalisisDatos")
library(readxl)
library(dplyr)
library(caret) # para matriz de confusión
library(rpart) #Para realizar el árbol
library(rpart.plot) #Para dibujar el árbol
library(factoextra) # para clusteres
library(NbClust)
library(zoo) # para ts diario
library(forecast)
getwd()
datos <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "Var Discreta Adq Bicicleta")
# str(datos)
# unique(datos$Country)
#| include: false
# cargamos datos
datos <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "Var Discreta Adq Bicicleta")
# vemos la estructura y convertimos los datos a su formato adecuado
# str(datos)
#colSums(is.na(datos)) # verificamos que no existe ningun null
# datos[is.na(datos)] <- 0 # valores nulos se reemplazarían por 0
# Quitamos la columna PersonType dado que todos su valores son IN
datos <- datos%>% select(!PersonType)
#quitamos aquellas paises que son agrupaciones
datos <- datos %>%
filter(!(Country %in% c("Northwest", "Southeast", "Central", "Southwest", "Northeast")))
# a factores datos que son categorías
datos$Education <- as.factor(datos$Education)
datos$PersonID <- as.factor(datos$PersonID)
datos$CustomerID <- as.factor(datos$CustomerID)
# Los booleanos le creamos una columna condicional
#BikePurchase
#HomeOwnerFlag
datos <- datos %>%
mutate(
BikePurchase_f = factor(BikePurchase, labels=c("FALSE", "TRUE")),
HomeOwnerFlag_f = factor(HomeOwnerFlag, labels=c("FALSE", "TRUE"))
)
print(datos)
# describimos los estadísticos numéricos
datos %>% select(where(is.numeric)) %>% summary(use="complete.obs")
# observamos cómo se relacionan las variables
datos %>% select(where(is.numeric)) %>% cor(use="complete.obs")
#split: seleccionamos el monto de entrenamiento y lo guardamos en la variabble de train
indice <- sample(1:nrow(datos), size = 0.8 * nrow(datos))
# Train: entrenamos al modelo con el subset de testeo
train <- datos[indice, ]
# test: tomamos el monto a testar
test <- datos[-indice, ]
modelo_logit <- glm(BikePurchase ~   Country + MaritalStatus + HomeOwnerFlag_f + Education + YearlyIncome + Occupation, data = train, family = "binomial")
summary(modelo_logit)
# 1. Ajuste del modelo (Cambiamos 'family' por 'method')
modelo_arbol <- rpart(BikePurchase ~ Country + MaritalStatus + HomeOwnerFlag_f +
Education + YearlyIncome + Occupation,
data = train,
method = "class")
# 2. Visualización
rpart.plot(modelo_arbol,main = "Árbol de Decisión: Predicción de Bike Purchase",
type = 2,
extra = 104,
nn = TRUE)
pred_logit_prob <- predict(modelo_logit, newdata = test, type = "response")
# 1# 1. Convertimos tus probabilidades a clases (0 o 1) con el corte de 0.5
pred_clase <- ifelse(pred_logit_prob > 0.5, 1, 0)
# 2. Convertimos AMBOS a factor asegurando que tengan los mismos niveles
pred_factor <- factor(pred_clase, levels = c("0", "1"))
real_factor <- factor(test$BikePurchase, levels = c("0", "1"))
# 3. Magia: Generamos la matriz completa
confusionMatrix(data = pred_factor, reference = real_factor)
# 1. Pide la clase directamente (type = "class")
pred_clase_arbol <- predict(modelo_arbol, newdata = test, type = "class")
# 2. Aseguramos que sea factor y tenga los mismos niveles que la realidad
# Nota: predict con type="class" ya suele devolver factor, pero esto es doble seguridad
pred_factor_arbol <- factor(pred_clase_arbol, levels = c("0", "1"))
real_factor_arbol <- factor(test$BikePurchase, levels = c("0", "1"))
# 3. Matriz
confusionMatrix(data = pred_factor_arbol, reference = real_factor_arbol)
# Ver qué variables usó realmente el árbol y cuánto importaron
modelo_arbol$variable.importance
#| include: false
getwd()
setwd("/Users/alejandrocamposlamas/Proyectos/ACTIVIDADES_UNIR/actividad-3-AnalisisDatos")
library(readxl)
library(dplyr)
library(caret) # para matriz de confusión
library(rpart) #Para realizar el árbol
library(rpart.plot) #Para dibujar el árbol
library(factoextra) # para clusteres
library(NbClust)
library(zoo) # para ts diario
library(forecast)
getwd()
set.seed(123)
datos <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "Var Discreta Adq Bicicleta")
# str(datos)
# unique(datos$Country)
#| include: false
# cargamos datos
datos <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "Var Discreta Adq Bicicleta")
# vemos la estructura y convertimos los datos a su formato adecuado
# str(datos)
#colSums(is.na(datos)) # verificamos que no existe ningun null
# datos[is.na(datos)] <- 0 # valores nulos se reemplazarían por 0
# Quitamos la columna PersonType dado que todos su valores son IN
datos <- datos%>% select(!PersonType)
#quitamos aquellas paises que son agrupaciones
datos <- datos %>%
filter(!(Country %in% c("Northwest", "Southeast", "Central", "Southwest", "Northeast")))
# a factores datos que son categorías
datos$Education <- as.factor(datos$Education)
datos$PersonID <- as.factor(datos$PersonID)
datos$CustomerID <- as.factor(datos$CustomerID)
# Los booleanos le creamos una columna condicional
#BikePurchase
#HomeOwnerFlag
datos <- datos %>%
mutate(
BikePurchase_f = factor(BikePurchase, labels=c("FALSE", "TRUE")),
HomeOwnerFlag_f = factor(HomeOwnerFlag, labels=c("FALSE", "TRUE"))
)
print(datos)
# describimos los estadísticos numéricos
datos %>% select(where(is.numeric)) %>% summary(use="complete.obs")
# observamos cómo se relacionan las variables
datos %>% select(where(is.numeric)) %>% cor(use="complete.obs")
#split: seleccionamos el monto de entrenamiento y lo guardamos en la variabble de train
indice <- sample(1:nrow(datos), size = 0.8 * nrow(datos))
# Train: entrenamos al modelo con el subset de testeo
train <- datos[indice, ]
# test: tomamos el monto a testar
test <- datos[-indice, ]
modelo_logit <- glm(BikePurchase ~   Country + MaritalStatus + HomeOwnerFlag_f + Education + YearlyIncome + Occupation, data = train, family = "binomial")
summary(modelo_logit)
# 1. Ajuste del modelo (Cambiamos 'family' por 'method')
modelo_arbol <- rpart(BikePurchase ~ Country + MaritalStatus + HomeOwnerFlag_f +
Education + YearlyIncome + Occupation,
data = train,
method = "class")
# 2. Visualización
rpart.plot(modelo_arbol,main = "Árbol de Decisión: Predicción de Bike Purchase",
type = 2,
extra = 104,
nn = TRUE)
pred_logit_prob <- predict(modelo_logit, newdata = test, type = "response")
# 1# 1. Convertimos tus probabilidades a clases (0 o 1) con el corte de 0.5
pred_clase <- ifelse(pred_logit_prob > 0.5, 1, 0)
# 2. Convertimos AMBOS a factor asegurando que tengan los mismos niveles
pred_factor <- factor(pred_clase, levels = c("0", "1"))
real_factor <- factor(test$BikePurchase, levels = c("0", "1"))
# 3. Magia: Generamos la matriz completa
confusionMatrix(data = pred_factor, reference = real_factor)
# 1. Pide la clase directamente (type = "class")
pred_clase_arbol <- predict(modelo_arbol, newdata = test, type = "class")
# 2. Aseguramos que sea factor y tenga los mismos niveles que la realidad
# Nota: predict con type="class" ya suele devolver factor, pero esto es doble seguridad
pred_factor_arbol <- factor(pred_clase_arbol, levels = c("0", "1"))
real_factor_arbol <- factor(test$BikePurchase, levels = c("0", "1"))
# 3. Matriz
confusionMatrix(data = pred_factor_arbol, reference = real_factor_arbol)
# Ver qué variables usó realmente el árbol y cuánto importaron
modelo_arbol$variable.importance
datos_cluster_input <- datos %>%
select(where(is.numeric)) %>%
select(-BikePurchase)
datos_escalados <- scale(datos_cluster_input)
clusterizacion <- kmeans(datos_escalados, centers = 4, nstart = 25)
resumen_clusters <- datos_cluster_input %>%
mutate(Cluster = clusterizacion$cluster) %>%
group_by(Cluster) %>%
summarise(across(everything(), mean))
print(resumen_clusters)
datos_para_arbol <- datos_cluster_input %>%
mutate(Cluster = as.factor(clusterizacion$cluster))
# 2. Creamos el árbol explicativo
# "Cluster ~ ." significa: Predice el Cluster usando TODAS las demás columnas
arbol_explicativo <- rpart(Cluster ~ .,
data = datos_para_arbol,
method = "class")
# 3. Lo visualizamos
rpart.plot(arbol_explicativo,
type = 2,
extra = 101,
nn = TRUE,
box.palette = "BuGn",
main = "Reglas que definen cada Cluster")
ventas <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "ST Ventas Totales ")
#colnames(ventas)
class(ventas$OrderDate) # Nos aseguramos que la columna de fecha está bien factorizada en fecha
min(ventas$OrderDate)
#unique(ventas$OrderDate)
series_ventas <- ts(ventas$Sales...2, start= c(2011, 5), frequency = 1)
series_ventas <- ts(ventas$Sales...2, start= c(2011, 5), frequency = 12)
series_ventas <- ts(ventas$Sales...2, start= c(2011, 5), frequency = 12)
series_ventas
series_ventas <- ts(ventas$Sales...2, start= c(2011, 5), frequency = 12)
plot(series_ventas)
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
#| include: false
getwd()
setwd("/Users/alejandrocamposlamas/Proyectos/ACTIVIDADES_UNIR/actividad-3-AnalisisDatos")
library(readxl)
library(dplyr)
library(caret) # para matriz de confusión
library(rpart) #Para realizar el árbol
library(rpart.plot) #Para dibujar el árbol
library(factoextra) # para clusteres
library(NbClust)
library(zoo) # para ts diario
library(forecast)
library(dplyr)
library(lubridate)
getwd()
set.seed(123)
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
#ventas_mensuales <- ts(ventas$Sales...2, start= c(2011, 5), frequency = 12)
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
ventas_mensuales <- ts(ventas$Sales...2, start= c(2011, 5), frequency = 12)
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
ventas_mensuales <- ts(ventas$Sales...2, start= c(2011, 5), frequency = 12)
ventas_mensuales
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
ventas_mensuales <- ts(ventas$Sales...2, start= c(2011, 5), frequency = 12)
plot(ventas_mensuales)
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
series_ventas <- ts(ventas_mensuales$Sales...2, start= c(2011, 5), frequency = 12)
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
# 2. Crear la serie temporal
# ¡OJO! Aquí usamos TotalSales, que es el nombre que definiste arriba
series_ventas <- ts(ventas_mensuales$TotalSales, start = c(2011, 5), frequency = 12)
# 3. Graficar la serie
plot(series_ventas, main="Ventas Mensuales", col="blue", lwd=2)
# Realizar la predicción
modelo <- auto.arima(series_ventas)
prediccion <- forecast(modelo, h = 2) # h=2 son los 2 meses que te piden
# Ver los valores de la predicción
print(prediccion)
# Graficar la predicción
plot(prediccion, main="Predicción Ventas Próximos 2 Meses")
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/alejandrocamposlamas/Proyectos/ACTIVIDADES_UNIR/Estudiar_R")
edades <- c(25, 32, 41, 28, 35 )
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
data <- data.frame(edades, nombres)
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
data <- data.frame(edades, nombres)
View(data)
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
data <- data.frame(edades, nombres)
View(data)
data$edades
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
data <- data.frame(edades, nombres)
View(data)
mean(data$edades)
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
data <- data.frame(edades, nombres)
#View(data)
mean(data$edades)
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
data <- data.frame(edades, nombres)
#View(data)
mean(data$edades)
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
personas <- data.frame(edades, nombres)
#View(data)
mean(data$edades)
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
personas <- data.frame(edades, nombres)
#View(data)
mean(personas$edades)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas <- as.factor(personas$genero)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas <- as.factor(personas$genero)
summary(personas)
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
personas <- data.frame(edades, nombres)
mean(personas$edades)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas <- as.factor(personas$genero)
summary(personas)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas <- as.factor(personas$genero)
summary(personas)
table(personas)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas <- as.factor(personas$genero)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas <- as.factor(personas$genero)
str(personas)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas <- as.factor(personas$genero)
class(personas)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas <-personas %>% as.factor(personas$genero)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas$genero <-as.factor(personas$genero)
edades <- c(25, 32, 41, 28, 35 )
nombres <-  c("Alejandro", "Jorge", "Ramon", "Judy", "Pablo")
personas <- data.frame(edades, nombres)
mean(personas$edades)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas$genero <-as.factor(personas$genero)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas$genero <-as.factor(personas$genero)
summary(personas)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas$genero <-as.factor(personas$genero)
summary(is.numeric(personas))
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas$genero <-as.factor(personas$genero)
summary(personas)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas$genero <-as.factor(personas$genero)
summary(personas)
table(personas)
genero = c("H", "H","M", "M", "H")
personas <- data.frame(edades, nombres, genero)
personas$genero <-as.factor(personas$genero)
summary(personas)
table(personas$genero)
aguacates <- read_csv("./Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
aguacates <- read_csv("./Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
aguacates <- read_csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
aguacates <- read_csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
aguacates <- read.csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
aguacates <- read.csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
aguacates
#cargamos
aguacates <- read.csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
#vemos estructura
str(aguacates)
#cargamos
aguacates <- read.csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
#vemos estructura
str(aguacates)
table(aguacates$geography)
#cargamos
aguacates <- read.csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
#vemos estructura
str(aguacates)
#cargamos
aguacates <- read.csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
#vemos estructura
str(aguacates)
# usamos summary()
summary(aguacates)
#cargamos
aguacates <- read.csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
#vemos estructura
str(aguacates)
# usamos summary()
summary(aguacates)
# cuantas filas y columnas tiene?
nrow(aguacates)
ncol(aguacates)
#cargamos
aguacates <- read.csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
#vemos estructura
str(aguacates) # aquí deberiamos  filtrar seguramente la geografía
# usamos summary()
summary(aguacates) # deberiamos convertir a factor type
# cuantas filas y columnas tiene?
nrow(aguacates)
ncol(aguacates)
dim(aguacates)
# ¿no hay alguna manera de hacer una especia de size() como en python?
# Type debería ser un factor porque es una cateogría y ahora está en varchar
aguacates$type <- as.factor(aguacates$type)
# creo que también tendría que mirar si hay algun null, creo que sea hacer con colSums(is.na) o algo asi, en el caso de hacer null filtrar quitando los nulls
# parece que filtrar es importante tanto nulls como registros de geografías que no son importantes, estos son temas que pueden surgir en el examen. Veo que subset() es algo que tiene preparado el profesor y tiene relación con esto
# summary() es un proceso iterativo, uno hace el summary y se da cuenta que quizás deba filtrar columnas o elegir solo las numericas, etc.
#Parece que al igual de importante que saber hacer un summary() es importante saber interpretar, posiblemente no interpretar todo de todas las columnas, pero si de aquellas que sean objeto de estudio, por ejemplo averge_price o total_colume.
# Creo que la profesora menciono que todo aquello que fuera 0, 1,
#cargamos
aguacates <- read.csv("Actividades/Actividad_1/Actividad 1 – Grupo3 - Análisis de datos de aguacate.csv")
#vemos estructura
str(aguacates) # aquí deberiamos  filtrar seguramente la geografía
# usamos summary()
summary(aguacates) # deberiamos convertir a factor type
# cuantas filas y columnas tiene?
nrow(aguacates)
ncol(aguacates)
dim(aguacates)
dim(aguacates)[1]
dim(aguacates)[2]
# ¿no hay alguna manera de hacer una especia de size() como en python?
# Type debería ser un factor porque es una cateogría y ahora está en varchar
aguacates$type <- as.factor(aguacates$type)
# creo que también tendría que mirar si hay algun null, creo que sea hacer con colSums(is.na) o algo asi, en el caso de hacer null filtrar quitando los nulls
# parece que filtrar es importante tanto nulls como registros de geografías que no son importantes, estos son temas que pueden surgir en el examen. Veo que subset() es algo que tiene preparado el profesor y tiene relación con esto
# summary() es un proceso iterativo, uno hace el summary y se da cuenta que quizás deba filtrar columnas o elegir solo las numericas, etc.
#Parece que al igual de importante que saber hacer un summary() es importante saber interpretar, posiblemente no interpretar todo de todas las columnas, pero si de aquellas que sean objeto de estudio, por ejemplo averge_price o total_colume.
# Creo que la profesora menciono que todo aquello que fuera 0, 1,
colSums(is.na(aguacates))
sum(is.na(aguacates))
prop.table(table(aguacates$type))
prop.table(table(aguacates$type)) * 100
aguacates_org <- subset(aguacates, aguacates$type = "organic")
aguacates_org <- subset(aguacates, aguacates$type == "organic")
aguacates_org <- subset(aguacates, aguacates$type == "organic" & aguacates$region == "Albany")
nrow(aguacates_org)
aguacates_org <- subset(aguacates, aguacates$type == "organic")
nrow(aguacates_org)
names(aguacates)
aguacates_org <- subset(aguacates, aguacates$type == "organic")
nrow(aguacates_org)
aguacates_org <- subset(aguacates, aguacates$type == "organic" & aguacates$geography == "organic")
aguacates_org <- subset(aguacates, aguacates$type == "organic")
nrow(aguacates_org)
aguacates_org <- subset(aguacates, aguacates$type == "organic" & aguacates$geography == "organic")
nrow(aguacates_org)
names(aguacates)
distinc(aguacates$region)
distinct(aguacates$region)
distinct(aguacates$geography)
distinc(aguacates$geography)
distin(aguacates$geography)
count(aguacates$geography)
unique(aguacates$geography)
aguacates_org <- subset(aguacates, aguacates$type == "organic" & aguacates$geography == "Albany")
aguacates_org <- subset(aguacates, aguacates$type == "organic")
nrow(aguacates_org)
# miro names(aguacates)
# miro unique(aguacates$geography)
aguacates_org <- subset(aguacates, aguacates$type == "organic" & aguacates$geography == "Albany")
nrow(aguacates_org)
# Esto no me ha salido, no sé como se usan dos condiciones, además las condiciones pueden ser OR o AND, en este caso he usado AND
aguacates_org <- subset(aguacates, aguacates$type == "organic" OR aguacates$geography == "Albany")
aguacates_org <- subset(aguacates, aguacates$type == "organic" | aguacates$geography == "Albany")
aguacates$type == "organic")
aguacates_org <- subset(aguacates, aguacates$type == "organic")
nrow(aguacates_org)
# miro names(aguacates)
# miro unique(aguacates$geography)
aguacates_org <- subset(aguacates, aguacates$type == "organic" | aguacates$geography == "Albany")
nrow(aguacates_org)
# Esto no me ha salido, no sé como se usan dos condiciones, además las condiciones pueden ser OR o AND, en este caso he usado AND
aguacates_org <- subset(aguacates, aguacates$type == "organic")
nrow(aguacates_org)
# miro names(aguacates)
# miro unique(aguacates$geography)
aguacates_org <- subset(aguacates, aguacates$type == "organic" & aguacates$geography == "Albany")
nrow(aguacates_org)
# Creo que las condiciones pueden ser OR o AND, en este caso he usado AND pero podria ser OR que es asi |
# precio medio aguacates
mean(aguacates_org$average_price)
