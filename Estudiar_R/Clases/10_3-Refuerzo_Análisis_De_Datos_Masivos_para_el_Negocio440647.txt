Hola, buenos dias a todos, buenas tardes, bienvenidos a esta clase de resumen. Muy buenas tardes, de acuerdo, hoy intentaremos ver como vivimos el otro día, vale, ya veréis que aquí si que hay muchas mas similitudes, pues lo que vendría siendo regresión lineal, lo que vimos en clasificación, que vimos dos casos, regresión logística y árboles de decisión, y luego intentar llegar un poco a la clasificación y a las series temporales. en principio deberíais tener todos acceso ya al documento que vamos a utilizar hoy es el mismo que os subieron por eso tardé un poquito más porque completé con la última parte de clasificación y series temporales que lo tenéis en el aula de información general junto con los archivos que se mencionan en el mismo documento y también ahí estaría la sesión de la grabación tanto de esta grabación como la que tuvimos la semana pasada en teoría hoy es una hora, bueno si nos alargamos un poquito más un poquito menos aquellos que no podáis pues os desconectáis sin problemas porque se quedará en la grabación pero para que tengáis todo lo mejor posible y repasemos todo lo más lo más característico y de nuevo recordar que tanto este libro no te preocupes, tanto este digamos que estos apuntes que os he dado como lo que vemos ahora mismo en clase es una forma de hacerlo pero en R existen diversas formas de hacerlo es decir, es muy probable que vuestra profesora o vosotros hayáis aprendido de otra manera se corrige por resultado por lo tanto si alguien sabe hacer las cosas de otra manera que las haga de otra manera no habrá en principio ningún tipo de problema dicho esto y ya sin más dilación os voy a compartir la pantalla como vimos la anterior vez podéis comentarme tanto por chat como por ejemplo si tenéis cualquier tipo de duda simplemente interrumpir durante la clase y habláis entonces la vez pasada vimos lo que sería la introducción de datos En la introducción de R y había uno que era el tratamiento de datos, que era lo que estuvimos más profundizando, sobre todo con el tema de hacer filtros, tema de valores nus que podemos hacer. Y os he añadido la parte de convertir a columnas de un tipo a otro. Lo que recordamos ahora cuando veamos el caso de una regresión logística lo volveremos a hablar, pero bueno, os lo he puesto aquí totalmente explicado en los apuntes. Empecemos con la primera. La primera ya empezamos con modelos como sería la regresión lineal, la regresión logística, árboles de decisión y clasterización. Lo primero que tenemos que tener en cuenta a la hora de decidir qué tipo de modelo hacemos es qué queremos conseguir. De manera muy sencilla, si yo quiero predecir un número del cual ya sé lo que ha pasado en el pasado en función de otras columnas, más lo que ha pasado en el pasado, estaría hablando de una regresión, ¿vale? Predigo números, sobre todo en regresión lineal. cuando lo que queremos es que tenemos una columna en la cual tenemos diversos casos por ejemplo, digamos que tenemos un montón de imágenes y yo tengo 50 casos de imágenes que sé que son gato y 50 casos de imagen que sé que son perro y yo le añado una imagen más y quiero saber si es gato o perro yo ya he distinguido dos categorías pero sé cuáles son una es gato y otra es perro aquí es donde estamos hablando de clasificación puede ser una clasificación en dos categorías una clasificación que se llama binaria en cuyo caso soléis utilizar la regresión logística o puede ser de más de dos categorías en cuyo caso solo podríais utilizar árbol de decisión porque no tendríamos regresión logística no encuentro material de las clases de repaso Valerina, en la clase que vosotros tenéis un momento, eh de cinco segundos aquí vosotros decís posjamos efectivamente, el aula virtual si entras por aquí vale, aquí tenéis que tener el aula de formación general el aula de formación general en teoría os lo han puesto documentación y de todas formas Irina, si tú eres de mi grupo, también apropiado análisis masivo en la parte de documentación aquí tenemos la parte de códigos, y códigos en él tendrás el uso en PDF y también todos los signos que así lo estamos utilizando, ¿vale? Pero si no, también la tienes en la parte que te he comentado de habla de información general, ¿vale? Vale, acuerdo, entonces, si tenemos más de dos categorías, por ejemplo, imaginemos que estamos haciéndolo de clase media, clase baja y clase alta, por ejemplo, ¿vale? Ya son tres, ya no podríamos utilizar regresión logística y solo podríamos utilizar, de lo que hayas aprendido, árbol de decisión, ¿vale? ¿Y cuál es el caso de la clasterización? Aquí entramos en otro apartado distinto, ¿vale? Hasta ahora nosotros teníamos ejemplos o teníamos casuísticas de lo que nosotros queríamos predecir. Esto es lo que se llaman datos etiquetados y es por lo que se suele llamar el aprendizaje supervisado, ¿vale? Cuando vamos a clasterización, yo ya no tengo casos, es como que seleccionamos todo un popurrí de datos y le decimos al ordenador, quiero hacer tres grupos. Ahora, como tú me los agrupes, es tu cosa. Es decir, nosotros aquí no intervenimos en ningún tipo de agrupación. Por lo tanto, el ordenador agrupa los datos como quiera, ¿vale? Para que tengamos bien claro de cuándo utilizar una clasificación, cuándo una clasificación o cuándo una regresión línea, ¿vale? dicho esto, en todos ellos lo primero siempre es cargar los datos creo que esto no nos sorprende a nadie entonces cargaríamos perdonad regresión logística es booleano pero árbol de decisiones es como que si te permite elegir varios grupos o algo así ah vale árbol de decisión te sirve para las dos casuísticas, cualquier clasificación la puedes hacer con un árbol de decisión ¿vale? regresión logística efectivamente solo puede ser cuando tienes dos categorías 0 si 1, si o no ah, una cosita, aparte de lo que has subido podrías subir el script tal como lo tienes así en cuaderno QMD vale, yo os lo subo también si lo queréis en cuaderno QMD me imagino que para poder hacer aquí el clip pero si copiáis las cosas tal cual están, vale, es así vosotros hacéis así, control C en un archivo R normal vale, si lo hacéis control C y le dais a ejecutar también os sería, no es necesario que lo tengáis de esta forma O sea, varias categorías en la variable Y. Efectivamente, con varias categorías en la Y no puedes utilizar regresión logística. Entonces, árbol de decisión siempre lo puedes utilizar, pero si tienes varias categorías en la variable Y no puedes hacer regresión logística. Regresión logística solo puedes utilizarlo cuando tengas dos. Luego pasaremos a regresión logística, no nos preocupemos. Entonces, cargamos los datos. En este caso sería el weather aus, que es la temperatura en Australia. Y lo primero que siempre os digo es intentar tener una visión general de los datos, con la dimensión de los datos, con el sum para ver cuántos valores nulos existen. aquí sería lo suyo que hicieseis un str de datos para saber qué tipo de columnas tenemos si estamos hablando de columnas de tipo texto tal como os comenté en la clase anterior vemos que tenemos varias columnas con valores nulos ahora lo que voy a hacer simplemente para este caso y para que veáis otro ejemplo es decir, todos estos valores nulos los voy a reemplazar por 0 podríais reemplazarlo por la media podríais haberlo sometido como ya trabajamos con lo de omitir, en este caso os lo voy a reemplazar a cero. Por lo tanto, ya no tendríamos valores nulos, sino que todos los valores serían nulos, los hemos cambiado por cero. Ahora, una cosa que os han preguntado de las entregas, que la podría haber puesto también en tratamiento de datos, pero como no os lo puse, os lo añadiría aquí para no olvidarse de la clase de hoy. Es cómo hacemos la covarianza. Hay dos formas. Tenéis la opción de, no sé si he escrito la segunda, sí. tenéis la opción que me imagino es como nos han explicado de normal de hacer seleccionar dos columnas y hacer la covarianza yo siempre utilizo esta, ya hemos quitado los valores nulos por un motivo el motivo es que me acostumbro más a poner toda la frase y de esa forma aunque luego en un futuro se me olvide quitar los valores nulos sé que no me va a distorsionar yo intento aprenderme siempre una forma de hacerlo y la utilizo siempre, esto es básicamente para que hubiese nulos que no los hay porque los hemos quitado, no me los tuviera en cuenta, ¿vale? De esta manera lo tendríamos en formato de dos columnas en formato numérico, pero ¿qué pasa si yo quiero calcular todas las columnas que pueda haber? Vale, pues en este caso lo podemos hacer con la librería de Plir, ¿vale? Nosotros utilizamos la librería de Plir, muy importante, solo funciona cuando la columna es numérica, por lo tanto aquí lo que estoy haciendo es quedarme con aquellas columnas que no son numéricas. ¿Qué ocurre si vosotros queréis utilizar una columna que no sea numérica? Bueno, pues que tendríais que utilizar, bien cambiarlo de string a factor o bien luego convertirlo de texto a numérico, con una de estas dos opciones que os pongo por aquí. Pero creo que de manera general, si no recuerdo muy bien, os sirve para el examen también con lo que se llaman las variables numéricas. no os lo puedo asegurar con total seguridad pero si no recuerdo mal sí entonces seleccionamos las que son numéricas y utilizamos la covarianza recordad que cuando tenemos este símbolo utilizamos la librería de Plir una librería no era más que R de por si no tenía todo el conocimiento así que íbamos entre comillas a libros y leíamos la información para poder usarla pues esto sería un poco las librerías que añadimos aquí si a alguien no le funciona y no se me ha olvidado de lo de que queréis páginas para practicar vale, si a alguien no le funciona tendría que primero instalarlo y si al instalarlo no le funcionase recordemos que os pasa una página que era www.posit.org.com en esa página sí que es cierto que la podéis descargar la versión correspondiente si alguno de vosotros os da algún error bueno, si nosotros ejecutamos esto, yo sí la tengo instalada así que no la voy a instalar de nuevo aquí tendríamos la covarianza claro, de todas las columnas con todas las columnas es cierto que aquí me podéis decir pero temperatura mínima una pregunta sí, para nosotros es como dado que, vale, así que es cierto que lo que hace es como seguir un proceso no había ninguna nueva variable para ello hubiese tenido que hacer aquí, por ejemplo, covaria. Efectivamente, ¿vale? Si yo hago covarianza y a eso le añado el valor que tengo en el otro lado, entonces sí creo una variable. Pero simplemente por el hecho de hacer los porcentajes mayor porcentaje, no crea ningún tipo de variable. ¿Sí? ¿Te he solucionado la duda, Alejandro? O sea, para crear una variable tendrías que darle un node y... No te preocupes. y una flechita con guión y flecha. Si os dais cuenta me podéis decir, bueno, así no la veo muy bien, porque sí que es cierto que en el caso de las columnas, si os dais cuenta, aparecen todas como en dos líneas porque no es la mejor forma de verlo, pero si os dais cuenta aquí en la terminal, sí que os aparece mejor. Recuerdo siempre que lo hagáis en un sitio, si lo estáis haciendo desde un archivo R como normalmente hacéis, ¿vale? Yo simplemente utilizo cuarto ahora mismo para que sea más cómodo a la hora de repasar, pero si lo hacéis aquí lo tendréis en la terminal. En la terminal sí que se ve bien, ¿vale? ¿Cómo podemos analizar la covarianza o en qué deberíamos fijarse en la covarianza? Cuando hablamos de la covarianza, sobre todo nos tenemos que fijar en lo que sería el signo, ¿vale? Es cierto que el valor también es significativo, pero el valor sobre todo nos cuesta saber un umbral. 33 es alto, bueno, si lo comparo con 3000 no es alto y si lo comparo con 10 sí que sería un valor alto. Entonces lo que es la fuerza de la relación la vamos a mirar siempre con el coeficiente de correlación. Entonces la covarianza no es más que si es positivo o si es negativo. Si es positivo, quiere decir que, por ejemplo, cuando aumenta la temperatura mínima, aumenta la temperatura máxima, lo cual tiene, entre comillas, cierto sentido porque generalmente estamos en verano o en primavera. Cuando aumenta, por ejemplo, la temperatura máxima, sin problema, los tenéis todos en el aula de información general, en la parte de documentación, y es el weatherhouse, el del tiempo de Australia.csv. Vale, entonces, bueno, aquí damos un poco lo que sería el signo positivo, relación positiva, cuando una crece la otra crece, negativo, relación inversa, ¿vale? Es decir, por ejemplo, evidentemente que es lo más normal, que si llueve no haya rayos de luz, de hecho si lo hubiese sería arcoiris y nos suele haber arcoiris, ¿vale? Entonces, una relación negativa lo que viene siendo es que cuando aumenta una de las variables la otra variable disminuye. Entonces, en covarianza, sobre todo, centraros en el tema del signo, ¿vale? Si es positivo o si es negativo. Vale, veo que alguien está mandando una foto. Muchísimas gracias, Irina. en el curso de R aquí no cuesta eso os lo envío por aquí y ya está, un momentito en principio en el archivo de R si descargas el PDF debería estar todo ahí dentro como capítulos y subcapítulos os vuelvo a pasar por aquí también el archivo de PDF por si acaso alguien no lo encuentra perdonad un momentito cinco segundos que dejo de compartir la pantalla creo en aula general también está y en el grupo mío en principio también lo que también está pero bueno ahora vuelvo a compartirlo un momentito a cinco segundos por si acaso a él es más como también mirarlo desde aquí este sería el archivo del curso y si no recuerdo mal ahora mismo estamos trabajando en el weather house que sería este de aquí para que lo podáis tener también vamos a trabajar con turistas UK turistas UK aquí está y también vamos a trabajar con el coaster de B aquí está esto es todo lo que trabajaremos el día de hoy, así que lo podéis descargar sin ningún tipo de problema. ¿Vale? Vuelvo a compartir pantalla para que lo podáis continuar. Entonces, hemos dicho, muy importante, covarianza te designo. Ahora, ¿cómo puedo saber si una relación entre dos variables es fuerte o no es fuerte o es débil o nada? ¿Es fuerte o no fuerte? ¿Débil o no débil? Etcétera. Vale, pues con eso tenemos que hacer con la correlación. ¿Por qué? Porque la correlación, yo sí que sé un baremo. La correlación siempre va entre menos 1 y 1. Entonces, si es 0, implicaría que es completamente independiente, es decir, que no sigue ningún tipo de relación entre ellas. Si es entre 0 y 0,5, positiva débil, entre 0,5 y 1, positiva fuerte, y lo inverso, entre menos 1 y menos 0,5, negativa fuerte, y entre menos 0,5 y 0, negativa débil. lo mismo solo se puede hacer para variables numéricas y es la misma sentencia pero en vez de COFCOR, por cierto, una cosa importante se os dejarán apuntes y código en el examen no sé si ya os lo han comentado a mi grupo yo se lo, si un 0 es prácticamente imposible vale, vale, yo a mi grupo no lo he comentado porque se lo pensaba comentar la clase de mañana ya que es algo que lo tenemos efectivamente lo debéis tener en Word o apuntes impresos creo que también se puede pero si ya lo vais a utilizar desde el ordenador pues evidentemente lo podéis tener en Word y lo podéis mantener abierto a lo largo de todo el examen no hace falta que os aprendáis todo de memoria la idea es que sepáis cómo utilizarlo disculpa una inquietud y el PDF que nos dejas ahí colgado perdón, no recuerdo cómo se llama, ese también lo podemos tener en el examen el de curso de R impreso, sí, impreso creo que sí si es online no, porque os hemos dado acceso solo a Word ¿vale? entonces si alguien abre un PDF lo que va a pasar es que os va a dar un problema, de acuerdo, a la hora de hacerlo, porque llegará la comisión evaluará que has abierto una herramienta que no os ha dado acceso y por lo tanto generalmente casi no hará problemas lo que os aconsejo a DSPDF seleccionar las partes que más os interesen y poner al lado el comentario de lo que hacen tampoco necesitáis un pdf de 140 páginas porque también entre que los vas buscando y no vas a tardar más así que yo lo haría de esa forma te has solucionado la respuesta el pdf fue posterior a que dijésemos el tema del Word normalmente yo siempre dejo Word y entonces por eso básicamente fue por esto pero si podéis tener el código, en un documento si no recuerdo mal, ya nos hemos puesto impreso, esto os lo pondrá vuestra profesora que os lo dé, en principio os lo pondrá en un foro, yo creo que ya os lo estoy dando al grupo que yo le doy pero no es el foro de dudas generales es otro hilo que pone examen cuando entréis en el foro y pongáis examen ahí veréis que os he puesto todos los documentos que están permitidos y ahora estoy pensando que si lo tengo abierto os lo puedo enseñar vale entonces documentación documento aquí aquí dentro de este de aquí en teoría tenéis acceso a ordenador, RR Studio el ex por si tenéis que abrir algún archivo el código en formato impreso y el código en formato Word tanto si vais presencial como si vais en modalidad online espero que os haya podido ayudar y que aquí os hayáis llevado una alegría al menos mi grupo esté convencido de que sí, porque no les había dicho nada al respecto hasta ahora. Vale, bueno, continuamos entonces. Es lo mismo, solo que utilizamos en Deco, utilizamos Core. Veo que tengo aquí muchos mensajes. Solo Word o pago impreso. Efectivamente, yo también creo que el PED es muy largo porque al final tiene todos los datos y por eso veréis que hay muchas partes en las que son hojas completas de datos. por lo tanto no os preocupéis, ¿de acuerdo? Yo lo que haría sería una versión reducida que sea solo el código que tenéis que utilizar y ahí lo podéis ver más claro Si, cuarto tiene una parte positiva que es que todo tiene una parte negativa que es que todo lo que son tablas de datos y todo te lo vuelca como hojas inmensas y los datasets no son precisamente pequeños ¿Vale? Bueno, hay que decir la correlación con el core para que vea si funciona, la ejecutamos sin ningún tipo de problema, recordamos que tenemos las variables numéricas y aquí tenemos por ejemplo la matriz, si vemos por ejemplo una primera que es mi temperatura con temperatura que es este 1, pues esto implica, es normal, es decir, es la relación perfecta, al final estoy mirando cómo varía una columna con respecto a sí misma, sin embargo si vemos con máximo temperatura que sería el valor de aquí, pues vemos que la correlación es 0.72, ¿está entre 0.5 y 1? Sí, por lo tanto que existe una relación, una correlación positiva fuerte. ¿Tiene sentido? Sí, porque tiene sentido que cuando la temperatura mínima asciende, la temperatura máxima asciende porque solemos estar yendo hacia estaciones más cálidas. Sin embargo, si por ejemplo vamos con el wind speed 9 am, que en este caso tendríamos que mirar este valor de aquí, que es el 0,18, porque veis que aquí están las cosas un poco desconfiguradas, pues en este 0,18 veríamos que está entre 0 y 0,5 por tanto es débil ¿quiere decir que no hay una relación? no, pero lo que quiere decir es que hay una relación mucho más débil si nosotros representásemos esto gráficamente entre la temperatura mínima y la temperatura máxima veríamos muchísimos puntos ascendentes que parece una recta pero entre la temperatura mínima y el wind speed veríamos un poco más de dispersión como un poquito más de nube de puntos se vería que crece pero prácticamente no se distinguiría Aquí, enlazando con un comentario que os he dicho un compañero, una correlación de estrictamente 0 sí que es cierto que es prácticamente imposible. Ya no para el examen, porque para el examen es entre 0 y 0,5 débil. pero en la vida real una correlación cercana a 0 es prácticamente imposible así que si es 0,01, 0,02, 0,03 se suele considerar también que son independientes y lo mismo pasa con lo alto en la vida real es muy complicado encontrar correlaciones muy muy altas entonces a veces se baja un poquito el baremo de lo que consideramos una correlación fuerte pero esto es en la vida real en el examen se dice la teoría de 0,05 0,51 que es lo que en principio y vamos a la regresión lineal dime y en ese numerito que estaba ahí arriba no lo puedo memorizar, en el 0.18 la interpretación, ¿cuál sería? porque imagino que en el 0.18 vale, en el 0.18 lo primero que tendrías que decir es que 0,18 está entre 0 y 0,5 vale, entonces es una correlación positiva, débil, eso sería lo primero y a priori parece cierto que el hecho de que la temperatura mínima disminuya no parece que afecte mucho a que haga más viento o menos viento, ¿vale? Entonces vendría siendo que puede que haya una relación, pero es demasiado débil, no es tan evidente como podría ser la temperatura máxima o la temperatura mínima. De todas formas, cuando os punten esto, os darán dos columnas concretas, ¿vale? y generalmente bueno, no se os pedirá que hagáis todas, ¿vale? y las que os den generalmente se verá clara la relación ¿vale? Profe, por favor, ¿me puedes explicar lo de ICNA, la parte de perdida de experiencia incluidas para evitar que se calcule efectivamente esto, cumplir observaciones a pesar que nosotros bueno, no sé si te he resuelto la pregunta, no he visto quien me ha preguntado, primero al que le estaba preguntando y perdone, yo le interrumpo Y perdona, yo la interrumpí un primero. No, tranquilo, tranquilo. Si a mí cuantas más preguntas me hagáis, mejor. Esa es esta clase. Esta clase es para cualquier duda que tengáis, me la podéis decir y yo os la pueda solventar en la medida de lo posible, ¿vale? Y podamos tener una mejor experiencia sin problemas. Interrumpidme todo lo que sea necesario, que para esta cosa no hay ningún tipo de problema. Vale, luego te contestó Alejandro esa pregunta, pero voy antes a la pregunta de... A la pregunta de Paulina. que era la primera que me había contado por chat. Vale, el tema de is.na, ¿vale? Eso lo que hace es ver cuántos valores nulos teníamos. Recordad que esto no es verdadero o falso en función de si había valor nulo o no había valor nulo, ¿vale? Entonces, a pese que nosotros ya hemos remontado estos valores nulos por cero, es decir, ya no tenemos valores nulos en nuestro dataset, yo particularmente me gusta covarianza añadir esta palabra, ¿vale? O sea, si tú haces la covarianza sin nada, te va a funcionar igual. pero yo prefiero añadirla porque imagínate que se te haya olvidado por algún casual quitar los valores nulos ¿vale? la covarianza te va a salir en EA, vas a empezar a pensar ¿por qué es en EA? ¿hay algo malo en mis datos? ¿hay algo que no me funciona? etcétera, etcétera, etcétera entonces es mejor siempre acostumbrarte a poner use igual a complete observations y así siempre te asegurarás de que no tengas los valores nulos ¿vale Paulina? contéstame si ha quedado esa parte clara y mientras voy resolviendo a caso de Diana ¿Puedes apuntar en cuaderno? Uy, pues esto lo he preguntado. Sé que impreso sí y word sí, en cuaderno no lo sé. Coméntalo en el foro que te ponga tu profesora, ¿de acuerdo? Para que lo pueda remitir a la organización y podamos saberlo mejor, porque es la primera vez que alguien me lo pregunta. Después, Cristina Las desviaciones típicas siempre son positivas, por lo tanto no afectan al símbolo de la covarianza, por lo que efectivamente el signo de la covarianza siempre va a coincidir con el signo del coeficiente de correlación. ¿En el que vamos a tener que describir descriptivamente las redundancias de los datos que actualizamos? no no tendréis que hacer filtros y cosas así pero no os vamos a decir que describas absolutamente todos los datos o sea, está muy guiado son una serie de preguntas y está muy guiado a que respondas lo que se te pregunta en cada una, o sea, no vas a tener tampoco que escribir la vida en verso ¿vale? perfecto luego, a lo mejor no hay que quitar nulos, dependerá de la movida esas decisiones las tomamos nosotros en el examen vale, si no quitáis nulos es posible que os dé problemas la parte de la regresión lineal, la parte de la clasificación y la parte de la clasterización, generalmente o se quitan los nulos o se reemplazan por un valor, esa decisión de si quitáis los nulos, quitáis la columna o se reemplazan en un valor que lo vimos en la clase anterior, esa decisión la tomáis vosotros en el examen, efectivamente y justificarla, quito los valores nulos por este motivo, vale o he decidido eliminar la columna porque no es importante o tal ¿vale? Reemplazar por la media, por ejemplo, efectivamente, sí, sí, exacto, ¿vale? Vale, pues continuemos ya con la regresión lineal, dado que luego todo el proceso de regresión lineal, clasificación y clasificación, el proceso es muy, muy, muy parecido, ¿vale? Primero, ¿qué tenemos que hacer? Tenemos que seleccionar qué columnas queremos para la regresión lineal. En este caso, yo he dicho que quiero dos, todas las que eran numéricas, entonces he visto cuáles son las médicas y ahora tengo que hacer la selección de mi conjunto de datos. Me voy a quedar con la alería de Plir, aquí no la he utilizado, ¿por qué? Porque ya la he cargado al principio, si la cargáis al principio no tenéis que estar cargándola cada vez que la utilicéis y de mi conjunto de datos selecciono todas las columnas. Los nombres de columnas son textos y recordemos que los textos siempre van en comillas, porque si no serían variables entonces entre comillas y separados cada uno de ellos por comas de acuerdo, una vez que hemos seleccionado estos datos de regresión que no hay más que hacer esta selección de estas columnas que objetivamente os lo he puesto así pero si queréis utilizar todas las columnas numéricas realmente estoy utilizando esto podríais haber puesto directamente este y llamarlo datos regresión y os habría funcionado igual os lo he puesto así por si alguno de vosotros el día del examen dice, pues mira, rainfall, yo he visto que la correlación es muy pequeña, no me interesa y la queréis eliminar, ¿vale? Porque esa es otra cosa con la correlación. Vosotros podéis decir, pues he visto, por ejemplo, que quiero predecir la temperatura mínima y he visto que con el viento tiene muy poca correlación, entonces, muy poca correlación, entonces yo no voy a utilizar el viento para predecir la temperatura mínima. Lo podéis hacer, ¿vale? Con esta justificación como os estoy comentando. Entonces aquí lo que haríais es no tener en cuenta esta variable de tiempo, ¿vale? Por eso os lo he puesto así y no os lo he puesto con seleccionar todas. Entonces vosotros el día del examen, si queréis aquellas que tengan correlaciones más débiles, podéis a lo mejor considerar que es mejor no utilizarlas, pues simplemente las eliminaríais y ya está, ¿vale? Intentad también que el código sea lo más fácil de utilizar para vosotros. después, siguiente punto ya tengo mis columnas, ¿cuál es el siguiente punto? para el aprendizaje supervisado, muy importante solo para el supervisado, es decir, para la clasterización no, tenemos que dividir el dataset en un conjunto de entrenamiento y un conjunto de testeo ¿por qué? primero el modelo tiene que aprender, entonces ¿cómo el modelo aprende? aprende con el conjunto de entrenamiento, en este conjunto de entrenamiento yo le doy los datos y le doy la solución, es como un niño pequeño ¿Cómo le enseñamos a leer? Le decimos la M con la A es mala, la M con la E es menos. Pues esto es lo mismo, le decimos mira, con estos datos esta es la solución. ¿Qué va a ocurrir en el caso del conjunto de testeo? Que yo solo le voy a dar los datos, voy a obtener la solución y voy a comprobar con lo que yo sé que es el resultado. Por eso dividimos entre entrenamiento y testeo. Vale, vale, vale, vale. Eso mismo sucedió en la actividad 2, el árbol de decisión. Aunque le colocara todas las variables, él decidió cuál es colocar la visualización por su nivel de peso de la variable. Efectivamente, Juan. Vale, y en realidad por lo que veo, la matriz de correlación te evita tener que hacer hipótesis. Sí, no es al 100%, ¿vale? Seguro de que la matriz de correlación te vaya a dar a las variables que tienes que quitar. Habría que hacer un poco más de estudios, pero a vuestro nivel sí, ¿vale? Y para la mayoría de la gente sí. pero en algunos casos sí que puede que estemos quitando algún punto que pueda ser importante pero para vuestro caso y esta asignatura como tal, sí, ¿vale? por la correlación podréis quitar vale, cuando dividimos por entrenamiento y testeos, ¿por qué nos lo piden en el enunciado como en la actividad 2? vale, aquí yo tengo mis pros y mis contras, ¿vale? para mí siempre, o sea, yo la regresión lineal no la contemplo y cuando veamos el siguiente cuatrimestre de asignatura no la contemplo sin entrenamiento y testeo. ¿Por qué? Porque tú con el entrenamiento aprendes y con el testeo miras cómo de bien ha ocurrido la regresión lineal. Sí que es cierto que en esta asignatura, por lo habitual, digamos que se ha basado mucho en hacéis la regresión lineal y cuando por enunciado te digo que lo dividas, entonces lo dividís. Entonces para esta asignatura sí, pero para vuestra vida diaria, para próximas asignaturas, que si la tenéis conmigo será para próxima asignatura siempre se descompone en entrenamiento y testeo, porque necesitas saber cómo de bien ha funcionado y no puedes saber cómo de bien ha funcionado dándole la propia solución, tendrás que hacer que él encuentre la solución y de ahí tú compararla con la solución que te has quedado ¿no entiendes Alejandro el tema del entrenamiento y testeo? lo digo por chat lo digo hablado que hay que hacer siempre entrenamiento y siempre hay que separarlo entre entrenamiento y testeo y testeo siempre, es que no te he entendido es que no lo habéis hecho vale, vale, vale, os explico esta asignatura perdón, di, di, di no, no, sí, sí, ven por aquí esta asignatura es una introducción básica para luego la asignatura que se tiene en el segundo cuatrimestre. Entonces, en esta introducción básica, ¿qué ocurre? Ocurre básicamente que se os dice cómo se hace una regresión lineal y no se incide tanto en el tema del entrenamiento y testeo. Entonces, en esta asignatura como tal, si os pide una regresión lineal, no necesitáis dividirlo. Y si os dicen una regresión lineal con testeo y entrenamiento, en principio sería cuando lo tuvieses que dividir que si hacéis la regresión lineal siempre dividiendo entre entrenamiento y testeo, nadie os lo puede poner mal porque es correcto, me explico pero no se os incide tanto en este aspecto a la hora de corregir, en vuestro día a día y para próximas asignaturas que tengáis por ejemplo, la que yo he dado que era la continuación de esta en Python, para mí siempre era obligatorio hacer entrenamiento y testeo porque luego en vuestro día a día va a ser así pero a este nivel si no os lo ponen específicamente podéis hacerlo con entrenamiento y testeo o sin él porque no se os ha especificado exactamente que siempre tenga que ser con entrenamiento y testeo a ver si yo recuerdo mal si no recuerdo mal es que no os lo puedo decir pero bueno, el tema es creo que podréis elegir y ahí escogéis qué opción queréis pero los estoy hablando de memoria y los pusimos hace muchísimo tiempo entonces es posible que me haya equivocado en este punto la duda es si el entrenamiento siempre al 80% y el test al 20%, casi en el 75% de las ocasiones sí, Paula, se suele utilizar el 80-20 otras veces se utiliza el 70-30 y ya suele ser muy raro el caso que utilices 60-40 la mayoría suele estar entre 80-70 para el entrenamiento y test 20 o 30% o sea, no siempre tiene que ser 80%, me refiero, se suele poner, que es 1, ahí vamos, 1 en error, ahí vamos, ahí vamos, entonces lo que tenéis que hacer es esto, siempre ejecutéis de algo más o menos parecido, luego el tema del índice, lo que estamos haciendo es desde la fila 1 hasta el número total de filas que tenga nuestro dato de regresión si hay algo que siempre os preocupa o no sabéis muy bien, ¿qué os aconsejo? os aconsejo, no sé qué significa esto, bueno pues voy a calcularlo y es el número total de filas que tenemos en datos de regresión entonces desde la fila 1 hasta el número total de filas que tengamos Lo que quiero es que me seleccione el 80% y estos van a ser los que guardamos en índice, es decir, índice que me está diciendo qué filas van al conjunto train. Entonces estas filas irán al conjunto train. Aquí hemos puesto todas las filas que selecciono para el conjunto de entrenamiento y cuando no pongo nada detrás de la columna estoy seleccionando todas las columnas. el 0,8 es random, perfecto, muy bien Paula es el 80%, exactamente y el 1,2,3 1,2,3, ah, sí esto podéis utilizar, es un número que hace la reproducibilidad, podéis poner 1,2,3, por ejemplo en Python se pone el 42, podéis, creo que también existe la semilla 0, podéis poner la que realmente os interese más, vale si es random me refiero a que sea el 80% me refiero a que si la selección la hace aleatoria o no vale, en teoría juraría que sí de todas formas esto no os lo van a preguntar tampoco en Python sí que utilizaremos una cosa que se llama random42 si no recuerdo mal y ahí sí que lo especificaremos que tiene que ser aleatorio de momento ahora mismo con que más que de sobra, pero entiendo tu pregunta y es una pregunta importante la semilla 42 me imagino que no lo he hecho nunca pero me imagino que si pones aquí 42 te funcionará igual, lo probamos vale y lo probamos vale, si tiene toda la pinta de que funciona igual, vale índice train test siempre deben ir siempre en el código nos podemos encontrar en algún momento yo os aconsejo que no índice podéis poner índice podéis poner index, el train y el test se suelen utilizar o bien train o bien train set test set ¿vale? pero esto sí sí que os aconsejo que lo llaméis train test porque casi todo el mundo lo entiende por train test, lo podéis llamar de cualquier otra forma ¿vale? pero os aconsejo siempre que lo llaméis así porque todo el mundo lo llama así importante sí, dime una consulta, nosotros en la clase usamos para el tema del índice una cosa que no, perdón Sí Sirve igual Sí, sí, sirve completamente igual O sea, el maestro que os he puesto es lo que yo normalmente utilizo, ¿vale? Pero podéis utilizar cualquier otra forma que os han dicho, al final la idea es que escojáis y por eso también viene bien que hagáis vuestro propio Word con vuestro propio código que escojáis lo que a vosotros os funcione y os sentáis más cómodos, ¿vale? Se va a evaluar por el resultado final no tanto por cómo lo y por el procedimiento que habéis hecho pensando pero que se utiliza subsample, utiliza sample así, está correcto igual. Y aquello que era create data partition o algo así ¿qué tiene que ver con esto? Vale, el data partition es este 80% es como que estás haciendo una partición de los datos de acuerdo de la misma manera, seleccionas un conjunto de datos para el entrenamiento y un conjunto de datos para el testeo. Tiene que ver con este tema del size ¿Y por qué acá uso este sample Y no uso ese otro, por ejemplo? Vale, porque a mí me gusta más esta Simplemente por eso O sea, al final Cada maestrillo tiene su librillo Y cada uno utilizamos una función u otra R tenéis muchas cosas De hacer las cosas de manera completamente O sea, de distinta forma Pero que al final el resultado es el mismo ¿Vale? También está bien que veáis distintas formas Porque os acostumbraréis más a una u otra A la que mejor os funciona a vosotros y será la que utilices. O sea que si yo utilizar, en vez de índice, como hicimos en tu clase, que pusiamos train index y le pusimos con este create data partition. Exacto. Y la columna de los datos y el p, bueno, acá es size, pero el otro era p, 0.70 o 0.80, es lo mismo. Igual, es lo mismo. ¿Me va a dar exactamente lo mismo o me va a dar algo distinto? Te va a dar algo distinto porque probablemente no te seleccione exactamente las mismas filas. sí, la misma cantidad de filas, pero no exactamente las mismas filas, porque hay un componente aleatorio, ¿vale? Pero podéis utilizar las dos cosas. Las dos cosas son válidas, las dos cosas al final te dan lo mismo. Esto simplemente porque hoy me ha dado más, bueno, cuando estaba haciendo esto, venía de una clase de Python y en Python es 3T de speed y lo haces con la x y y y lo tienes bien un grámetro de size. Como estaba con el size y todo, pues tiré más hasta vertiente, pero bueno, las dos las podéis utilizar, dan lo mismo y el resultado es correcto, ¿vale? O sea que no... Siempre tengo que poner el setSeed antes Es para que siempre te dé el mismo resultado, ¿no? Que cuando ejecutes te vaya haciendo como cosas completamente diferentes ¿vale? Ah, ok Y también para garantizar el tema de el random Vale, Sergio, he visto que has respondido muchísimas gracias también Y luego, entonces la variable va en negativo ¿vale? ¿Por qué? Porque si nosotros hemos seleccionando estas filas para el entrenamiento, esas filas no pueden ser para el testeo, tenemos que seleccionar el resto de filas y recordemos que igual que cuando hacíamos el select y le poníamos el menos, estábamos quitándolas, pues aquí lo mismo, le ponemos el menos a este índice y estamos quitando esas filas. Seleccionamos todas las columnas porque aquí no estoy especificando ninguna columna en específico. ¿Sí, Paulina? ¿Te he resuelto la duda? Sí, gracias, Rafael. Una cosita. El 0.8, o sea, corresponden los datos de entrenamiento, entonces, o sea, se utiliza una mayor cantidad para el entrenamiento antes que para el testeo. Exacto, porque tú creas el modelo con la mayor cantidad de datos posible, por ejemplo, imagínate el caso de un niño que lo estás enseñando a leer, tú le vas a dar muchos ejemplos de cómo se lee y luego tú le dejas solo al niño y ¿qué haces? Pues le pones a lo mejor una frase corta que mezcle varias cosas para ver si ha funcionado. pues esto es lo mismo, tú creas el modelo con la gran mayoría de los datos y luego te reservas un cachito pequeño para poder saber si ha sido correcto o no ha sido correcto. ¿Sí? ¿Se entiende? Sí, he entendido, gracias, profe. Exacto, perfecto. Efectivamente, Alejandro. Vale, sí que os aconsejo hacer dimensiones, ¿vale? Si nosotros hiciésemos la suma de una más otra, me tendría que dar esta, ¿vale? Esto es simplemente una comproción, porque a veces ocurre, sobre todo en Python, cuando descomponemos que hay que poner un orden muy concreto y hay gente que cambia el nombre y entonces no es correcto. ¿Cómo hacemos la regresión lineal? Utilizamos la palabra LM, la variable que yo quiero predecir, en este caso he seleccionado la lluvia, es la variable de la cual yo quiero tener el conjunto de la predicción, en vez de que empece al resto de las columnas. Aquí si lo hemos descompuesto en entrenamiento y testeo, pues nuestros datos solo pondremos entrenamiento. Si estamos trabajando con todo el conjunto de los datos y no hemos descompuesto en este entrenamiento y testeo, pues aquí será todo el conjunto de los datos. Bueno, nosotros lo ejecutamos y después lo analizamos. Pero en este análisis, varias cosas a interpretar. La primera, los coeficientes. Bueno, esto lo que me está diciendo es que es una reducción lineal, no es más que una recta. Nosotros lo que estamos diciendo es que la temperatura... Creo que he escrito por aquí abajo. Vale, efectivamente. Estamos diciendo que el rainfall, es decir, la cantidad de lluvia, ¿qué será? Será un determinado término que no tiene absolutamente nada, es decir, un término que se llama término impendente generalmente para ajuste, que es el intercept. Este sería el término independiente. Creo que esta era otra completa en el diferente que os hice. Tengo que revisarlo. Siguiente. Esto es lo que os digo, que al hacer la regresión me ha dado dos valores diferentes. Lo hacemos ahora en por real. Este de aquí. Aquí tendríamos que sería este valor. menos 3,75 creo que era, después ¿qué haríamos? La temperatura mínima, ¿qué ocurre? Pues entonces seleccionaríamos el coeficiente en la columna de estimado de la temperatura mínima, en este caso 0,27, pues aquí estamos diciendo que sería más 0,27, esto es que depende de cómo lo hice en su momento, pues hay unos valores u otros. Ah, que le cambié, gracias, gracias Era un dos, porque ya me resultaba raro que fuese tan diferente Entonces, gracias Entonces, si lo ejecutamos Hacemos el summary Bueno, así un poco rápido Vamos con un poco más salido, algo aplicando también El tema es que cogemos uno de los coeficientes estimados y lo que va haciendo es multiplicando a cada una de estas variables. Importantísimo, si os preguntan cómo afecta tal variable o qué ocurre si aumentamos en uno la variable mínimo de temperatura y dejamos el resto igual. Pues qué ocurre si aumenta en un grado la variable mínimo de temperatura y el resto está igual. que sumaremos 0,27 por 1 más. Entonces, aquí tenedlo en cuenta que lo que nos permite saber es cuánto afecta, pues si aumenta o no la temperatura, la probabilidad de que llueva o la cantidad de lluvia sería con 27 más. Aquí otra cosa que sí que os pregunten que es el tema de si son significativas o no son significativas. Para saber eso, lo que tenemos que tener en cuenta son los códigos de significancia y esta columna de aquí. 1,27. El coeficiente es 0,27, así que tú harías más 0,27 por la temperatura mínima. En este caso, 0,27 por la temperatura mínima, pero si aumentamos en 1... vamos a hacerlo un momento porque creo que es un poco probable pero que entenderéis para todas a ver si me vamos a la pantalla entiendo que sí la lluvia hemos toque imaginemos que tenemos un caso que se hace más que tendríamos que sería hola hola hola hola hola ¿Profes que se escucha intermitente? Ahora no se escucha nada, profe. No, profe, nada, no se escucha. Haga pruebas unido, profe. O puede ser incluso que el Zoom haya escogido tal micrófono. No, profe. No, todavía no se te escucha. Inclusive en la pantalla aparece el micrófono desactivado. Vale, creo que ya. Puede ser, es que estaba haciendo pruebas de mi tecnología. Ahora sí que funciona. Vale, pues lo que está diciendo, imaginemos que estás a 25 grados. ¿Vale? De acuerdo. Entonces, ¿qué ocurre? Yo el sumo 1 a este 25. Pues tendré lo que era más 0.7. Vale. ¿Qué veo? Vale, tenemos la lluvia, que era R, que era un número que era el intercept, que no tenía absolutamente nada, más el estimate, el valor que está en el estimate. ¿Se te cortó otra vez? Sí, profe. Se escuchó intermitente. Vale. Si vamos aquí, ¿me escucháis bien? ¿Os lo explico aquí? Sí. ¿Es peor? Vale, perfecto. Pues vamos a hacer una cosa. Rofe, abrite un script. Ahí va, abrite un script blanco y lo escribís en la pantalla. Así te queda más fácil. Porque creo que el tema es cuando habéis visto el programa. Sí, y si lo pongo así, así lo veis bien. Aquí sí, ¿no? Y vale, perfecto. Sí, porque quería haceroslo de otra forma y luego he pensado que tenía esta. Vale, entonces tenemos el conjunto de la lluvia, que es un término sin nada, que es el intercepto. 0,23 es el estimado por la temperatura mínima a el estimado que sea por la segunda variable, más el estimado que sea por la tercera variable. Así toda la columna que tenemos de estimate. ¿Qué ocurre cuando yo le aumento en 1 la temperatura mínima? Es decir, ahora estoy diciendo, imaginemos que tengamos un caso concreto. Yo diría que sí. Un caso concreto es el número que tengamos aquí, más 0,27 por, en este caso estamos con la temperatura que es 25, más el resto de variables con sus valores y sus estimates. ¿Qué ocurre cuando yo aquí aumento en 1? Si yo aumento en 1, yo estoy diciendo que es algo así, 0,27 por, aquí tendríamos igual, y eso se mantendría igual, y se mantendría igual. Ahora, por la propiedad distributiva de la multiplicación, este 0,27 multiplica aquí y este 0,27 multiplica aquí también. Entonces, ¿qué tendremos? Tendremos que se mantiene igual 0,27 por 25 más 0,27 más esto que se mantiene igual. ¿Sí? Pero, ¿qué tenemos aquí? Fijaros. Esto que se mantiene igual en todos los casos, con esto que mantiene igual en todos los casos, y el 0,25, era justo lo que yo ya sabía que era 100. Por lo tanto, esto es 100 más 0,27. ¿Cuánto he incrementado cuando he incrementado en 1 la temperatura? Esto es 0,27. Se ha entendido más o menos. Esa explicación... Entonces, si se aumentase por 2 en vez de en 2 grados, en vez de en 1, sería 100 más 0,27 por 2. Exacto. ¿Y cuánto ha aumentado? Si yo te pregunto cuánto ha aumentado, te estoy preguntando esos 0,27 por 2, que son 0,54. Si yo te pregunto cuál es la temperatura, sería 154. Cuidado con la pregunta que os hagan porque la respuesta es diferente. 100 con 54, ¿no? O 100 con 27, no 154, ¿no? Eso, con coma. Exactamente. O sea, casi digo para asegurarme, ¿vale? No, no, ahí, ahí, ahí. Ahí, perfecto, ¿vale? Pero cuidado con la pregunta. Leed muy bien las preguntas. Eso sí que os lo voy a pedir, ¿vale? De acuerdo, entonces, más... Vale, veo que tengo aquí chat. Bueno, vuestro propio R es una calculadora. Es decir, si vosotros queréis hacer aquí 2 por 5 en la terminal ahí tenéis el 10 ¿vale? o sea que realmente cuando tenéis R tenéis realmente una calculadora ¿vale? todo lo que queráis hacer, las potencias si alguien quiere hacerlo son con dos asteriscos ¿vale? luego tienes la suma normal la resta normal la multiplicación un asterisco, la división una barra ¿vale? la raíz cuadrada que no las tenéis que hacer se puede poner exponente fraccionario accionario, pero bueno, esto no lo tendréis que hacer, o sea que tranquilidad por esta parte siguiente, tema de los errores, de acuerdo, aquí teníamos lo voy a poner ya con esto aquí ha cambiado, pero bueno, sería más o menos lo mismo, ¿vale? ¿qué ocurriría? aquí nos ha dado el R cuadrado múltiple, nos ha dado un 0,151 bueno, aquí cuando lo hemos vuelto a ejecutar un 0,0967 ¿qué querría decir esto? que solo me explica un 9,7% de la variabilidad en precipitación modelo bastante malo si vais al ajustado nos indica lo mismo, efectivamente es un modelo bastante malo porque solo te está explicando un 97% de los casos que son correctos aquí tenéis también el estadístico que en principio no hace falta comentarlo y algo que es importante es el tema de si son significativas o no, que esto me lo preguntó mi grupo, que sé que le gustó bastante así que os lo voy a contar se compara siempre con 0,05 salvo que en un programa nos diga lo contrario entonces por ejemplo en este caso 0,221999 que es la columna probabilidad mayor que no tenemos ninguna estrellita por lo tanto lo paramos con 0,05 lo vendrá por aquí y como el valor era 0,22 es mayor que 0,05 pues no podemos considerar que sea significativa podemos decir perfectamente que no es significativa si fuese menor que 0,05 sería significativa. El modelo nos indica el tema de las tres estrellitas, por eso estaría indicando que compara con 0, que compara con 0,01, que compara con 0,1, pero el proceso es el mismo. Si es mayor que esa cantidad no es significativa, si es menor que esa cantidad sí que sería significativa. vale, sí, truco en Python al menos funciona vale, aquí no, vale, que es elevado a la menos 10, no sé si os he puesto aquí una nota, juraría que sí juraría que sí bueno, creo que en algún punto que es 2 elevado a la menos 16 esto significa 2 por 10 elevado a la menos 16 ahora explico de nuevo los asteriscos 2 por 10 elevado a la menos 16 es decir es 0,16 ceros y luego un 2 a la práctica es lo mismo que 0 ¿cómo hacemos la notación científica? si yo tengo 2 en amarillo creo que no se ve muy bien así que os lo voy a poner en rojo 2L5 ¿qué quiere decir? vamos a ponerlo con decimales que quizá es lo peor, quiere decir 2 con 1, ¿vale? Quiere decir esto es 2 con 1 por 10 elevado a 5. ¿Qué quiere decir es 10 elevado a 5? Que movemos la coma 5 posiciones. 1, 2, 3, 4, 5, ¿vale? Entonces sería 1, 2, 3, 4, 5. Sería el resultado. Entonces el elevado a 5 no es más que por 10 elevado al número que tengáis. De la misma forma, si yo, por ejemplo, 3, para que veáis uno sin coma, 3 elevado a la menos 4. ¿Qué estoy diciendo? Que muevo la coma. ¿Pero hacia dónde? Hacia el lado contrario, ¿vale? Hacemos la coma estaría aquí, porque 3 es lo mismo que 3,0, así que damos 1, 2, 3, 4. La coma se mueve aquí, relleno con 0. ¿Vale? Queda claro el tema de la notación científica. Si lo veis es notación científica, es lo que en R se estudia con E en vez de con 10 elevado a lo que sea. Vale, entonces, continuemos. Vamos a esperar arriba un momento. Aquí ves que tienes, María, que tienes una serie de asteriscos. Entonces, de normal, cuando tienes asteriscos, lo comparas con 0,05. Por norma general, salvo R, que sí que te lo da con estos asteriscos, si tú trabajas en Python o trabajas en cualquier otro idioma o lenguaje de programación, generalmente siempre lo compara con 0,05. Y cuando estudias estadísticas siempre se compara con 0,05 a menos que lo diga lo contrario. Entonces, si tu valor del estimado, en este caso 0,22, es mayor que el 0,05 cuando no hay asterisco, ¿qué quiere decir? Quiere decir que no es significativa. Si tu valor es menor que el 0,05 entonces tu variable sí que sería significativa. ¿Qué ocurre? Que hay excepciones, pero no excepciones en el sentido de que cambiamos lo de mayor o menor, no, excepciones en el sentido que cojamos 0,05 o cojamos 0,001, 0,1 y esto te lo indica aquí. El número de asteriscos te indica cuál es el valor con el cual tienes que comparar. ¿Se entiende mejor? O sea, en vez de 0,05 harías el mayor o menor con 0,001 o una cosa de estas. Pero, por ejemplo, en cualquiera de los casos de los tres asteriscos, en teoría lo estás comparando con cero, ¿no? PR lo comparas con cero. Entonces, ¿es mayor que cero? Entonces, ¿es significativo? porque fíjate que tienes aquí un menos, un menor, ¿vale? Y al tener un menor, esto quiere decir... Vale, en un ordenador no suele haber un cero rotundo, cero rotundo, cero rotundo, ¿vale? Cada lenguaje de programación tiene su cero, ¿vale? Por ejemplo, si te vas a Python, no creo que no eran 16 cifras, 16, sino que creo que eran 23. Pero bueno, cada uno tiene su cero, su número a partir del cual podemos considerar que es cero, ¿vale? En este caso, fíjate que en la mayoría de los casos con menos 12, menos 11, sí que me ha dado el valor, menos 7 me ha dado un valor, ¿vale? Y aquí directamente no me ha dado un valor, sino que me ha dicho, es menor que esto, ¿vale? Entonces, básicamente que es cero y nosotros estamos comparando que sea estrictamente mayor. Entonces, sí sería significativo en esos casos, ¿no? Sí, exactamente. ¿Puedo subir un momento otra vez, por favor? Sí, claro. Por ejemplo, en el caso justo más arriba de 0.22. Este de aquí. El 0 más 0, 0, 0, 20, 203. Eso es. Ahí no sería significativo, ¿no? Porque ha dado un valor y es mayor. Vale. Dame un momento. ¿Qué es un valor aproximado a 0? Este, este y este. Aquí un momento que tendría que pensarlo. sí, debería ser mayor, por tanto no sería significativo al igual que en ese otro sería una rata sí, es una rata porque he contado uno de menos sí, todo lo que sea menor que 0,05 es significativo efectivamente porque es lo que más me ponga, pero si lo analizáis tal como tiene R con los asteriscos lo compara con otro pero sí, en efecto es que os lo he comparado con esto de aquí porque me he confundido de asteriscos tendría que haberte lo comparado con este dime y por ejemplo igual en el caso de 0.005.379 que tiene dos asteriscos sí sería con este 0.001 os lo he comparado con el anterior vale, o sea me he confundido de orden, he pensado que esto era este este era este y este era este pero no, efectivamente lo que comentas en ese caso sería no significativo ¿no? Sí, sería no significativo efectivamente. Entonces no significa prácticamente nada, nada, ¿no? Sí, es que el modelo sí, es normal, el modelo es muy malo, o sea, cuando hagáis vuestros modelos nos pasarán estas cosas, ¿vale? Pero... Y tengo otra pregunta más, es que esto me trae por el camino de la amargura. No, no, tranquila, tranquila, dime, dime. ¿Qué significa esto? ¿Esto es que es una variable importante? o no lo es, el que sea significativo vale, esto lo que vendría haciendo es que en principio no afecta tanto al modelo es decir, que podrías hacer el modelo sin esa variable a pesar de que tú puedas tener un valor que es lo que te suma o te baje lo que te puede decir es que son variables que en principio no tienen tanta importancia de cara al modelo es un concepto un poco más complicado y implica, todo esto tiene que ver con tema de control de hipótesis, de si son variables que se pueden quitar o no quitar. Sería un tema entero de estadística, pero bueno, para que te hagas una idea puedes considerarlo como que no son tan importantes. Nos van a preguntar si son significativas o no significativas. Vale, sería por así decirlo, te lo estoy preguntando sobre todo por, a ver, por entender la parte por la actividad 2. No, tranquila, tranquila. sería algo semejante como en el árbol el apartado que viene de importancia variables o algo así que te sea un apartado de importancia de la variable vale, sería algo más parecido algo que no hemos visto del árbol que son los Gini, más parecido a la pureza de cada uno de los nodos, pero sí, lo puedes interpretar así ¿vale? tened en cuenta que si se os preguntan por tema de cuánto impacta, ¿vale? cuánto impacta si la pregunta va cuánto impacta es más coeficiente, ¿vale? Si os preguntan significativos, lo van a preguntar por esa palabra, ¿vale? No os van a preguntar por otra cosa rara, os preguntarán ¿qué variables son o no son significativas? ¿Vale? Esa va a ser la palabra. Entonces, muy importante que cuando lo argumentéis digáis con qué valor lo estáis comparando, ¿vale? Porque si os habéis equivocado en lo que me ha pasado a mí, que he contado mal los asteriscos y he puesto que son con 0,01 o con 0, bueno, eso no es grave, el tema es que tengáis que sea mayor no significativo, que sea menor significativo, ¿me explico? o sea que si os confundís y lo hacéis con uno o con otro no pasa nada ahora miramos por el tema de la actividad dos, porque yo se lo aconsejé a mi grupo por una cosa, ¿vale? que era mejor la actividad hacerlo con árbol de decisión y bueno vas a hablar también sobre la especificidad vas a hablar sobre eso efectivamente, ya os he dicho que la clase de hoy, quien no pueda pues que siempre tendré la grabación pero sé que creo que quiero que quede más o menos claro todo ¿vale? entonces aunque tardemos un poquito más os quiero repasar todo más o menos y todo el tema de las preguntas que podáis tener pues poder solucionarla ¿vale? entonces la parte de crear el modelo, lo hemos realizado hemos estado comentándolo y en realidad tenemos la predicción ¿vale? aquí tenemos que lo predecimos con el modelo que hemos creado y tendríamos el tema de qué nuevos datos le introducimos, en este caso como hemos hecho el entrenamiento del testeo lo hacemos con el test, si no crearíamos un conjunto de valores como se hizo igual que la regresión logística con encontrar la probabilidad de Leonardo DiCaprio si no recuerdo mal, pues crearíais un conjunto de valores y lo haríais exactamente igual que la expresión en este caso solo se ha sacado un caso porque nos salían un montón de filas y se quedaba feísimo el pdf es el 0,28 vale como podemos evaluarlo existen estas métricas la métrica de error cuadrático medio la métrica de la raíz del error cuadrático mes a ver a ver a ver estoy con reducción lineal regresión logística va después si hoy probablemente sea bastante más de una hora no te preocupes vale, entonces regresión lineal ¿de acuerdo? entonces ¿dónde estábamos? tenemos aquí las estadísticas la raíz del error cuadrático medio el error absoluto medio ¿cómo lo compararía yo? yo aquí lo que haría también lo podéis hacer así o tenéis vuestras propias métricas ¿de acuerdo? que si hacéis un bueno, yo lo comparo normalmente con lo que sería el summary datos rainfall. Recordad que vamos a tener la métrica del R2, ¿de acuerdo? Para poder comparar, ¿de acuerdo? Que esto sí que sabemos que si es más cercano a 0 predice mal y si es más cercano a 1 predice bien, ¿vale? En este caso, pues, predicería bastante mal. Pero aquí, con mi grupo sí que lo vimos, el error cuadrático y el error cuadrático y la raíz cuadrada, ¿vale? Porque, ¿cómo puedo saber si este error cuadrático es mucho o es poco? quizá alguno de vosotros tenéis esta duda claro, yo para que culo esto lo que hago es compararlo con los datos que tenía de partida, fijaros que la media del dato que tenía de partida de la lluvia era 2,38, entonces si mi media es 2,38 que mi error si lo miramos con la raíz cuadrática que mi error en este caso sea 7,82 sobre 2,48, a mi me parece un error bastante, bastante malo ¿Por qué? Porque la media prácticamente es 2,82 y estoy diciendo que el error, o sea, me puedo equivocar en 7 puntos para arriba o 7 puntos para abajo cuando la media de todos los datos es 2,82. Entonces, bueno, esto es puesto aquí por si a alguien le interesa, ¿vale? ¿Cómo compararía? Dime. Perdón, esto que estás contando, o sea, esto sale en los descriptivos del sumari del modelo. Vale, esto como tal no lo tienes que calcular por fuera el cuadrático medio, ¿qué sería? Sería de las soluciones que tú conoces menos las predicciones, lo elevas al cuadrado y haces la media, es la media de la resta de los cuadrados Vale, no hay una función que te lo saque lo estás tú calculando Me imagino que sí, ¿vale? No, esto no entra en el examen, en el examen entra simplemente, esto es simplemente por vuestra curiosidad en el examen con que estáis analizando el R cuadrado, más que de sobra ¿vale, Cristina? que es lo que habíamos visto anteriormente Python sí que existe en R casi siempre la he calculado así pero probablemente exista probablemente exista una librería de funciones en la cual si tú pones minSquareR fijo que te sale y no tengas que calcularla a tu mano segurísimo seguro seguro dime ¿haces al cuadrado y lo otro la red cuadrada? sí Y SQRT es lo que se suele utilizar para raíz cuadrada. Es como square root, en inglés es SQRT, y lo abrevian en la SQ y el RT. Por eso te sale SQRT, tanto en Python como en estos idiomas. Esto es nada para la ciencia, pero lo importante es el examen. Saber clasificar, si os lo preguntan, que a lo mejor no os lo preguntan, saber interpretar el R-square. Luego para los logaritmos es más o menos lo mismo, lo único que poníamos aquí un logaritmo, a veces le poníamos un más uno para regular, que a veces no, no da un error, fijaros aquí me ha dado un error, me ha dicho que tengo un error en esta parte porque tengo algo singular, entonces para que no nos diese ese error cuando trabajamos con logaritmos antes es con cada, a veces le ponemos un más uno. ¿Por qué? Porque sumarle 1 en un logaritmo en base a 10 es prácticamente nada. Efectivamente es porque intercepto 0 o algo así, efectivamente, no quería entrar en tanto. Cuando hacemos este caso, lo único diferente es que los coeficientes no los vais a analizar como tal, sino que tenéis que elevarlos al exponencial para poder saber cuál es el porcentaje. Eso es simplemente que es el cambio por porcentaje. Dicho esto, vamos al tema de la clasificación, que aquí es donde veremos sensibilidad, sensitividad y todas estas cosas. En este caso de la clasificación tenemos dos casuísticas, regresión logística, árbol de decisión, regresión logística, predecimos dos clases, 0, 1, árbol de decisión, sirve para todos los casos. Entonces, en el caso de la versión logística, lo mismo, en este caso vamos a utilizar el mismo punto de datos, vamos a hacer un NA omit datos, es decir, vamos a omitir los valores nulos y importante, muy importante, vamos a crear una columna que es la columna llueve hoy que se basa en si el rain today es un sí o es otro valor. En el caso de que nos digan que rain today es sí, lo que hacemos es en esta nueva columna ponemos el valor 1 y en caso contrario ponemos el valor 0. Me cansaré de repetirlo, esta parte es muy importante. Entonces aquí nosotros tenemos una nueva columna, fijaros que se llama llueve hoy y en esta columna tenemos ceros o unos en función de si rain today es sí o no. También si sabes esa función te sirve. ¿Vale? También No, no, no, ojo, aunque sea más fácil Aprendedlo con Con crear columna nueva No puedo decir mucho más Alejandra Pero aprendedlo con crear columna nueva, por favor ¿Vale? Entonces, si fuese Sí, pues, ojo, cuidado Si el sí es con acento o el sí es sin acento ¿Vale? O si el sí es en mayúsculas O es en minúsculas Por favor, mirad bien esa parte ¿Vale? En este caso es en inglés En la primera con mayúsculas ¿de acuerdo? entonces una vez que lo creemos ¿cómo hacemos la regresión logística? pues lo mismo lo que vamos a hacer es seleccionar los datos aquí yo he seleccionado los datos por los mismos que teníamos en la anterior ocasión, lo que pasa es que añado la columna del lleve hoy y quito muy importante también ojo cuidado, si yo he creado una columna si he creado una columna 1, 0 en función de otra columna en este caso Rain Today para el modelo no me añadáis la columna Rain Today porque ¿qué va a hacer el modelo? va a decir ostras, pues siempre que en Rain Today es no llueve es cero, y siempre que Rain Today es yes, llueve es uno, pues el modelo es fácil, llueve hoy es lo mismo que Rain Today ¿vale? así que ¿de acuerdo? si seleccionáis las numéricas nunca os va a pasar esto ¿vale? pero por favor, si a alguien le gusta pasarlo a factor o hacerlo de este tipo, ¿de acuerdo? Aseguraros que si creéis una nueva columna no pongáis la columna de la cual lo habéis creado, por favor ¿vale? Porque luego el modelo os va a dar mal, es poco ¿vale? Porque básicamente el modelo va a decir, pero no tiene sentido que haga una relación logística si es tan fácil como decir que es la misma columna, ¿vale? Suele pasar, porque es la típica cosa que no nos damos cuenta, así que por favor asegurados, ¿de acuerdo? De no poner el ring today Pasar a factor es, si tú tienes un texto, aquí hubiésemos podido pasar perfectamente a factor. Aquí te vamos a haber dicho que esta columna Read Today, que es una columna de tipo texto, me la considerase como un factor. Un factor es que sigo manteniendo la palabra no y la palabra sí, pero internamente yo les doy un código. Yo digo que la palabra no internamente es cero y la palabra sí internamente es uno. y en esa columna no podría tener, por ejemplo, una palabra quizás, no la puedo tener porque por factor estoy diciendo que solo hay dos posibilidades, ¿vale? Efectivamente lo mejor es pasar todos los textos a factor, ¿de acuerdo? Pero, vuelvo a repetir, aprended a crear una variable con if-else, ¿vale? Los números nunca te van a dar problemas, lo que siempre te da problemas son los textos, ¿vale? Los números no te van a dar problemas, ¿vale? No puedo decirlo más alto y más claro, ¿vale? Aunque es cierto que se puede pasar los números a los textos a factor, ¿de acuerdo? Para el caso de la regresión logística, ¿vale? Es probable que tengáis que crear una variable, ¿de acuerdo? las fechas si no os compliquéis con las fechas salvo que sea una serie temporal que lo repasaremos ¿vale? pero por favor si os piden crear una variable ¿vale? crear una columna es crear una columna hacemos el if-else con eso si no os piden crear ninguna columna podéis utilizarlo como as-factor ¿vale? pero si os piden crear una columna por favor hacedlo con el if-else bueno o con cualquier otra forma pero crear la columna con ceros y unos, columna nueva ¿si? ¿se entiende? más claro creo que no lo puedo decir así que por favor aprenderos ese amparo una cosita el as factor también también lee cuando es sí, no o quizás sí, lo que te diría es que tienes tres posibles valores que son sí, no y quizás pero si se lo das desde el inicio lo que no puedes hacer es escribir un as factor como sí, no y luego intentar añadirlo en quizás porque entonces te va a decir, oye, no, no, solo puedo tener sí y no. Si tú desde el inicio sabes que tienes sí y no quizás y lo pasas con sí y no quizás, entonces no vas a tener problema. Respondiendo a la pregunta de Paulina. ¿Qué pasa en la tabla de los textos no mantienen formato? Vale, buena pregunta, ¿vale? No os va a pasar en el examen, ya os lo aviso, ¿vale? Si creo o al menos en los que yo considero no, ¿vale? tenéis la opción de hacer el porcentaje en porcentaje si no recuerdo mal y añadir aquí que esté en sí por ejemplo en sí y en sí por ejemplo y hacer pues en este caso sería que rain today estuviese en esto, o sea en lugar de poner un igual igual la puedes tener rain today que esté en esto ¿se ha entendido Paulina? lo que pasa que no te va a tocar, o sea no somos tan exigentes, ¿de acuerdo? En principio el formato va a ser correcto pero si en algún momento te incurres esto lo que hace es decir, si el valor que está aquí está en alguna de las soluciones que tú pones aquí Ya, gracias, gracias Trojo, entonces ahí incluiría todas las soluciones de formato que se den más bien Exactamente, ¿vale? Exacto Perfecto, gracias Nada, es una columna 0 y 1 al reconocer de por sí como un factor de valor 0, 1, si la pones como una columna aparte, sí, pero es importante que tenga eso, una columna aparte por favor, ¿vale? de todas formas, si no recuerdo mal, comprar cuando haces un factor, lo que se hace es daros una columna que se sigue viendo el texto, aunque tú internamente tengas los números pero lo que se sigue viendo es el texto, pensad que lo que van a hacer es, si os aparece esta pregunta, corregiros porque tengáis una columna que lo que se vea sea 0 y 1, no el texto ¿me explico, Cristina? pero si en el dataset siempre he hecho con el ifelse, por eso tengo que comprobar y lo comento ahora dime yo lo que me refiero es que si en el dataset directamente tienes una columna de por ejemplo sobrevivir o morir, que ya viene directamente puesta como 0 y 1 que si eso ya lo reconoces por si como factor o hay que poner as factor aunque ya tengas 0 y 1? Porque no lo reconoce como factor. No, si tienes, vale, si tienes 0 y 1, te había entendido mal la pregunta. Si tienes 0 y 1, ya lo dejas como 0 y 1. Nos vamos a hacer cambiar una que ya es 0 y 1, ¿vale? Claro, entonces R ya lo reconoce directamente. Como número. Sí, es número directamente. O sea, los números no os preocupéis. Las columnas que sean números, preocuparos 0, ¿vale? El as factor son para columnas que son texto. ¿Vale? Entonces texto, el texto puedes tener distintas, distintas opciones. Entonces tú con el as factor lo que hace es entre comillas darles internamente un número, ¿vale? pero las factor es para columnas de texto no para columnas, y ahora me habéis creado la duda ¿vale? dadme 5 segundos es que a nosotros en los en el de aguacates nos salía como que teníamos que cambiar solo una variable que era integer los números y todo lo demás no, no, o sea, cambiarlo me refiero ponerlo como as factor Vale, ojo, ojo, en la matriz de confusión Sí Sí, ahí vamos después No te preocupes Sí, sí, en la matriz de confusión sí Lo cambiaremos, el resultado 0 y 1 A las factor en las dos ocasiones ¿Vale? Sí, sí, sí Pero ahora mismo estamos en la parte de Antes de toda la relación logística Crear la columna, ¿vale? Luego vayamos ya a esa parte O sea, tú harás la relación de forma normal Y luego ya lo miramos, ¿vale? Vale, creamos la columna a if-else, ¿vale? Con datos r2d igual a yes, esto lo hemos hecho, y ahora vamos a la parte, seleccionamos las columnas que hemos hecho, entonces es lo mismo, dividimos entre data-70, exactly lo mismo, y el modelo lo único es que ponemos aquí glm y la familia binomial, porque tenemos solo dos posibilidades, ¿de acuerdo? De hecho, si no ponéis este familiar binomial, no es exactamente una red de logística, sino que es gaussiana, si no recuerdo mal. ¿Vale? Pero bueno, ¿lo creéis? Y teníamos el sumario. Ah, mira, aquí tenéis la nota científica. Y sabía que en algún punto lo había puesto. Bueno, aquí ya me estoy diciendo que el algoritmo no ha ido bien, ¿vale? Que no ha convergido. De todas formas, nos va a dar un resultado y nos va a dar una posibilidad de predicción. Pensad que estamos intentando predecir la temperatura y el tiempo y es algo que es completamente aleatorio, ¿vale? A vosotros es muy probable que este aviso no salga. Pero aunque os salga este aviso, no os preocupéis porque el resto, si es cierto que el método no es el mejor, porque no ha encontrado una solución, pero el resultado te lo va a dar igual. Aquí volvemos a tener todo el tema de las probabilidades, en este caso de la significancia, aquí como no tenemos ningún asterisco ni ninguna leyenda, se pararía con 0,05. Como vemos, ninguna es significativa, ¿de acuerdo? Es normal, es un modelo bastante, bastante malo. Y aquí tendríamos los coeficientes, ¿vale? Los coeficientes pues los elevaríamos a 10, ¿de acuerdo? aquí os he explicado un poco y todo es mayor que 0,05 por lo que ninguna variable es significativa ¿vale? los coeficientes sobre todo se interpreta el signo que es como de probar este modelo efectivamente, no, no, no perfecto Alejandro, exactamente ¿vale? aquí el tema es, aquí lo tengo por ejemplo con un coeficiente ¿vale? tenías este coeficiente, le vas a la exponencial y lo que dices básicamente que no estás prediciendo el valor sino la probabilidad de que ocurra ¿vale? dudo que os entre ¿de acuerdo? sobre todo, muy importante el tema de las probabilidades de significante y no sé si son significativas o no son significativas pero no creo que os pregunte nada más, lo que os pueden preguntar es que calquéis luego vosotros una probabilidad ¿vale? entonces esto lo habéis hecho vosotros purísimo con el tema de Leonardo DiCaprio, lo habréis visto en clase ¿vale? en el caso de que lo hayáis hecho con entrenamiento y testeo pues lo que haríamos sería el new data igual a test y el tipo de respuesta ¿vale? esto os va a dar bueno, lo ejecuto todo para que lo veáis ¿vale? bueno, voy a ejecutar esto primero para que lo veáis primero es que cuando predico no sale valores entre 0 y 1. ¿Por qué? Porque lo que predigo es la probabilidad. ¿De acuerdo? Entonces, por eso aquí añadí una nueva frase que es si la probabilidad es mayor que 0,5, dame 1. Y si la probabilidad es menor que 0,5, dame 0. ¿Por qué? Porque si es mayor de 0,5, tiramos a que en efecto va a ser un positivo y si es menor, tiramos a que es el valor 0. lo podemos hacer de nuevo con el delay y lo que estamos comprobando son estas probabilidades en una variable que ya es o 0 o 1 de forma que la podremos comparar con lo que yo sabía si era 0 y 1 para la matriz de confusión la matriz de confusión la podéis hacer así o ahora os enseño la otra forma así la tenéis de una manera muy normal pero si os aconsejo hacerla de esta forma sí, exacto la matriz de confusión solo, solo, solo, solo, solo para clasificación y aquí de momento habéis visto lo que es regresión logística y lo que es árbol de decisión ¿vale? esa es la matriz de confusión métricas como la regresión tendréis el R cuadrado tenéis el mean square error el mean absolute error como métricas y la clasificación, aunque no lo hemos visto y no es centra, tiene sus propias métricas, que no son la matriz de confusión ni las de la regresión. ¿Sí? ¿Se entiende? Yo creo que sí. ¿K o O? Porque según donde pongas la K, la respuesta es muy diferente. Si es K, repíteme K de nuevo. Vale, perfecto, gracias. Vale, entonces, lo que dice hacer así la matriz de confusión, Ahora no os lo aconsejo, ¿por qué? Porque si lo hacéis así tenéis que calcular vosotros todas las métricas que van asociadas a la medida de cohesión, ¿vale? Entonces, hay un paquete que es caret, ¿de acuerdo? Y aquí sí, aquí sí que tenemos que pasarlo a factor, ¿por qué? Porque tenemos que decir que solo hay dos posibles valores, o el valor 0 o el valor 1. los códigos entre comillas internos o los valores entre comillas internos que toma la variable factor se llama levels, ¿vale? y luego tendríamos los números entonces aquí lo que estamos entre comillas diciendo es, considerame 0 y 1 como texto, pero que solo pueda ser estas dos opciones, para el caso de la matriz de confusión, ¿vale? porque categorías en sí deberían ser textos, lo que hacemos el finoto como actor esto lo que hemos prevencido como lo crean en este tema entonces aquí tendríamos las métricas, importantísimo saber analizar vale, levels es creo que si os saco una que sea que sea eso lo vais a entender mucho mejor vale, a ver, una que sea teórica, vale, por ejemplo esta Windir Windir 3pm para que veáis un poco lo que es Levels un momento, estábamos aquí antes de esto no necesitáis saber lo que es Levels lo estoy explicando más que nada para que os quede todo como mucho más claro pero no, no, no, pero te lo explico no, no es necesario ahora pero tranquilo tranquilo, tranquilo, mira si es muy fácil, lo vais a entender enseguida en cuanto lo explique a ver lo que os preocupéis para el examen que no lo necesitáis saber vale, un momento aquí lo tengo vale, porque me ha faltado poner de qué dataset es un momento, le he puesto texto tengo que ponerlo como datos si no recuerdo mal, la columna unir3pm, vale, perfecto vale, cuando nosotros nos esto aquí lo que nos va diciendo es un poco simplemente para los valores, parece que no ha ocurrido pero fijaros el tema de layers ¿qué son los levels? son las opciones únicas que puede tomar esa variable, ¿vale? luego es cierto que nosotros si hacemos lo que un str para ver qué tipo de variable es ¿vale? tendremos que es una variable con 16 los niveles son cada uno de las posibles opciones que tengamos y luego el código interno. Efectivamente, las categorías de la variable. ¿Se entiende? O sea, es el número de variables únicas. El nombre de las categorías únicas, sí. Es decir, como si tuvieses hecho la columna, hubieses quitado los duplicados y te hubieses quedado con los valores de esa columna. Sí. O sea, podéis preguntarme todo esto, pero sí quería que os quedara claro que no se va a preguntar por levels en el examen, o sea que todo lo que sea curiosidad también pregúntamelo, ¿vale? pero que no que no suene en el examen, eso me refería entonces nada, lo usamos a factor, le especificamos que solo puede tener dos niveles, o bien cero o bien uno, ¿vale? y sacamos la métrica, de la métrica importante, que son valores verdaderamente positivos, ¿vale? os voy a sacar de nuevo esto y os lo la gente que se tenga que ir, de verdad que sin problemas, ¿eh? que no pasa nada ¿vale? lo tendréis luego en la grabación este valor, ¿vale? que es o si es este 9 si consideramos que el 0 es positivo son los verdaderos positivos y podríais decirme, ¿vale? ¿y cómo sé yo si el 0 es positivo o el 0 es negativo? porque aquí abajo todo te dice cuál es la clase que el modelo ha considerado positiva, ¿vale? entonces, el modelo ha considerado positiva la clase 0, por lo tanto 8.779 casos son los verdaderos positivos, en los que el modelo en la realidad Fijaros, la referencia me ha dicho que es 0 y la predicción me ha dicho que es 0, es decir, el modelo ha acertado. Ha acertado, ¿vale? Y en positivo. Si nos vamos al caso de los 2.505, ¿qué serán los verdaderos negativos? Si lo veis en inglés, a veces nos aparece con el true positive o el true negative, es decir, los valores en los que es negativo y el modelo ha acertado con el valor real, ¿vale? Y luego tenemos este 0 y este 0, ¿qué pasa? Aquí dice que el modelo en realidad era 1 y me ha dicho que es 0. Es decir, en realidad era negativo y me ha dicho que es positivo. Aquí tendremos los falsos positivos. Y este modelo, este valor de aquí que se llama 1 y 0. Es decir, lo que estamos diciendo es que en realidad es un 0 y el modelo me lo he clasificado como un negativo. Luego tendremos falsos negativos. entonces esto sería importante que lo supieses distinguir que es verdadero positivo, falso negativo, verdadero negativo y falso positivo en caso de que os lo pregunten ¿qué más cosas podemos ver de aquí? bueno, el accuracy es de 1 sale demasiado bien para mi gusto pero bueno, el accuracy en principio es de 1 luego tendríamos el 95% de coeficiente esto es un coeficiente de seguridad no tenéis que saberlo, ¿vale? esta tampoco lo tenéis que saber y aquí lo importante es saber qué es la sensibilidad, qué es la especificidad y yo creo, bueno, la prevalencia también os la puedo enseñar, pero sobre todo sensitividad y especificidad, ¿vale? dame cinco segundos, ¿qué es la cura? vale, la cura sí es a norma general cuántas veces ha acertado nuestro modelo entre cuántas veces lo ha intentado ¿vale? es decir, ¿qué estamos diciendo? ¿Qué será? ¿Cuántas veces lo ha acertado? Lo ha acertado 8.779 más 2.505. ¿Entre qué? ¿Entre cuántas veces lo ha acertado? Pues será entre la suma de 8.779, 0, 0 y 2.505. Tenemos el dibujito en la pantalla Sí, en la parte de VP, TP, FP, VN Pero la precisión que es Vale, aquí cuidado ¿De acuerdo? Porque hay dos palabras que en inglés son distintas Pero en Vale, vale En español Son iguales Y es la precisión Entonces, cuando os preguntamos precisión, si nos preguntan nada más que precisión, suele referirse la cura, ¿de acuerdo? Pero, pero, hay otra métrica que se llama precisión per se, ¿de acuerdo? Pero creo que aquí, cuando se nota en precisión se refiere a la cura, ¿me explico? O sea, la cura sí es la precisión en inglés, lo que pasa que en la matriz de confusión hay dos métricas que se llaman las dos precisión. Lo que pasa que en inglés ahí no interviene nada lo de la especificidad y lo otro, la sensibilidad para decirla aquí no espera, espera no, no, pero tranquila, tranquila, ahora os voy a explicar la sensibilidad y la especificidad, pero si en el examen os preguntan por la precisión, ¿vale? es la precisión, punto ¿sí? eso me refiero, o sea, si en el examen nos dicen ¿cuál es la precisión del modelo? será la precisión, si en el examen se pregunta, ¿cuál es la sensitividad y especificidad? ¿Veis la sensitividad y la especificidad? ¿Me explico? Porque si no vais a querer explicar lo demás, ¿vale? Y puede ocurrir dos cosas. La primera, que os equivoquéis, que espero que no, y estoy segura de que no. Y la segunda, que os quedéis sin tiempo para resolver otros ejercicios u otras preguntas, ¿vale? Entonces, lo de Akurasi es la precisión. La precisión es Akurasi, sí. Vale, y es que yo tenía otra pregunta, porque había leído algo así como que cuando la cantidad de datos no es igual en el entrenamiento que en el test, como en este caso que es un 80-20, que es más importante la desbalanceada, lo que viene abajo. Importante, sí, pero no os lo vamos a pedir como tal en esta asignatura, si tienes toda la razón. ¿Qué ocurre? Pero vamos a pensarlo desde un punto de vista lógico. imagínate que tú quieres predecir si un niño va a ser si un bebé va a ser niño o niña y yo te doy todo un dataset de niños y te doy cuatro casos de niñas, ¿qué va a hacer el modelo? va a decir pues siempre son niños o casi siempre son niños, entonces te lo voy a predecir porque sea niño pero no necesariamente porque esté teniendo en cuenta las variables, sino simplemente porque siempre he visto niños, el modelo dice pues niño de nuevo por eso efectivamente cuando está desbalanceado que es el caso también de este dataset lo que se suele hacer es balancearlo existen técnicas de balanceo que no hemos entrado y que no vamos a entrar, ¿vale? pero si a alguien le interesa, pues por ejemplo esta la técnica de balanceo SMOKE, es la que más se suele utilizar, que genera datos ficticios para equilibrar el conjunto de datos que tengas ¿vale? o sea que sí, lo que has escuchado es cierto ¿vale? y en esos casos sí que veréis todo el tema del score de balanceo y empezaréis a analizar más estas métricas en profundidad, ¿de acuerdo? pero no para el momento en el que estamos ahora. No sé si me he explicado. O sea que tienes toda la razón, que efectivamente si está desbalanceado el modelo no es el mejor o te puede dar un resultado como este que parece que es demasiado bueno, pero en realidad no lo es. Exacto, es el acuracy, efectivamente. Si os preguntan por sensitividad y sensibilidad, entonces ya son estas métricas de aquí. Con el caso de sensitividad y especificidad os pondré un caso concreto que era el caso del test COVID. Ahora voy a eliminar esto, esperad un momento que lo elimine aquí. El test COVID, ¿recordáis el test COVID qué ocurría? ocurría que si el modelo te daba que no tenías el test COVID casi era bastante seguro de que no lo tenías pero sin embargo si me daba que era positivo había muchísimos falsos positivos había muchos casos en los que el test te decía tienes la enfermedad pero realmente a lo mejor era una gripe era un catarro, era otro tipo de cosa pero el modelo que pasaba entonces que era muy sensible a falsos positivos es decir, detectaba muchos falsos positivos, no detectaba bien el hecho de tener la enfermedad, pero era muy bueno descartando la enfermedad. Es decir, si te decía que no tenías el COVID, era muy probable que no lo tuvierais. ¿Sí? ¿Os acordáis de esto? Os lo comento porque creo que es la mejor. ¿El test COVID no se vio en clase? El de DiCaprio es el de Titanic, Alejandro. Sí, no, ahora os lo enseño. Cinco segundos para que lo veáis. En este caso sería que el modelo está sobreentrenado. Puede ser, pero lo que yo os quiero hablar de esto es más sencillo. Cuando nuestro modelo predice bien los casos positivos es la sensitividad. ¿De acuerdo? Es decir, si nuestro... o sensibilidad. No, sensibility en inglés. Espera, sensitivity en inglés, sensibilidad en español, perdón. ¿Vale? Entonces, ¿qué estamos diciendo? que en el caso del test COVID, que cuando me daba que estaba enferma había muchísimos falsos positivos, ¿qué ocurría? Que tenía una baja sensibilidad, una baja sensitivity. Predecía mal los casos positivos. ¿Qué ocurría con el test COVID y la especificidad? Que si yo sabía que era negativo, que no tenía la enfermedad, era muy probable que no lo tuviese. Es decir, detectaba muy bien el hecho de que una persona no estuviese enferma, que tenía una alta especificidad. creo que se entiende bastante mejor esto que diciendo es verdadero, es positivo, es falso, es positivo con el ejemplo de los test yo creo que nunca se os va a olvidar vale, el tema de los test sin problemas imagínate un test médico un test médico que te diga que si da negativo tú casi ya respiras tranquilo no tienes la enfermedad porque es un test muy fiable entonces si te da negativo sabes que no vas a tener la enfermedad ¿qué quiere decir esto? que tienes una alta especificidad predices muy bien los casos negativos con lo cual, si yo me hago el test y veo negativo pues digo, ah perfecto, todo está genial no tengo la enfermedad, ¿vale? alta especificidad, la especificidad mide cómo de bien predices lo negativo ¿vale? ahora bien, imagínate que me da positivo pero voy al médico, me hago todas las pruebas tal no sé qué y resulta que estoy sana ¿qué ocurre? que soy un falso positivo ¿qué pasaba en el test COVID? que había muchos falsos positivos. De hecho, muchas veces la gente se hacía dos y tres pruebas porque daba positivo con muchísima facilidad. Es decir, no predice del todo bien los casos positivos, que tiene una baja sensibilidad. ¿Se entiende, Alejandro? Sí, exacto. Son dos métricas diferentes, pero con el caso de los test médicos creo que es como más se queda en la cabeza pero esto haciendo el ejercicio algo de lo de las telecomunicaciones nosotros por ejemplo decíamos no sé si tiene relación decíamos vale cuando la especificidad es muy grande nos interesa sesgar el modelo y como que lo poníamos que detectara más falsos positivos que negativos Vale, sí, esto, a ver, luego evidentemente de todas estas métricas normalmente no te quedas solo con el resultado, luego tomas acciones, ¿vale? que es, o reduces el tamaño del entrenamiento o en el entrenamiento te das cuenta que está desbalanceado y empiezas a meter desbalanceados o introduces un sesgo para ver si es posible que mejoren estas métricas, sí, ¿vale? pero de momento al nivel que estamos nos quedamos en simplemente ser capaz de analizarlos si no es que el examen nos duraría horas así que nos quedamos en eso vale pensad que este número es porcentaje este número es porcentaje ¿de acuerdo? aquí quiere decir que aunque yo tenga el 1 esto quiere decir que el 100% entonces digo que este modelo también quería que os escribais este caso porque yo este modelo ya directamente pienso que no es el modelo adecuado que hay un sobreajuste que hay un desbalanceo de datos o algo es muy muy raro pero muy muy raro que la clase de uno y que las y que todas las que sean esto es prácticamente imposible ¿vale? eso es que dentro de los datos pues o habrá que desbalancearlos o habrá que hacer un smooth o el entrenamiento habrá que aumentarlo porque a lo mejor no está pillado ¿vale? pero lo que yo os quiero decir con esto ah ya sé por qué es porque creamos una nueva variable esperad creamos una nueva variable haciendo esto de crear ¿verdad? creamos una nueva variable ¿vale? ¿O no llegamos a crearla? Bueno, la cuestión, que si os da uno, tendríais que sospechar. En el examen, si os da uno, que nadie se apure, ¿vale? Es decir, que nadie se apure y que nadie le dé un microinfarto y que nadie diga, no me ha salido el examen y nos volvamos la mente en blanco. No, se corrige por planteamiento. Es decir, imaginemos que es por el caso que suele ser que tienes dos columnas que tienen la misma información, ¿vale? A lo mejor tenéis 0,2 menos. Me explico, pero no vais a tener un punto menos. Me explico lo que os quiero decir. O sea, que corregimos por planteamiento. Si está bien hecho el planteamiento, aunque os dé un resultado mal o la cura si no sea el mejor del mundo o lo que sea, no os preocupéis. Se corrige porque más o menos el planteamiento del ejercicio sea correcto. Eso también quiero tranquilizaros. En general, para todo lo que hagáis, ahora mismo lo que estamos mirando es simplemente que sepáis cómo hacerlo, lo que entendáis que son cada una de las cosas y los que estéis en miedo a programar, ¿de acuerdo? Pero si os sale una cura así de uno, yo, por ejemplo, sé que algo tiene que estar mal, ¿vale? Es decir, viéndolo así digo, algo está mal, seguro, ¿vale? No de la programación, sino del conjunto de datos que tenemos, ¿de acuerdo? Pero bueno, si os da este caso, no os preocupéis. Vosotros lo analizáis como que esto es que el 100% de los casos de los falsos positivos me lo ha hecho bien y el 100% me los ha hecho de los negativos también, ¿vale? Entonces, porcentaje. Efectivamente, lo que se valora es el planteamiento y el razonamiento. Efectivamente, ¿vale? Entonces, si alguien ve que, por ejemplo, no sé qué hacer y la columna de texto me está fastidiando y me está dando un montón de errores, bueno, pues yo, por ejemplo, la quitaría. Luego, a lo mejor tengo un poquito menos de puntuación, vale, pero el resto del ejercicio estará correcto, ¿vale? Con esto quiero deciros. en este sentido el tema del sensitivity el tema del specificity ¿cuánto es grande? pues evidentemente a partir de un 50%, o sea mayor de 0,5 ¿cuánto es pequeño? pues menos de 0,5 ¿sí? pero lo podéis analizar en términos de porcentaje ¿queda claro este tema de la matriz de confusión? ah, da sí porque recordemos que habíamos dicho que no convergía ¿vale? la solución era que no convergía pero bueno no es algo que os tenga que preocupar a vosotros ahora correcto, hasta aquí me seguís vale, entiendo que sí pues vamos a árboles de decisión de aquí sería todo el R se entrega en formato HTML en la plataforma de examens, podéis subirlo en formato VR en el punto R lo podéis subir o sea, tal cual lo tenéis aquí que lo guardáis en formato .R aquí le dais a guardar lo guardáis en vuestra parte del escritorio y lo subís en .R No hace falta que lo paséis a HTML, ¿vale, Juliana? Entonces, esto sería todo lo que habría que hacer. Bueno, aquí os he puesto los casos. Pensad que los números pueden variar porque es cuando yo los hice. ¿De acuerdo? He explicado un poco la sensitividad, os he explicado un poco la estificidad y también he explicado, por ejemplo, cómo se puede predecir cuando tenemos un caso concreto. ¿Vale? Un poco lo que hemos hecho con Leonardo DiCaprio. pues en este caso el new data en vez de poner el test ponemos una crema y lo único que hacemos es sentar las variables damos el valor correspondiente vale y lo imprimimos de acuerdo entonces el objeto es pues veréis que aquí tenéis en este caso uno que quiero saber recordemos que esto es la probabilidad en este caso es uno en nuestro caso mejor o sale 0 con 8 si quiero saber realmente si es que sí o si es que no tendré que donar la en este caso es que sí y por tanto la redondea ¿de acuerdo? antes de empezar con árboles de decisión ¿alguna duda? de todo esto, algo que no se entienda entiendo que no tema de los árboles de decisión necesitáis dos librerías no os preocupéis la librería de rpart y la librería de rpart.plot ¿por qué? porque los árboles de decisión como mejor se entienden es con el dibujo así que hagamos librería ¿de acuerdo? lo mismo, lo único que cambia es que en vez de poner GLM y binomial vosotros ponéis Rpart y metoclase, ¿por qué? recordad que vosotros estáis prediciendo 0 y 1, ¿vale? los árboles de decisión también los podemos utilizar aunque no es muy extendido como para que nos den valores que son que son numéricos, ¿vale? entonces al hacer el metoclase estáis diciendo que no me puede salir por ejemplo un árbol con un nodo 0,5 si tengo 0 y tengo 1 es o bien 0 o bien 1 no puede haber un nodo con un valor intermedio ¿vale? entonces con esto lo hacemos con el método class entonces nosotros ejecutamos exactamente lo mismo, quitamos el repate y ponemos el método class y podéis sacar el summary el modelo de árbol importante ¿vale? aquí tenéis para mí lo más importante, el variable importance ¿vale? es decir, las importancias importancias de cada una de vuestras variables y aquí es lo que yo comentaba que si os preguntan por importancia de las variables no os cuesta hacer la every rpt y hacerlo con un árbol me explico es decir dependiendo de lo que os pregunten Podéis hacerlo perfectamente con un árbol aquí no hay que poner nada como factor si hiciésemos la matriz de confusión sí en el caso de que pero todavía no hemos llegado y no recuerdo si nos lo hacía, no, pero si es en la matriz de confusión que se haría igual sí, vale, pero en el momento de hacer la matriz de confusión, ¿se entiende? y bueno, si utilizáis texto sí que sería lo mejor vale vale, dicho esto ¿acabáis? no vuelvo a repetir el tema del best factor, si vosotros tenéis cadenas de texto, si una de las variables que utilizáis para predecir es texto en plan de por ejemplo países yo si os aconsejo siempre convertirlos a asfactor, si no es el caso y todas las columnas son numéricas y lo único que queréis es hacer la matriz de confusión a la hora de hacer la matriz de la confusión tendrás que hacerlo exactamente igual que la relación logística, coger el asfactor ¿sí? pero si es interno como la columna de meses en aguacates, exacto para predecir, ojo estamos con predicción para predecir si es íntegra o no para aclarar una cosa, en el tema de la matriz de confusión aunque es el único lugar en los que los íntegres cuando sea 0 y 1 los vais a convertir en as factor pero porque esos números no los estás identificando como el número 0 o el número 1 sino que entre comillas es como la clase positiva y la clase negativa, no es un valor numérico porque no existe el 0.3 o el 0.4 o el 0.5 ¿me explico? entonces es como un caso raro, es como un número pero que en realidad significa como clase A y clase B, ¿se entiende? a la hora de hacer el árbol no, no necesitas pasarlo, solo los tipos texto en el caso de los float no te dará problema no te preocupes porque la variable que estamos considerando o sea, cuando yo estoy diciendo este method class es la variable que yo acabo haciendo al final pues 0 y 1, sí y no es lo que quiero predecir, por ejemplo yo que sé, bolas rojas bolas azules, bolas verdes por ejemplo, rubio, moreno y pelirrojo, ¿de acuerdo? es la variable que estás haciendo al final, no vas a tener números decimales ahí, por tanto no vas a tener un float, Alejandro si es dentro de las variables que utilizas para predecir, ahí puedes tener float y puedes tener lo que quieras, ¿sí? perfecto de esta manita entonces aquí tenemos toda la información del árbol pero vale se interpreta no demasiado bien de acuerdo entonces lo que vamos a hacer es dibujarlo porque porque se interpreta bastante mejor entonces nosotros lo dejamos y aquí os he puesto qué significa cada uno de las cosas, ¿vale? Aquí arriba, en el valor este que tenéis arriba, ¿qué es? Es ¿qué clase predomina? Ah, de cara a estudiar es mejor repetir estas dos cosas estudias y repetir de cambio actividades. Las dos te recomendaría, ¿vale? Porque sí que es cierto que estas, también os he puesto casos en los que el modelo no salga perfecto para que no os bloqueéis, para que veáis casos en los que el modelo no son perfectos y continuéis pues argumentando las cosas tal como eso para que si en el examen os sale algo que no entendéis sepáis cómo continuar, ¿vale? Pero aquí os estoy dando bastante, bastante información para que lo entendáis todo perfecto, ¿vale? Entonces creo que como estructura está bastante bien pero las actividades de las clases de Titanic y todo esto lo haría también, ¿vale? No sé si me he explicado bien. Vale, vio la manita, perfecto. Entonces, ¿cómo lo interpreto el árbol de decisión? El árbol de decisión lo interpretaría en base a los valores que tengáis. En base a este valor de aquí arriba lo que nos dice es que en el conjunto de los datos lo que más predominan son ceros. Después tendríamos en este caso, que es el 0, tendríamos que fijaros que como lo hace, dice, ¿Rifle es menor que 1,1? Sí, pues entonces tenemos este otro nodo. Y si no es menor, tenemos este otro nodo. Ojo, cuidado, leed muy bien cuándo es sí y cuándo no, porque a veces cambian, ¿de acuerdo? En este sentido, ¿qué me siento del 78%? Que el 78% del conjunto total de datos está aquí. Y aquí me diría que el conjunto total de datos está aquí. ¿Qué es el número entre medias? Aquí predominan los ceros, aquí predominan los ceros, aquí predominan los unos. Y el valor entre medias es cuál es la probabilidad de que sea, en este caso, 1. Entonces, ¿cuál es la probabilidad de que sea 1, 0, 22? Que sea 1, 0, 0. Que sea 1, 1. Si no fuese solo 0, 1 y fuese 0, 1, 2, por ejemplo, os aparecerían aquí tres números. Probabilidad que sea 0, 1 o 2. Así que os puede ocurrir. Muy importante que a veces da lugar a equivocaciones es que imaginemos que yo aparte aquí tuviese otra división, ¿vale? Y el porcentaje, ¿vale? Yo tuviese aquí, por ejemplo, un 54%, por ejemplo, ¿vale? Y aquí tendría entonces un 24%, ¿vale? Podéis decirme, bueno, 54 más 24 son 78. Lo importante es que los nodos finales al sumar el total de aquí, es decir, estos valores de 54 a este 24 no es 54% de 78%, sino 54% de ese 100% del total. Por eso la suma de estos, de los nodos finales, siempre da 100. en el mensaje es mejor usar R-Martin o cuarto de script con comentarios lo que queráis ¿vale? lo que queráis completamente lo que queráis, si preferís cuarto con cuarto, si preferís R-Martin como hemos trabajado en clase normal, lo que queráis yo lo estoy haciendo así más que nada porque creo que quedaba bastante más claro yo un compañero que me lo dijo uno de vuestros compañeros me lo comentó de cara a que quedase más claro todo pero si lo queréis utilizar o no en el examen da eso como queráis, ¿vale? Lo podéis hacer como hemos hecho, con eso, sin eso, como queráis, ¿vale? De acuerdo. Entonces, he explicado un poquito lo que son árboles de decisión. Con esto creo que hemos terminado árboles de decisión. Estoy yendo un poquito más rápido, pero si alguien necesita alguna duda, me lo puede comentar. Igualmente está todo en principio aquí explicado. ¿Cómo podéis tener las variables? Pues haciendo el verbo importas, tenéis anterior la importancia, ¿vale? hacer predicción igual, no se os olvide el class y el new data y si queréis hacer la predicción de un dato completamente nuevo, simplemente en el new data en vez de poner test, hacéis el data frame como tal ¿Nos puede enviar el archivo en cuarto en el pdf? Vale, se lo digo también a Saray para que os envíe el archivo en cuarto son cuatro archivos así que os lo pasaré como un como son varios archivos os lo pasaré como una carpeta comprimida a ver si puedo hacerlo vale, bueno, lo mismo, cero de acuerdo, vale pasamos obviamente a clasificación, esto lo habéis visto más recientemente, así que yo creo que podemos ir más largo, más rápido volvíamos la carga de los datos no sé hasta ahora a ver de qué tipo son cada uno de los datos la curva del ROC esa no entra entonces no creo que os lo pregunten no En principio no entra, no te preocupes por la curva roja Hacemos el string de los datos, tenemos que son todos valores numéricos en este caso con decimales Y tenemos una clasificación que es en tres categorías, de cetosa, de color y virgínica Ahora bien, aunque nosotros tenemos una clasificación, lo que queremos es que el ordenador nos lo agrupe como él quiera es decir, independientemente de esta clasificación, yo le voy a dar al ordenador las cuatro columnas primeras, podría darle también esta clasificación, no habría ningún y le voy a decir, ordenamelas como quieras, ¿vale? es decir, es una clasificación porque yo no le estoy diciendo al ordenador, hay estos tres grupos cetosa, versicolor y virgínica clasifícamelo en estos tres grupos sino que yo le estoy diciendo al ordenador, tienes estas flores, es cierto que existe esta clasificación, pero agrupan más como toqueras, ¿vale? Esa sería la diferencia con el tema de clasificación. ¿Vale? La única diferencia es que en la clasificación nunca, nunca, nunca se hace entrenamiento efectivamente como una clasificación no supervisada. La única diferencia es que en la clasificación nunca, nunca, nunca se hace división entre entrenamiento y testeo. ¿Por qué? Porque no sé la solución. No tengo en ningún caso ninguna solución, ¿vale? Por tanto, no voy a hacer esa diferencia. Simplemente seleccionamos, ¿clastrización entra en el examen? Entra en el examen, sí, ¿vale? Es más fácil, de hecho, si lo pensáis bien, es más fácil, ¿de acuerdo? Que el resto sea más corto porque os quitáis la parte de dividirlo entre entrenamiento. Sí que os aconsejo para el examen, ¿vale? Que repaséis todo, ¿de acuerdo? No repaséis, no hagáis la de repaso, regresión lineal y clasificación porque tengo más probabilidades de que me entre regresión lineal y clasificación ¿vale? por favor os lo pido repasad todo, ¿vale? dicho esto, tenemos lo que sería datos numericos, datos porcentuales si queremos, solo si queremos no es obligatorio, os lo pido, podemos dibujarlo aquí por ejemplo, yo ya sé que hay una correlación fuerte entre dos variables porque fijaros, esta variable de pétalo si os dais cuenta es prácticamente en línea recta yo sé que aquí va a haber una correlación fuerte ¿vale? sin embargo si nos vamos por ejemplo pues aquí veo que hay una especie ascendente pero no del todo ¿vale? esto ¿cómo lo podemos analizar? bueno viene aquí especificado abajo ¿vale? pero lo que te voy diciendo es que esta fila es sepal y esta columna de aquí es la longitud del sépalo ¿vale? esta fila de aquí es sepal width y esta columna de aquí es el ancho del sépalo. Por lo tanto, esto que va a ser la relación entre esta fila, la hojita del sépalo, y esta cuna, que es el ancho del sépalo. Por si acaso alguien quiere esto, aunque si os lo preguntan. Exactamente, lo que no tiene correlación le aparece más o menos como una especie de círculo de nubes completamente disperso. Dicho esto, continúo. Hoy la clase está siendo larga, lo siento. pero de verdad que si alguien tiene que irse, que de verdad que no se sienta mal, como si me quedo aquí sola, no os preocupéis, pero sí que me apetecía que tuvierais todo más o menos. Bueno, aquí hemos hecho la correlación de los datos numéricos, lo mismo, tenemos valores que son negativos, valores que son positivos, bueno, un poco en general, como lo queríamos. Y ahora lo muy importante, el caso de Python, es que digáis, bueno, vale, muy bien, hago grupos, pero ¿cuántos grupos hago? Bueno, pues hay tres formas. ¿Tengo que utilizar las tres formas en el examen? No, no tienes que utilizar las tres formas en el examen. Puedes utilizar la forma que mejor te venga. Es decir, aunque os enseñemos tres formas, utilizad una única. Entonces, aquí tendríamos el library facto ex. ¿De acuerdo? Y sería la primera. Utilizamos esta librería con esta función, metemos nuestro conjunto de datos también muy importante que sean numéricos y luego tendríamos que le decimos el método el método que estamos utilizando es Cummins que lo que hace es agrupar los puntitos o sea, proyecta los puntos, dibuja los puntos para que los entendamos y luego va agrupando según la distancia ¿vale? entonces esta fórmula ya directamente me está diciendo fijaros que el número óptimo de clúster es el 2 ahora os explico lo del código el número óptimo de clúster es 2 no os lo recomiendo mucho ¿de acuerdo? esta versión pero no es la que más se suele utilizar por eso no os lo recomiendo, pero bueno es una de las formas ¿vale? yo en R tengo mi favorito, vamos al método del codo, fijaros, el método del codo es lo mismo ¿de acuerdo? pero le añadimos aquí una cosita, le añadimos el WSS que básicamente es la la distancia dentro de cada uno del grupo ¿vale? El tema del codo, para que lo entendáis bien. Esto se asemeja, a ver si lo puedo dibujar un... Dibujo muy mal, ¿vale? Mi parte no es el... Pero bueno, la cuestión, ¿dónde estaría el codo en este dibujo? El codo estaría en este punto número 2, ¿verdad? Hay gente que me puede decir, el codo estaría en el punto número 2. aceptable, lo que sí que es cierto que en el punto número 4 no estaría. ¿Sí? Entendemos el dibujo del... Dibujo fatal, ¿vale? Pero entendemos el dibujo del código y que quedaría más o menos en el 3, aceptaría el 2, pero el 4, por ejemplo, no lo aceptaría. Sí. ¿Se entiende? Vale. Y no. Dime. Sí y no. Pero... Sí y no. la cuestión es que tienes que pensar que es como el codo, entonces tiene la parte siempre que baja, ¿de acuerdo? y luego sí que es cierto que hay como dos puntos, que es como que tuvieses dos codos, ¿vale? si cogieses el 2 o coges el 3 es correcto ¿vale? sí que es cierto que el 4 ya estaríamos hablando más o menos, si te das cuenta es cuando se estabiliza, entonces estaría más o menos como en esta parte, ¿vale? no tanto en el codo, o sea, el codo es como el pico ¿vale? porque es más parecido a todo de los de antes, ¿vale? pero estoy completamente de acuerdo contigo que el método del codo no es el mejor ¿vale? porque siempre estamos entre es el 2, es el 3 o a lo mejor luego resulta que tienes aquí el codo y dices ostras y no será el 7 ¿vale? entonces R no os ríáis de mi dibujo ¿vale? por favor, o sea, de verdad que te encontramos con dibujar, no es lo mío a ver, vale, lo que se estaba comentando ¿vale? R tiene una ventaja ¿vale? que no tiene bueno, Python creo que sí la ha incorporado pero hasta hace nada no la tenía Python que es este método para mí es el mejor, el nbclash ¿vale? lo que haces es decir, el conjunto de datos numéricos que tienes sabemos que vamos a analizar quiero que me hagas las métricas entre tener dos grupos tener tres grupos, cuatro grupos cinco grupos, seis grupos, ¿hasta qué? hasta ocho grupos, ¿vale? ese es el número total de grupos que me va a analizar y el método que yo quiero para hacer la clasificación es el método de Cummins Entonces nosotros Importante, fijaos aquí está entre comillas En los casos estaban con mil Entonces, ¿qué nos hace el NBGast? Nuevos gráficos, me parece perfecto Pero vosotros tenéis que ir A ¿Vale? Entonces, si vais a estas estrellitas Lo que os dice es Fijaros, de todos los índices 11 de ellos dijeron que lo mejor era tener 2 clusters O sea, 2 grupos 11 dijeron que lo mejor era tener 3 grupos y 2 dije que lo mejor era tener 8 grupos ¿vale? Conclusión, dice, bueno, teniendo en cuenta la regla de la mayoría y luego el tema de que este va antes que este pues el número mejor de grupos sería 2 efectivamente, como un consejo de sabios y nos quitamos el tener que interpretar el codo, ¿vale? que a veces nos puede ir entonces para mi gusto aprovechad que estoy trabajando en R y utilizad esta, porque siempre os va a decir lo que es la mayoría en base a criterios que está utilizando él internamente. ¿Se entiende? Perfecto. Eso te ha gustado más, Alejandro, que el coto, ¿verdad? A mí también. En Python no tenemos esta suerte. En este caso, aprovechemos esta, que nos da el resultado. Y una vez que tenemos ya, en este caso habíamos visto que podemos seleccionar bien 2, bien 3, lo que queráis, hacemos la esterilización. Camils, mi conjunto de datos, y 2. Esto ya me va a dar la clasificación. Si yo miro la clasificación, ¿qué me da? Me da el vector, el clustering vector. Lo que me está diciendo es, mira, para la primera fila que me has dado, digo que está en el clúster 2. Para la segunda fila que me has dado, está en el clúster 2. La tercera fila que me has dado está en el clúster 2, etcétera, etcétera, etcétera. y me da unas distancias acuerdo que esto me dice más o menos si es bueno o si es malo lo importante aquí también es que veas esto ¿qué pasa? que yo sabiendo la medida de cada columna puedo identificar qué tipo de clúster tengo puedo interpretar el tipo de clúster que tenga por ejemplo, yo en este caso estoy viendo que el clúster 1 tiene mayor sépalo tiene un poquito menos el ancho del sépalo pasándolas a factores. Las categóricas creo que pasándolas a factores y si no a numéricas lo podrías hacer. Sí, sí, sí, creo que sí. En Python ya te digo que pasándolo a numérico. En R creo que también, ¿vale? O sea, creo que si la pasas a factor creo que lo puede hacer bien porque en Python es que no existe la categoría factor como tal. Pero sí, tendrías que pasarla con texto, texto como tal, ¿no? ¿Vale? Entonces, lo segundo que vemos es que el ancho es un poquito menor, que la longitud del pétalo es bastante mayor y que la longitud del ancho del pétalo también es bastante mayor. Por lo tanto, yo podría decir flores grandes y me quedan como flores pequeñas. ¿Por qué? Porque todo, salvo en el ancho del sépalo, que es básicamente la coronita que está debajo de las flores, pues en todo es mejor. De acuerdo. También podéis sacar los clústeres haciendo el vector clúster que hemos visto anteriormente y podéis sacar una tabla de frecuencias. si hacemos la tabla de frecuencias del vector veremos que el clúster 1 tiene 97 flores y el clúster 2 tiene 53 flores ahora recordad que nosotros teníamos una clasificación previa perdón, teníamos una clasificación previa ¿qué puedo decir? puedo decir, oye, ¿y mi clasificación previa? ¿cómo ha quedado en esta nueva clasificación? pues voy a hacer una tabla de frecuencias de la clasificación que yo tenía previa y la clasificación que hemos hecho entonces aquí veréis que por ejemplo la cetosa está toda en el clúster 2 la versicolor está casi toda en el clúster 1 y la virgínica estaría casi toda en el clúster 1 ¿sí? ¿se entiende? si hay alguna cosa que no hayáis visto aquí es porque lo veréis en la clase que viene mi grupo, esto por ejemplo de interpretación de los clústeres utilizando árboles lo verán en la clase que viene, ¿vale? o sea, mañana básicamente entonces bueno, podemos hacer cuando quieren interpretar también los clases hay veces que se dice, bueno yo he sacado una agrupación y quiero saber qué variables han tenido más importancia que a veces se dice pues en vez de ir a las medias que me pueden dar cierta información, lo que puedo decir es bueno, voy a hacer una clasificación con mi resultado de la clasterización ¿para qué? para tener un árbol de decisión que me diga cuándo he ido a un lado y cuándo he ido a otro aquí por tanto no hace falta hacer el entrenamiento porque al final queremos que sea todo el conjunto de datos no voy a predecir y lo que voy a decir es mira pues aquí ha ido a este lado por este motivo ya que ha ido este otro entonces hacemos la clasificación las variables utilizado para hacer la clasificación y el resultado de la misma porque se hace esto porque ya que tengo dos clases y os lo hago con tres para que veáis también una cosa del 3 tenemos que predomina el caso 1 que la probabilidad de 2 en este caso es 0,35 del 100% ¿qué variable he tenido en cuenta para dividir? pues una vez que ya sabemos la clasterización muy importante, esto me permite conocer los clusters pero no me va a permitir hacer la clasterización, la clasterización la he hecho con el Cummins, importante entonces lo he separado por la longitud del pétalo y en función de eso pues el cluster 1 o el cluster 2, aquí lo que más hay son unos, aquí lo que más habría sería el caso de los clusters 2, es como que estoy clasificando ahora lo que sería el clúster si tenemos aquí es un momento este que ya me estoy viendo pero quiero que es todo bastante tan claro que la vida de lo posible entonces aquí tenéis el cluster 3 si lo hacemos con clave 3 y a bajar voy a bajar voy a bajar y ya queríamos con clases un clúster y ponerlo que está aquí, vale pues si nosotros lo hiciésemos los restos fijaros lo que os comentaba aquí lo que ha hecho es descomponer por si la longitud de pétalos es mayor o igual que 2,5 si es que no, todos van a este clúster en el que la mayoría de lo que hay es 3, vemos que tiene probabilidad 0 de estar en el clúster 1 probabilidad 0 de estar en el clúster 2 y probabilidad 1 de estar en el clúster 3 y correspondería a un 33% de los datos iniciales. En el caso de que sea efectivamente mayor o igual que 2,5, pues pasamos a hacer una segunda división. Esta segunda división es mayor o igual que 2,5, pero es menor que 5,2. En el caso de que sí, pues tendríamos la primera caja, que es así como naranja muy fuerte, probabilidad de estar en el clúster 1, 0,94. De estar en el clúster 2, 0,6. De estar en el clúster 3, 0,00. ¿Cuál es el total de la población que ha venido a este clúster? Un 44% Y en el caso de que sea no Es decir, el pétalo se encuentra entre 2,5 y 5,2 Pues tendríamos que lo que más hay son del clúster 2 Probabilidad de estar en el clúster 1, 0 Probabilidad de estar en el clúster 2, 1 Probabilidad de estar en el clúster 3, 0 Y el total de la población un 23% ¿Se ha entendido? He ido un poco rápido, pero me sirve si habéis entendido un poco si no habéis llegado a esto con vuestra clase os lo explicarán pero bueno sería otra forma de que se os preguntan interpretación de podréis hacerlo así directamente aquí ponéis lo mismo que hayáis puesto muy importante lo del método CLASS y aquí ponéis lo mismo que hayáis puesto para hacer la clasterización y es analizarlo como se comenta vale y lo último del día de hoy si lo veis que sí queréis hacerlo es, si no pues lo dejamos aquí, sería series temporales ¿Queréis que lo hagamos hoy? O lo dejamos aquí, como veáis Series temporales cuando hacéis el ánimo Vale, lo dejamos aquí Por mí no lo hagáis, de verdad Bueno, os lo digo una cosa rápida ¿vale? Muy importante, cuando hagáis series temporales, convertirlas a serie temporal antes ¿vale? Importante, estos me dicen a ver en teoría entra ¿vale? De ahí que se entre en el examen es otra cosa, ¿vale? Pero en teoría entra. Nada, lo único que quiero comentaros es la frecuencia, en este caso es 12 porque es mensual 12 med vale, en principio es la última clase que tenéis conmigo, salvo mi grupo no está predispuesto nada más por eso os comentaba si queríais que fuese hoy o si no, ¿vale? tiene menos probabilidades de entrar que las otras cosas ¿vale? pero os puede entrar es más probable que os entre relación lineal y clasificación que series temporales de acuerdo tema de series temporales, utilizaremos teorías, os lo digo muy rápido porque hay cosas que son más complicadas, o sea yo me centraría más en lo otro pero esto estudiadlo por si acaso, ¿vale? ¿Qué tenemos? Conocer datos, un poco lo mismo que os he hecho, lo vamos a repasar. Bueno, si vemos aquí el conjunto de datos, eso sí, fijaros que los datos son año 2000, mes 1, es decir, cuando estoy empezando, en enero del año 2000, ¿vale? Esto es importante. ¿Por qué? Si yo dibujo datos tal cual y no hago nada más, fijaros que no parece que tenga ningún tipo de sentido. Entonces, para dibujar una serie temporal, si no yo especificar que es una serie temporal, se utiliza el plot.ts. De forma, se interpreta que la columna de abajo son ciertos meses, aunque no sabe qué meses son. Entonces, ¿cómo se debería hacer realmente? Se debería hacer yo turistas, lo voy a guardar en mi variable turistas, que es una serie temporal. Entonces lo quiero definir, le estoy diciendo al modelo, es una serie temporal sí o sí, ¿vale? De mi conjunto de datos de Reino Unido, mi variable que es la que tiene datos, ¿vale? La variable UK, es la variable que tiene datos y ¿dónde empiezo? Empiezo el 1 de enero, en enero del año 2000, es decir, empiezo en el año 2000, enero, ¿vale? Por eso ponemos 2001 porque tus datos empiezan en 2000, mes 1, ¿vale? además yo veo que la frecuencia es mensual cuántos meses tiene un año 2 por tanto frecuencia 12 12 implica mensual y no podéis decir bueno pero como sabe la serie que me tiene que poner la serie va poniendo pues enero 2001 a febrero de 2000 marzo de 2000 hasta que hasta que vaya hasta sacar los dos cuáles saben los datos la serie te dirá he terminado es este dato de acuerdo por eso no necesitamos aquí poner la segunda columna porque me la está generando automáticamente esto de aquí. Entonces, una vez ya definida como serie temporal, ya simplemente con el plot normal ya dibujéis el cante. ¿Vale? Bien. Que hemos visto que se podía descomponer. Cuando la descomponíais teníais la vertiente que era la observada, la serie tal cual, ¿vale? La tendencia, esto básicamente la reduce a la serie en general ha crecido o ha disminuido. es decir, hemos tenido crecimiento, hemos tenido descensos, ¿vale? El carácter seasonal que vendría siendo los ciclos, ¿vale? Y luego un carácter aleatorio que siempre tienen todas las series, que son básicamente subidas o bajadas que nos siguen como un comportamiento normal. Es básicamente lo que tenéis aquí, más o menos, es claro, ¿vale? Si yo quiero predecir, ¿cómo lo puedo hacer? De nuevo, lo he puesto con entrenamiento y validación. Si veis vuestros ejercicios, veréis que la mayoría de las ocasiones no habéis hecho ni entrenamiento, validaciones más o menos de este. Veréis que no habéis hecho entrenamiento ni validación, con lo cual, bueno, si os lo piden, lo hacéis. Si no os lo piden, no lo hacéis. En este caso, ¿por qué hacemos el entrenamiento y validación? Porque lo que quiero es estar seguro de que mi predicción es correcta antes de predecir cosas del futuro. ¿No lo tenéis? El R como tal, el formato R. Vale, os lo puedo dar en formato QMD. Vosotros lo copiáis y lo tenéis en R igualmente. Entonces, en este caso, yo quiero predecir a lo que serían 12 meses. ¿Cuántos son 12 meses? Bueno, aquí lo he hecho un poco a la cuenta de la vieja para que sepáis que también lo podéis hacer a la cuenta de la vieja. Suena muy mal, pero es así. Si yo quiero 12 meses y es mensual y tengo 239 valores, ¿cuál será mi test que voy a hacer? 228, 239 que son esos 11 meses y el resto lo pondríamos como entrenamiento pero es más o menos lo mismo, creamos otra vez una serie temporal de entrenamiento creamos la serie temporal de validación y hacemos la predicción, recuerdo Si no os lo preguntan, entrenamiento y testeo, lo mismo digo para todo el caso de regresión lineal y de regresión logística. Si específicamente no os ponen que hagáis entrenamiento y testeo o saquéis matrices de confusión o algo de esto, podéis hacerlo sin dividir entrenamiento y testeo y hacerlo como en clase de meter todo el conjunto de datos. En función del examen y el tiempo que tengáis, haced una cosa o haced otra. Importante también. entonces aplicamos la predicción hacemos el library forecast y utilizamos el autoarima ¿por qué el autoarima? porque si no tendríamos que estar predefiniendo nosotros ciertos parámetros y es bastante más engorroso si el ordenador ya puede hacerlo por nosotros ¿por qué lo vamos a hacer nosotros? entonces creamos el modo de arima y con la palabra forecast no predict que es lo que normalmente estábamos utilizando sino en series temporales se utiliza forecast hacemos la predicción de los 12 meses para poder probar, ¿vale? veis que es la línea azul que nos ha considerado ¿por qué tiene estos valores aquí sombreados? es porque digamos que te dice, vale, con un valor azul tienes un 95% de seguridad, ahora la siguiente ¿por qué no hace el 30%? el 30% es de número Amparo no se te oye a ver hola hola hola ¿se me escucha? hola hola bueno un poco lo que os quería contar es si haces el inter lo que pasa es que llama entrenamiento ST y validación ST que sería como el test ¿vale? pero es que lo hace si os lo pregunten en el examen y no os lo especifica podéis hacerlo directamente con todo el conjunto de datos ¿sí? Pero aquí lo que hemos hecho, hemos puesto en esto. En lugar de utilizar los índices, para que veáis que también se puede hacer así, en lugar de utilizar los índices, se me complican mucho los índices, se me complica mucho el sample. Bueno, ¿qué quiero? 12 meses. Pues selecciono los 12 últimos para el test o validación y el resto para el entrenamiento. ¿Vale? Sin ningún tipo de fórmula. Que lo hacéis con el sample muchísimo mejor. ¿Vale? Que no lo hacéis con el sample y lo hacéis así, pues no está tan bien, pero está bien. ¿Se entiende? No sé Alejandro si era esto lo que preguntas Que mucha información en un día Yo lo sé, de verdad lo siento Pero espero que Sí se hace Exactamente Otra cosa es que luego En el examen No lo hagáis porque no os lo especificen Tendréis bastantes cosas a hacer Y vayáis lo más rápido posible Lo mismo con regresión lineal y regresión logística ¿Vale? En el examen también valorad un poco eso Si tenemos tiempo para hacerlo si no tenemos tiempo para hacerlo? Porque si no, puede ser un examen algo largo. O sea, no tiene por qué ser muy largo, pero como probablemente, o sea, contestad lo que se os pregunta y siempre razonad los argumentos. Pero, por ejemplo, no, sí da tiempo, ¿vale? Pero lo que me quiero referir es, imaginaos que os preguntan una regresión logística y te dicen cuál es la probabilidad de que la persona haya sobrevivido. ¿De acuerdo? Entonces, ¿te están preguntando por matriz de confusión? No. ¿Te están preguntando por acurací? No. ¿Te están preguntando por sensibilidad? No. ¿De acuerdo? Entonces, a lo mejor ya lo valoraréis vosotros. ¿Vale? O regresión lineal. Dime cómo afecta la variable tal, o la variable, por ejemplo, la cantidad vendida al precio. ¿Vale? ¿Me están preguntando por métricas para los... sí, ¿vale? Te pregunta bastante implícitamente, ¿vale? Luego sí que se toque, tendréis que razonarlo, pero la pregunta es implícita. Si lo añadís, bastante mejor, ¿vale? pero tendréis que hacer varias cosas es probable que os toque hacer más de un modelo, ¿de acuerdo? entonces mirad, ¿vale? tampoco hace falta hacer la grandísima catedral para un modelo y luego decir que no llego para el otro, entonces mirad más o menos lo que os están preguntando para ser capaces de ajustar a lo que se os preguntan, que luego lo argumentéis ¿vale? y luego ya se os da tiempo y queréis añadir métricas, añadid todas las métricas que queráis ¿vale? pero aseguraros primero de tener al menos la respuesta base a todas las preguntas ¿me he explicado mejor? por eso digo el tema de si no me lo preguntan específicamente y voy deprisa y corriendo, a lo mejor no necesito hacer entrenamiento y puedo hacer una reversión lineal como hacíamos al principio sin entrenamiento y testeo, ¿vale? va más en este sentido vale, bueno, hacemos el adobrín, el forecast si lo tenéis aquí, para comparlo lo podemos dibujar encima de lo que diría la media y lo que más en la cura, si aquí tenéis una métrica para saber cómo ha hecho el resultado que volvéis a tener el M el RME, el MA, los mismos que hemos visto anteriormente y que se va a dar una evolución de la media y si no, lo que vais a tener siempre haciendo el RME si lo queréis hacer sin dividir transición y validación, más sencillo todavía seleccionáis todos los puntos de los datos ¿vale? convertidos a serie temporal, hacéis el autoarena y hacéis la predicción listo, con esto ya lo tendréis, ¿vale? si os dais cuenta, los primeros temas que sobre todo repasar la relación lineal, clasificación de las dos maneras y el tema de la clasificación, ¿vale? de acuerdo con esto sí que ya os voy a liberar un poco, sé que la clase hoy ha sido larga, lo siento, ¿vale? La anterior clase no pude alargarme mucho porque tenía otra clase después y con eso esta sé que me interesaba que al menos vieseis un poco todo, ¿vale? Solo como recordatorio, no es todo mi código el correcto y el único que sirve, ¿vale? O sea, si vuestros profesores os han dado otra forma y os sentís más cómodos utilizando esa otra forma porque es el que habéis utilizado en las actividades y las actividades os han puesto 10, pues perfecto, adelanto con adelante con eso ¿vale? pero bueno, yo os lo doy como ejemplo a mí por ejemplo el nean.me es lo que más me gusta, entonces es más como yo trabajo dicho esto, os saldrá genial, sobre todo tened en cuenta de que se corrige por planteamiento así que si a alguien le da algún problema el tema de las cosas o eso no os preocupéis, intentad analizarlo con lo que os sale, ¿vale? para mí como siempre ha sido un placer seguro que haréis muy bien el examen ya tendremos la reunión en la cual se explicará absolutamente todo, ¿de acuerdo? Me alegro muchísimo que os haya gustado y de verdad muchísimas gracias y oraré por vosotros de verdad, confiad en mí, será largo y se os pedirán bastantes cosas ¿vale? Pero recordad centraros en lo que se os pregunta y analizadlo, ¿vale? Eso es lo más importante y una vez que ya tengáis hecho las preguntas que sean, que además son bastante claras, bastante explícitas. Si os la paso, se lo comentaré a Sara entre hoy y mañana, ¿vale? Si tengo tiempo, porque ahora ya sí creo que me voy a ir un poquito a cenar y luego ya a descansar, que mañana a las 8 de la mañana hay que estar en pie. Total, que... que se lo pasaré, ¿de acuerdo? Pero sobre todo eso, ¿vale? Centraros en lo que se os pregunta y luego ya cuando tengáis tiempo ya hacéis lo que queráis, adornáis todo lo que queráis, pero las preguntas son bastante explicativas, centraros en lo que se os pregunta, por favor. os saldrá genial, estoy segurísimo de ello, así que muchísimo ánimo y nos vemos, ¿de acuerdo? muchísimas gracias, hasta otro día bueno, hasta el próximo cuatrimestre muy probablemente ¿vale? adiós adiós, adiós gracias nada gracias
