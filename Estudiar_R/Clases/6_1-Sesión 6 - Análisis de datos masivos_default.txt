Hola, bienvenidos a esta clase. Hoy intentaremos hacer media hora de teoría y media hora de práctica. Veremos lo que sería el aprendizaje supervisado y la primera de las técnicas que vamos a empezar a intentar. También aprovecharemos para decir cómo podemos hacer métricas o estadísticos dependiendo del valor de otras columnas. cuando hacemos agrupaciones y queremos saber, por ejemplo, tenemos un dataset de determinados barrios y quiero saber la media de población por cada uno de esos barrios. No la media de población de la ciudad en total, sino por cada uno de estos barrios. Entonces, ¿cómo podríamos hacer esto con RStudio? Sin más dilación, voy a volverlo a tener todo configurado. Entonces, como he tenido que reiniciar el ordenador, no os preocupéis, pero abro ahora el documento y ya estaría. Les voy a compartir ya pantalla. y como siempre si miras de este lado es básicamente porque os tengo aquí tengo el chat también aquí abierto de forma que os puedo atender lo antes posible voy a darle aquí a presentar entonces el día de hoy veremos el aprendizaje supervisado ya más o menos lo habíamos comentado la semana pasada entonces ¿qué etapas tiene el aprendizaje supervisado? Pues lo veremos el día de hoy, ¿de acuerdo? Tendríamos primero que seleccionar las variables, qué variables vamos a utilizar para predecir o para clasificar, lo que habíamos comentado la anterior vez. Una vez que hacemos esta selección de variables pasaríamos a la ejecución y por último a la valoración del modelo. Para el tema del modelado y la predicción, la base debe estar con la columna de fecha en años, que pasa cuando la fecha está en formato año, mes, día y varias columnas que repiten la fecha. vale, en este caso de acuerdo, cuando como tal tienes la fecha, lo ideal sería que hicieses algo con una serie temporal vale, si no es cierto que la fecha suele dar algunos tipos de problemas, porque no es un dato numérico que es lo que generalmente trabaja en los algoritmos y por tanto tendrás problemas, ¿qué se suele hacer? si lo que quieres es ver la evolución temporal, se juegan con series temporales, lo que habíamos visto del autoarima si lo que quieres jugar es con una predicción, pues una regresión, un aprendizaje supervisado o un aprendizaje no supervisado, lo que hacemos es pasar esta fecha a formato numérico. Generalmente se suele utilizar, por ejemplo, el tema de segundos. Hay una función que se llama secondsToEpoch, es un buen nombre que se suele decir, y cada función en él retiene la función característica, en Python se escribe de una forma característica, y lo que hace es convertir cualquier fecha en formato mes, día y año, pues entonces lo convierte en número. Tendrías las tres opciones. Si quieres algo que tenga el tiempo como variable principal y que miras, por ejemplo, una evolución en el tiempo, estaríamos hablando de predicción con sellos temporales. Y si quieres aplicar supervisado o no supervisado, tendrías que pasarlo a número. Generalmente se utiliza la que os comento. las funciones que nos lo transforman a segundos hasta una época determinada que siempre utiliza la misma el ordenador. Entonces, ¿después qué hacemos? Al final nosotros tenemos que en el aprendizaje supervisado tenemos un conjunto de datos de los cuales aproximadamente el 70 o el 80% de los mismos lo vamos a utilizar para poder entrenar nuestro modelo, para poder ajustar nuestro modelo y esto es lo que se llama la fase de entrenamiento o el conjunto de entrenamiento y el resto que me queda, ese 30-20% sería el conjunto de testeo que se utiliza para comprobar cómo de bien lo hace nuestro modelo. Entonces, después, los datos son etiquetados. Esto que quiere decir lo que hemos comentado, que tenemos un histórico de valores o tenemos ejemplos de los resultados que queremos. muy comúnmente, a veces se dice que son datos etiquetados porque conocemos la solución en muchísimos casos y de aprender de esas soluciones, de esos resultados, de esos ejemplos ya resueltos pues intentamos que el modelo sea capaz de predecir nuevos. Se utiliza para predicción sobre todo cuando estamos hablando de variables numéricas, predecir un número por ejemplo predecir el precio de algo y luego tenemos el caso de la clasificación. Cuando hablamos de clasificación, imaginemos que tenemos un conjunto de imágenes. Yo tengo un conjunto de imágenes que sabemos que son perros, un conjunto de imágenes que sabemos que son gatos y un conjunto de imágenes que sabemos que son, por ejemplo, ardillas. Nosotros al algoritmo le vamos a decir, mira, estas imágenes son perros, estas imágenes son gatos y estas imágenes son ardillas. De manera que cuando le introduzco fotografías nuevas, él sea capaz de decirme si es un perro, si es un gato o si es una ardilla. pero lo más importante es que nosotros ya tenemos el resultado, ya sabemos que es perro, que imágenes son perro, ya sabemos que imágenes son gato y ya sabemos que imágenes son ardilla es decir, tenemos los datos etiquetados con la solución, ¿vale? Entonces, vamos a tratar un poco de norma general, pues la teoría sobre el modelo de clasificación, el de predicción y intentaremos empezar a hacer algún tipo de ejercicio en RStudio, ¿vale? Entonces, el caso de la clasificación, ¿vale? En el caso de la clasificación es lo que os comento, conocemos las categorías o los grupos de antemano, ¿de acuerdo? Entonces, en este sentido, por ejemplo, veis la tabla, en este caso tenemos la observación A, B, C, D, E y F, que vienen a partir de dos variables independientes. Por ejemplo, aquí podríamos tener, me lo invento, pero la primera columna que es 1, 3, 4, 5, 6, 8 podría ser por ejemplo la calidad del producto y la segunda columna 1, 1, 1, 2, 2, por ejemplo podríamos estar hablando del precio. Entonces tendríamos que si la calidad del producto es 1 y el precio es 1, consideramos que la categoría es 1. Si la calidad del producto es 3 y el precio es 1, entonces estamos hablando del producto B. Entonces, ¿qué ocurre? Que una vez nosotros digamos este conjunto de datos, el algoritmo va a aprender de él y luego cuando le dé una calidad del producto, por ejemplo, en el invento, pero la calidad del producto 3 con el precio 2, pues a lo mejor me dice que es una categoría C. ¿Por qué? Porque él ya ha aprendido de estos ejemplos en los cuales conocemos casos particulares de esta clasificación. Clasificamos en las categorías A, B, C, D, E y F. ¿de acuerdo? entonces lo podemos hacer así u otra opción es que nosotros quisiésemos predecir la observación en función de cualquiera de las otras dos características ¿vale? por ejemplo si nosotros vamos a la segunda, al segundo columna ¿vale? que en este caso estábamos hablando del precio pero si nos ponemos en el caso al final todo depende del contexto ¿vale? pero si aquí en vez de precio consideramos pues observación como el identificador de la transacción de compra, pues esta es la compra A, la compra B, la compra C, la compra D, la compra I, la compra F. Ahora consideremos que la primera columna por ejemplo sea el número de unidades que hemos comprado y la segunda columna pues sea al final si es buen comprador o mal comprador. Entonces nosotros identificamos el buen comprador con un 1 y el mal comprador con un 2. En este caso tendríamos que ser una variable dicotómica, ¿por qué? Porque tiene dos valores 1 y 2. ¿Qué ocurre? Que si yo sé que el cliente A, B, C son variables de, por ejemplo, buen cliente y han comprado un producto, tres productos y cuatro productos, tendríamos que D, E y F habrían comprado, o sería mal cliente entre comillas, y habrían comprado cinco, seis y ocho unidades, ¿de acuerdo? Pero nosotros sabemos ejemplos. En este sentido, si lo enfocamos de esta manera, ¿qué querremos predecir? Pues querremos llegar a clasificar en buen cliente o mal cliente. Por lo que si yo tuviese aquí otra compra que fuese la compra G, que la cantidad de producto fuese 8, yo podría con eso llegar a predecir si es un buen cliente o un mal cliente, que son las dos categorías que tenemos. Entonces, es un poco lo que os he puesto. Depende mucho del contexto y lo que queráis analizar. Es cuando escogéis una variable como la variable en la cual vais a clasificar u otra variable como la variable en la cual lo haréis. veremos ejemplos y veréis la diferencia entre ellas ¿cuál es el objetivo? lo que os he comentado si yo añado ahora una transacción G que por ejemplo compra 8 unidades, quiero clasificarlo entre si va a ser buen cliente o mal cliente entonces, por ejemplo si tomamos el valor 2, es decir, si tenemos el caso de que está entre medias, que la cantidad sería 2, está entre 1 y 2, pues ¿qué tipo de cliente vamos a tener? Pues evidentemente el 1, porque si el 1, si comprar un producto es la categoría 1 y comprar 3 productos es la categoría 1, por lógica comprar 2 clientes también será la categoría 1. Y de la misma manera, si comprar 6 productos es la categoría 2 y comprar 8 productos es la categoría 2, ¿qué va a ser la lógica? Que comprar 7 productos también sea la categoría 2. entonces teniendo en cuenta eso podemos tener un primer clasificador muy sencillo ¿cuál sería el primer clasificador más sencillo de todo? pues hasta que compres cuatro productos la categoría sería 1 y a partir de que compres cuatro, o sea de cinco y más productos pues tendríamos la categoría 2 ¿de acuerdo? en este sentido, dejadme ver un momento que está grabando Entonces, en este sentido, ¿qué podemos decir? Oye, decimos que es 1 si la cantidad de producto, en este caso la X, la primera columna, es menor o igual que 4 y 2 si es mayor o igual que 5, ¿vale? Para tenerlo en cuenta. Entonces, es cierto que la mayoría de las columnas pueden ser o no son numéricas. Podemos tener caso de fechas, como comentaba Jonathan, podemos tener también caso de textos, ¿vale? La mayoría de los algoritmos, quitando algún algoritmo por ejemplo como puede ser CatBoost que lo ha desarrollado entre otros en este caso Rusia, pues la mayoría de los algoritmos necesitaríamos siempre o casi siempre pasar las variables que son texto o fechas a números. ¿Para qué? Para poder aplicar bien el tipo de algoritmo que estemos considerando. Esto también lo veremos en la parte práctica. Vayamos ahora al siguiente caso. Ahora fijaros que hemos añadido otra columna, entonces tenemos nuestros IDs de transacciones, luego tendríamos nuestra primera variable que habíamos comentado que por ejemplo era la cantidad, la segunda variable que por ejemplo puede ser la frecuencia, es decir, bueno el precio tendríamos uno sería la cantidad, otro sería el precio y ahora añadimos una tercera variable. Fijaros que las dos primeras las llamo independientes y la tercera columna la llamo dependiente. ¿Qué quiere decir? Que yo quiero clasificar la columna dependiente, es decir, mi columna y, en función de los valores de las otras columnas, en este caso de la independiente x1 y de la independiente x2. ¿Qué tendríamos ahora? Fijaros, volvemos a tener dos variables, o sea, dos posibles categorías, la categoría 1 y la categoría 2. Fijaros que cuando la variable x1 es menor que la variable x2, que se cumple en el caso a, en el caso b, en el caso c, tendríamos que me devuelve el valor 1, la categoría 1. Sin embargo, cuando estamos ante que la x1, la primera columna, es mayor que la segunda columna, por ejemplo, el caso de la d, el caso de la e y el caso de la f, sería la categoría número 2. Entonces aquí tendríamos un clasificador muy sencillito. ¿Hasta aquí se entiende lo que queremos hacer? ¿Hay alguna duda, alguna cuestión? Vale, perfecto, veo que sí se entiende. Entonces podemos continuar a lo siguiente. ¿Cuál es el objetivo? Por tanto, el objetivo al final no es sólo clasificar, es decir, no sólo es decir el nuevo valor G, que por ejemplo la primera columna sea 8 y la segunda columna sea 6, si la primera columna es 8 y la segunda columna es 6, ¿qué categoría tendría? ¿1 o 2? Os pregunto. Si la primera columna tenemos, vamos a escribirlo aquí, creo que puedo ponerlo, tenemos una transacción G, que la primera es 8, y la segunda columna sería 6. Vale, efectivamente el 2. Entonces no es sólo importante predecir el 2, es decir, ser capaz de decirle oye esta columna está en la categoría número 2, sino que también es muy importante mirar cómo de bien lo ha hecho nuestro algoritmo, es decir, realmente me puedo fiar del resultado del proyecto sí o no. entonces para eso se utiliza la matriz de confusión la matriz de confusión no es más que bueno el nombre de matriz no sé si os sonará para aquellos que tengáis más conocimiento de matriz al final no deja de ser una tabla con dos columnas en este caso porque tenemos dos posibles valores reales y dos filas porque tenemos también las filas de los valores predichos entonces ¿qué me está diciendo la matriz de confusión? pues por ejemplo, aquí me dice oye, tu valor real era un 1 y tu modelo ha predicho un 1 en cuantas ocasiones en 5 ocasiones entonces, estas son las 5 ocasiones en las que el modelo ha acertado era la categoría 1 y en efecto, ha hecho la categoría 1 si vamos ahora a la categoría a la segunda columna que tenemos que mi valor real era 2, es decir, pertenecía a la categoría número 2 pero mi modelo me ha predicho un valor 1, por lo tanto aquí ha fallado. ¿Y por qué? Porque era la categoría número 2 y me ha dado la categoría número 1. Lo mismo con la segunda fila. En este caso tenemos que el valor que me ha dado el modelo sería 2 pero en la realidad el valor es 1. Por lo tanto esto también sería un error porque no me está dando el valor correcto. Sin embargo aquí el valor real era 2 y el resultado que me ha dado el modelo es 2 también, por lo tanto aquí estarían los verdaderos en la diagonal, los incorrectos en este caso en la otra diagonal, pero no, el 2 y el 3. vale, es una métrica que es muy muy importante y de esta métrica sale algo que quizá os haya sonado alguna vez que son los true positive o verdaderos positivos los true negatives y verdaderos negativos los false positives o falsos positivos y los false negatives o falsos negativos ¿a cuántos os suenan los falsos positivos? por ejemplo de la pandemia del COVID ¿cuántos habéis escuchado la palabra falso positivo? sobre todo se dio mucho en el COVID ¿qué significaba el falso positivo? todo test médico, ¿vale? al final, ¿qué te está diciendo? te está diciendo si una persona está enferma o no está enferma por lo tanto, exacto, ¿vale? por lo tanto, en este caso, ¿qué consideramos? podemos considerar el 1 como que está enfermo y el 0 como que esté sano entonces ¿qué ocurre? que el test lo que hace es predecir entonces cuando el test nosotros estamos enfermos que estaríamos en la posición 1 y realmente el test me dice que estoy enfermo pues llegaría a Astro Positive es decir, verdaderos positivos ¿por qué? porque yo estaba enfermo tenía la categoría número 1 y el test médico me ha dicho que en efecto estoy enfermo en efecto malado 1 ¿no? ¿vale? Entonces estos serían los verdaderos positivos en castellano o true positive en inglés. Se suelen utilizar alternativamente la TP o la VP en función de si lo queréis en castellano o en, bueno, en español o en inglés, ¿vale? Lo siguiente, ¿qué pasa aquí? Aquí tenemos que nuestro valor real, vale, nuestro valor real en este caso sería 2, es decir, no estaba enfermo, pero nuestro modelo que nos ha dado nos ha dado que sí que estaba enfermo esto es lo que pasaba por ejemplo con el test COVID que había muchos falsos positivos, es decir, era un test exactamente, falso positivo realmente era negativo y falso negativo realmente era positivo, aquí lo que estamos diciendo en el caso de que los test médicos que creo que se ve bastante bien es el 2 hemos dicho que se está sano, o sea en realidad nuestra persona estaba sana pero el test médico que ha dicho ojo que estás enfermo Por eso se llaman falsos positivos, porque en realidad estaba... Sí, exactamente, aparte de los falsos positivos y los falsos negativos, a veces se llaman error de tipo 1 y error de tipo 2. Pero lo más común para lo que vais a tener a este nivel sería falsos positivos y falsos negativos. De la misma manera, si la persona estaba enferma y el test me ha dicho que está sano, ¿qué ocurre? Que tenemos los falsos negativos, porque sí que estaba enferma. y si no estaba enferma y el test me ha dicho que no estaba enferma, tenemos los verdaderos negativos. Con estas métricas, bueno, con esta matriz lo que se saca son una serie de métricas, ¿vale? Esta serie de métricas serían las que veis aquí, la sensitividad, ¿vale? La especificidad, el accuracy o el balanced accuracy. Sobre todo las tres primeras muy muy importantes, ¿vale? Porque son la base. Al final tenemos accuracy que es exactitud. muy sencillito es las veces que ha acertado entre las veces que lo ha intentado cuántas veces ha acertado pues el 5 el true positive más el true negative más el 6 y cuántas veces lo ha intentado pues será 5 más 3 más 2 más 6 5 más 2 es 7 3 más 6 es 9 y de aquí tenéis este 7 más 9 de aquí abajo pero al final es cuántas veces lo ha acertado entre entre el número de veces que ha errado esta métrica es la base para saber cómo de bien funciona nuestro modelo sin embargo hay dos también muy importantes la sensitividad o la especificidad sobre todo la sensitividad y la especificidad se utilizan muchísimo en test médicos luego os pondré si tengo tiempo el caso del test COVID para que veáis cómo se utiliza pero ¿qué es la sensitividad? básicamente es cómo de bien ha predicho las categorías positivas entonces ¿qué hacemos? Pues diríamos que serán los verdaderos positivos, es decir, las veces que he acertado en la parte positiva, dividida entre todas las predicciones cuando el valor real era positivo. Entonces será 5 dividido entre 5 y 2. ¿Por qué entre 5 y 2? Porque es cuando mi valor real era positivo. ¿Qué me mide la sensitividad? Como de bien me predice un valor positivo. Y lo contrario sería la especificidad. La especificidad es cómo de bien o cómo de seguro yo puedo estar con la predicción de los negativos. ¿Qué será? Pues muy parecido al anterior caso. En este caso cogeríamos 6 entre 9. ¿6 por qué? Porque son los verdaderos negativos, son aquellos en los que el modelo ha acertado diciéndome que era negativo. entre los intentos de la columna cuando tenía el valor real negativo. Entonces sería entre la suma de 6 más 3, que es este 9 que veis a continuación. A veces se dan en tanto por ciento, otras veces no. Esto ya depende de la persona. ¿Hasta aquí se entiende? Sobre todo esas tres son las más importantes. ¿Vale? Perfecto. De acuerdo, luego tenemos otras opciones, ¿de acuerdo? Por ejemplo, una de las principales, o sea, ¿qué tipos de métodos, qué métodos podemos utilizar para hacer las regresiones? Bueno, para hacer las regresiones logísticas son los métodos, pero para hacer la clasificación. En este caso tendríamos el análisis discriminante de Fisar, ¿vale? La regresión logística y los árboles de decisión. Y dentro de los árboles de decisión hay uno sobre todo muy importante que sería el Random Forest, ¿vale? el primer modelo sería el análisis discriminante de Fischer ¿de acuerdo? realmente no se utiliza a día de hoy porque es mucho peor que la regresión logística o que los hables de decisión y nos dan valores muy sencillitos y la lógica de entenderlo es bastante sencilla los otros dos por lo tanto sí que es cierto que fue la primera la primera metodología pero no es actualmente la que se utiliza ¿vale? después tenemos la regresión logística que es la que vamos a utilizar si no recuerdo mal hoy que esta solo sirve ¿Vale? Cuando tenéis dos categorías. El caso que hemos visto de la variable dicotómica, ¿vale? Solo puede haber dos categorías, es decir, sí y no, cliente y no cliente, enfermo y no enfermo, ceros y unos, unos y doses, pero no puedo tener más de tres categorías, ¿vale? Cuando nosotros tenemos más de tres categorías o incluso cuando tenemos ceros y unos, ¿vale? Es cierto que ceros y unos serían árboles de decisión y para más categorías podemos utilizar ya otros algoritmos diferentes, ¿de acuerdo? El árbol de decisión, ¿cuántas personas de aquí conocen un árbol de decisión? ¿Sabéis lo que es? Puede ser que no, ¿eh? Comentádmelo. Para poneros un ejemplo de que es un árbol de decisión que se entienda más o menos bien. Vale, os comparto por si acaso y lo miramos. Entonces, ¿qué es un árbol de decisión? Vale, pues un árbol de decisión a lo mejor alguno de vosotros lo ha utilizado ya, pero básicamente es algo parecido a esto. nosotros decimos, bueno, vamos a observar el cielo nos hacemos dos preguntas ¿el cielo es soleado o está lluvioso? este sería mi 0 y mi 1 hay una tercera opción, que seas nublado podríamos tener 0, 1 y 2 si está soleado, entonces que me pregunto voy a mirar en este caso la humedad ¿la humedad es alta? pues no ¿o la humedad es normal? pues sí ¿el caso del cielo está nublado? sí o no Y el caso de lluvioso podríamos tener hace viento, pues en este caso si el viento es débil, pues sí, o si el viento es fuerte, o pues no. Sería por ejemplo un ejemplo, había uno mucho mejor que se interpretaba, a ver si lo encuentro. Por ejemplo, empezamos diciendo, bueno, queremos evaluar cómo de sana puede estar una persona. entonces ¿qué haríamos aquí? a ver si lo puedo poner más grande para que lo veamos claro pues decimos vale tiene menos de 30 años si tiene menos de 30 años voy a preguntar pues si come pizza si la respuesta es un sí pues podemos pensar en que a lo mejor no está en la mejor forma física que puede estar si nos respondemos que no pues a lo mejor podemos considerar este es un ejemplo muy sencillito pero podríamos considerar que en efecto pues la persona está en su mejor forma física en el caso de que tenga más de 30 años pues entonces ¿qué tenemos que hacer? tenemos que hacernos la pregunta sobre si hace ejercicio o no hace ejercicio si hace ejercicio probablemente esté en su mejor forma física y si no pues tendríamos que estaría en baja forma física esto es un árbol de decisión y esto lo podemos hacer con los algoritmos de R pero es simplemente la lógica es esta ir haciendo preguntas y diciendo si lo cumple o no lo cumple pues entonces voy a preguntar esta otra cosa queda más claro el concepto de árbol de decisión ¿O no? Sí, profesora, sí. Entiendo que sí. Perfecto. Entonces, otras opciones que tenemos. Agrupar o clasificar según vecinos que estén cerca. Es decir, nosotros tenemos, por ejemplo, un punto y en el espacio, esto lo intentaremos ver, creo que se ve mejor con los ejercicios, pero lo que vamos a intentar es representar todo gráficamente. cuando yo represento todo gráficamente que matemáticamente es proyectarlo en espacios de dimensión inferior pero bueno cuando representamos gráficamente con puntitos al final que ocurre que los puntitos que están más cerca entre sí tienden a ser similares o ser parecidos por lo tanto básicamente lo que se intenta hacer es en función de las observaciones que están en los alrededores seleccionar la categoría mayoritaria de sus alrededores y es la categoría o es el grupo que le voy a dar a mi nuevo punto. Y por último tendríamos las máquinas de soporte vectorial que matemáticamente son un poco más complicadas porque lo que hacen es dividir por hiperplanos. Dividir por hiperplanos matemáticamente suena muy difícil pero lo que quiere decir es Así muy a grosso modo. Si yo tengo estos dos conjuntos de puntos, ¿qué es dividir por hiperplanos? Pues técnicamente es dividir de la forma que mejor separe los distintos grupos. Ya sea con rectas, en realidad es con un espacio de dimensión inferior. Entonces si es dos dimensiones sería con una recta. No hace falta que entréis en la parte matemática. Lo que tenéis que pensar es que lo que hace es, entre comillas, como representarlo gráficamente y acabar dividiéndolo por hiperplanos, ¿vale? Matemáticamente esto quiere decir que encuentra un espacio de dimensión uno menos de la que tiene actualmente la representación y es el hiperplano que mejor separa a ambos, ¿vale? Pero bueno, matemáticamente como tal no tenéis que pensar en qué es, sino simplemente saber utilizarlo, ¿vale? Entonces, eso sería respecto a la clasificación y respecto a la predicción ya realmente lo hemos hecho, ¿vale? A ver, una pregunta. Vale. Vale. si no aparece en la entrega que tengáis ningún límite en ningún tipo de formato en principio yo no os pongo ninguno tenéis que pensar que si no tenéis ningún tipo de límite en la entrega en principio no tendréis segunda pregunta ¿se deben colocar en Word los anexos de los resultados en la consola en R o solo compartir el script que se guarda en R? podéis hacer las dos cosas, tanto podéis adjuntarme el script en R como si queréis aparte de hacer capturas de pantalla en los anexos de los resultados de la consola en R me servirá porque básicamente lo ejecutaré yo para comprobar que os ha salido correcto hay que señalar en que nos ha ayudado la IA en la actividad, en las demás asignaturas de las otras asignaturas dice que señalemos en que nos ayudó el desarrollo de la actividad esto en principio conmigo nunca ha pasado pero bueno podéis comentarlo en principio la idea sería o lo mejor sería que no tuvieseis que utilizarla, ¿vale? Sé que es complicado, pero bueno, en este caso si la utilizáis sí que no estaría mal que lo comentéis, ¿vale? Pero la idea es un poco que no tengáis en teoría que utilizarla, ¿vale? Con esto creo que ya tengo, no te preocupes por el mensaje, creo que ya os lo resuelto. Vale, el tema de la predicción. El tema de la predicción ya lo hemos visto con las regresiones lineales, ¿vale? Por ejemplo, entonces, perdonad. básicamente si yo añado una observación más en este caso con el 6 pues cuál será el valor numérico que me va dando que esto es básicamente lo que se hace es construir las rectas como lo habíamos visto y con eso rellenar el valor en este caso pues vemos que si 1 es 1 y 2 es 4 que es 2 por 2, 3 es 3 por 2 que es 6, 4 es 4 por 2 que es 8, 5 es 5 por 2 que es 10 Es cierto que el 1 no nos cumple porque debería ser 1 por 2 es 2, pero bueno la recta que probablemente mejor aproxime todo esto sería 2 por la columna de la variable independiente, por lo tanto si nosotros hemos puesto un 6, ¿qué vamos a hacer? Pues tendremos un 12. En este caso la representación en forma de recta sería y igual a 2x y si tenemos más variables independientes es un poco lo que hemos hecho en la regresión lineal, de hecho es lo mismo. En este caso pues si vemos que 1 más 1 es 2, 2 más 1 es 3, 1 más 4 es 5, 2 más 5 es 7, ¿cómo se calcula la dependiente? Sumando las dos independientes, por lo tanto la recta será las dos independientes. esto es lo que se llama con la regresión lineal y al final queremos encontrar cómo de bien ha predicho entonces en este punto pues tendríamos las métricas del error absoluto medio que es básicamente seleccionar la diferencia entre el valor que me ha dado y el valor que tengo real en valor absoluto y hacer la media el error de sesgo medio que se utiliza de vez en cuando básicamente si os dais cuenta aquí lo único es que no toma el valor absoluto sino que hace la diferencia entre el valor real menos el valor que nos ha predicho. El cuadrático medio que es hacer la media de las diferencias del valor real menos la predicción al cuadrado y luego hacéis la media. El error absoluto porcentual que es parecido pero en porcentajes y el error cuadrático medio que es el que ya hemos comentado que para mí es el más interesante o el que mejor resultado o más fácil os va a resultar analizar. por último tenemos lo que serían las regresiones lineales no quiero, si voy muy rápido me lo podéis decir pero como quiero tener más tiempo para la práctica por eso quizá voy un poco más rápido pero si alguien se pierde cualquier cosa de verdad que para eso estoy para explicaroslo todas las veces que sea necesario entonces, ¿qué pasa con las regresiones lineales? al final nosotros tenemos que lo que estamos haciendo es construir una variable ¿en función de qué? Pues en función del resto de variables, pero siempre de manera lineal, es decir, no nos vamos a encontrar una variable al cuadrado, no nos vamos a encontrar una variable al cubo, no nos vamos a encontrar variables que estén multiplicándose entre sí, sino que va a ser un número por mi variable más otro número por la variable más otro número por la variable. Entonces, la idea es tener los coeficientes de estas variables independientes. ¿Y cómo se calculan estos coeficientes? Bueno, cuando apliquéis la regresión lineal, vosotros realmente no sabréis lo que está pasando por dentro, pero por dentro hay una fórmula matemática, que son los mínimos cuadrados, que es con la que se utilizan estos coeficientes. Realmente, cuando utilizamos la mayoría de los programas informáticos, no vemos la parte matemática que hay por detrás. Sí que es cierto que no son los mejores en cuanto a la predicción. ¿Por qué? Porque cuesta mucho aproximarse. Imaginemos que tengamos un conjunto de datos que hagan lo siguiente. A ver, ¿dónde tenía aquí la...? Vale, que hagan lo siguiente. Esto evidentemente yo no tengo ninguna recta que me lo vaya a clasificar bien. ¿Qué es lo que me lo clasificaría? Me lo clasificaría una parábola. Pero una parábola ya no es algo lineal, sino que es algo de grado 2. Es normalmente una columna elevada al cuadrado. ¿Existen estas regresiones? Sí existen, se llaman regresiones polinómicas, pero se hace de manera bastante parecida a la regresión lineal. Y otro tipo, también lo hemos visto en la clasificación, serían las máquinas de soporte vectorial. Y ya lo último, para lo que tenemos que terminar, aunque para la práctica no lo veremos todavía, son las redes neuronales. ¿Alguien conoce los grafos? ¿Os habéis oído escuchar de grafos? ¿Uno habéis oído escuchar de grafos? Imaginemos que tenemos una red social, para que os hagáis una idea. Entonces, ¿qué pasa con la red social? Que sé que esta persona se comunica con esta otra persona, se comunica con esta otra persona y se comunica, por ejemplo, con esta otra persona. Y esta persona a su vez se comunica con esta persona, se comunica con esta otra persona, esta se comunica con, por ejemplo, la persona gamba y esta persona se comunica con la persona fa y la persona, por ejemplo, beta. Y luego estos a su vez se comunican con la persona, por ejemplo, Y. Vale, entonces esto sería un grafo, no es más que una serie de relaciones. Las redes neuronales se representan así y lo que simboliza es que esta sería la primera tapa o la primera capa, se puede llamar capa de entrada, y esta sería la capa de salida. entonces entre medias pasa un montón de cosas en distintas capas, en distintas etapas hasta llegar a un resultado digamos que esto es lo que se llama las neuronas las neuronas aparte para que todo esto tenga lugar pues tiene que haber una función de activación una función de activación que me permita tener esa entrada de datos y acabar con esa entrada o con esta salida de datos para que os hagáis una idea es decir, existen muchísimas herramientas para realizar tanto la regresión, tanto la predicción como la clasificación ¿cuál es mejor o cuál es peor? no hay ninguna que sea ni mejor ni ninguna que sea peor lo que sí hay son contextos y en función del contexto será mejor utilizar regresión por ejemplo lineal o utilizar una regresión polinómica o utilizar una red neuronal en el día a día cómo se decide cuál utilizar pues básicamente muchas veces por las métricas de error intentas con uno, ves que no sale, intentas con otro ¿por qué? porque los modelos que siempre consideramos que son los que sí o sí ocurren en la vida real no suelen ocurrir tan bien entonces muchas veces tienes que hacer casi que más prueba e intento vas probando distintos modelos a menos que sea un tipo ejemplo de libro que ya os digo yo que no suele ocurrir los ejemplos de libros los ejemplos del libro ocurren en la teoría, ocurren en los exámenes, pero en la vida real sí que es fácil distinguir de tengo que predecir un número, hacemos predicción, tengo que clasificar en categorías conocidas, hacemos clasificación, pero ya escoger qué algoritmo utilizas dentro de la predicción o qué algoritmo utilizas dentro de la clasificación tiene que ser por intentos, la mayoría de veces, para saber cuál es el método que mejor me funciona. en cuanto a la teoría ¿hay algún tipo de duda, alguna cuestión algún tema? nos ha quedado 20 minutitos para la práctica así que bastante bien si alguien tiene alguna duda, alguna cuestión por favor que lo comente, que para eso estamos hoy un poco más rápido, pero eso no quiere decir que no podáis preguntar nada o si tenéis dudas de verdad que todo lo que necesitéis preguntádmelo el cabecidio sin redes neuronales me quedé confuso. Vale, cabecinos, lo que haces es representar gráficamente los puntitos y dices vale, imagínate que tienes amigos, ¿vale? ¿Consideras que tus gustos serán parecidos a tu grupo de amigos? Sí, haremos ejemplos de regresión lineal, ya en principio los hemos hecho pero si queréis los volvemos a hacer. De redes regionales no sé si nos dará tiempo. De regresión logística sí, de hecho es lo que vamos a ver hoy. Regresión lineal es muy parecido a lo que hicimos, pero si queréis lo volvemos a repetir. Redes neuronales no creo que nos dé tiempo porque es un nivel un poco superior y es bastante confuso. Y el cabecinos, Francis, piensa en un grupo de amigos. Si todos tus amigos les gusta el pop, ¿qué es más probable? ¿Que a ti te guste el pop o que te guste, por ejemplo, el heavy metal? ¿Qué opinas? ¿Puedo ser el pop? Vale, te gustaría más el pop en teoría porque supuestamente te juntas con gente que le gustan las mismas cosas. Pues piensa ahora que nos abstraemos, ya no son amigos, son puntitos. Pero puntitos cercanos, ¿qué normalmente significa? Significa que se comportan igual o se comportan parecido. Por lo tanto, si todos ellos tienes la categoría de escuchan pop y tienes un puntito entre medio que no tienes la categoría, pues ¿qué es lo más probable que ocurre? Que también escuche pop, ¿vale? Por cercanía. Entonces eso sería muy en modo general y quitándole toda la dificultad, pero sería un poco cómo funciona el cabecinos. existe otro que luego es Cummings, pero que eso ya lo veremos con la clasterización, que es cuando tú no sabes la categoría pero dices, oye, estas personas que están juntas se comportan igual, va a ser un grupo eso es otra cosa, pero el Cabecinos tú conoces las categorías y dices si los de al lado escuchan el pop pues esta persona también escuchará pop ¿vale? y en cuanto a las redes neuronales es un poco más confuso porque matemáticamente también implica mayor, bastante conocimiento, ¿vale? Pero para que te hagas una idea, en las redes neuronales nosotros pasamos la información, hay una serie de etapas que se llaman capas, ¿vale? Tenemos la capa de entrada de la información y luego hay otra serie de capas y en esas capas ocurren ciertas cosas, ¿vale? Bastante complicadas matemáticamente. De hecho, sueles tener funciones como la sigmoide, funciones como la relu, la tangente hiperbólica, son funciones matemáticas ya más complejas y al final acabas con un resultado que básicamente te dice la categoría. En cuanto a algoritmos fáciles de interpretar, redes neuronales no está ahí. Y de hecho esto es uno de los grandes problemas porque muchas veces los requerimientos técnicos que nos dicen es oye necesitamos saber exactamente qué ocurre dentro del algoritmo. algoritmo y muchas veces diréis es que no sé qué ocurre dentro del algoritmo porque no entiendo las distintas etapas, esto ocurre muchas veces y uno de los problemas es las redes neuronales, por lo tanto son lo que mejor resultado nos da pero de cara a regulaciones y de cara a que nos pregunten oye realmente qué estáis haciendo es de lo más complicado de entender, porque depende la función, no son funciones matemáticas sencillas, no son rectas, son tangentes hiperbólicas empieza a jugar más el tema de las proyecciones en espacios de dimensión inferior entonces se suelen utilizar pero ahora con el auge de lo que sería la explicabilidad de la inteligencia artificial son un poco caja negra y no gusta las cajas negras en el sentido de la caja negra de los aviones que es que no acabas de saber entender las cosas pues es un poco oculto todo pero lo que tienes que entender es que son una serie de etapas, de capas que tú defines que quieres que haga por ejemplo imagínate que tienes imágenes pues que tendrás que hacer, la primera será descomponer esas imágenes, lo que se hace es pasarlas a colores grises para quitarles el color después de tenerlo en escala de grises os enseño una capa después de tenerlo en escala de grises lo que se hace es hacerlo bien de contraste porque el ordenador entiende mejor así, le pones bien de contraste después ese bien de contraste acabas convirtiendo la imagen en unos y ceros porque al final los ordenadores se entienden por unos y ceros y después de hacer esos unos y ceros aplicas los algoritmos de clasificación y entonces luego haces la parte contraria empiezas a hacer el contrario y acabas con el resultado pero no es para nada sencillo y cada una de las etapas las fijas tú lo que quieres que ocurra en cada una de las de las fases pero luego hay un punto en el que siempre es muy normal que pierdas un poco el rastro más o menos queda claro las redes neurales son lo más complejo De acuerdo, pero de momento aquí vamos a hacer lo más sencillito, que es hoy en día la regresión logística. Entonces, lo primero que vamos a utilizar es un conjunto de datos. Para utilizar este conjunto de datos vamos a utilizar un paquete, una librería que se llama Titanic. Recordad que es librería, R no tiene todo el conocimiento del mundo, entonces nosotros tenemos que ir a buscar este conocimiento a ciertos libros. estos libros que son gratuitos, lo estoy diciendo en terminología común de andar por casa, porque creo que lo vais a entender mejor que si me pongo súper técnica entonces, estos libros en R digamos que se llama packages, se llaman paquetes y lo necesitamos para decirle R, oye, incluyeme la información que tengo aquí, sé que de base no lo tienes, pero quiero que me lo incluyas es como los DLCs en los videojuegos nos pasaría un poco lo mismo Tienes que instalar el DLC para poder jugarlo, ¿no? Pues aquí un poco lo mismo. Entonces instalamos el paquete, que este paquete lo único que tiene es un dataset que va a ser sobre los supervivientes del Titanic y únicamente por ello lo queremos, porque es un dataset tipo prueba que os va a salir bastante bien, ¿vale? Entonces una vez que lo hemos instalado, ¿qué tenemos que hacer? Tenemos que leerlo. vamos a leerlo como indicando library que es lémelo básicamente y el nombre del paquete fijaros para instalarlo el paquete lo he puesto entre comillas para utilizarlo el paquete no lleva comillas vale entonces nosotros ejecutaríamos esto y ya está cuando vemos aquí que nos sale otra vez el simbolito que es como un mayor mayor que sería que ya ha terminado de ejecutar entonces lo que vamos a hacer es cargar los datos utilizamos la función data y en este caso vamos a empezar con el titanic train vale que es el dataset de entrenamiento este pensar que es la primera vez que vamos a hacer una regresión logística así que vamos a hacerlo sencillito ya os enseñaré cómo descomponer datasets y todo y una vez que nosotros hemos descompuesto aquí este data vale vamos a utilizar los datos vamos a crear una variable una caja donde yo voy a guardar que información guardo la información de mi data set titanic vamos a descargarlo y si nosotros ahora hacemos un view de datos seremos capaces de ver fijaros el data set es un data set sencillito entre comillas tenemos el identificador del pasajero en este caso del Titanic que hubo, si sobrevivió o no sobrevivió, fijaros que aquí sólo tenemos dos valores el valor 0 y el valor 1, el 1 generalmente significa que sobrevivió y el 0 en este caso significa que no lo hizo, luego tenemos el tipo o la clase de pasajero, tenemos el nombre del pasajero, el sexo o género del pasajero, la edad del pasajero, esta columna que si no recuerdo mal era si tenía, si tenía, lo diré, a ver, esta era una columna que también nos decía si tenía un tratamiento especial o no o algo así era, ¿vale? Luego tenemos el tema del ticket, por si acaso es interesante, el tema de la tarifa de la habitación, el tema del tipo de cabina, algunos fijaros que tenemos hasta el camarote en el que estaban hospedados y el estado del embarque. Entonces con estos datos nosotros que vamos a querer clasificar, vamos a querer clasificar en superviviente o no superviviente, en este 0 o en este 1. Entonces, ¿qué hacemos? Lo primero que siempre tenemos que hacer es entender los datos y para entender los datos lo primero que vamos a hacer con el STR de datos que es, pues va a ser encontrar qué tipos de columnas tenemos. Fijaros, tenemos 891 filas, 891 filas de 12 variables. Tenemos cada una de las columnas y en este caso, pues, int, int, números sin decimales, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. Otra que es numérica, numérica. El nombre es de tipo CHR, viene de carácter, es decir, viene de texto. el sexo, el género tenemos que también sería de carácter, luego tendríamos la edad que son números, fijaros que aquí ya tenemos algún NA, es decir, vamos a tener valores nulos y tendremos que quitarnos, ¿de acuerdo? Luego, variable numérica, variable numérica, variable tipo texto, variable tipo número con decimales, variable tipo texto y variable tipo texto, ¿sí? ¿Qué más cosas podemos hacer? Pues podemos mirar además métricas estadísticas Las métricas estadísticas solo me van a salir de aquellos datos que son numéricos Por ejemplo, tenemos el passenger ID y ya veremos que la vamos a eliminar Pero tenemos por ejemplo sobre supervivientes La medida de supervivientes es 0,38, es más cercano a 0 que a 1 Es decir, en este caso hubo más fallecidos en principio que supervivientes Si nos vamos por ejemplo a la edad, vemos que la edad media era de 29,70 y vemos que la edad mediana sería 28. Hay diferencia, por lo tanto probablemente haya outliers, pero bueno, esto será algo que lo miraremos. aparte me da también el número de valores nulos fijaros el NAS en este caso son 177 que probablemente tenga que ver con el tema de los valores nulos que se representan con NAS de hecho el resto de columnas no tiene en principio valores nulos pero lo vamos a representar ¿cómo podemos mirar si hay variables o hay columnas en las cuales tenemos valores nulos? porque lo primero sería eliminarlos Entonces haremos col sums y dentro de esto col sums haremos isna de datos. Ejecutamos esta de aquí y fijaros, tenemos que todo es cero, es decir, no tengo valores nulos, salvo la columna age, la columna que se da, que me vendría a decir que tengo datos nulos. Fijaros que tenemos 177 datos nulos de 891 filas, es decir, tenemos bastantes números. Pregunta, ¿creéis que la edad es un dato relevante a la hora de intentar clasificar entre si ha sobrevivido o no ha sobrevivido? ¿Qué pensáis? Sí, muy importante. Exactamente, entonces no podemos pensar en eliminar directamente la columna y olvidarnos de ella Por tanto tenemos que tratar los datos nulos Lo que vamos a hacer ahora es utilizar las fórmulas que ya habíamos utilizado la clase anterior En este caso las vamos a eliminar estos datos que nos puede generar problemas Entonces haremos datos limpios y aquí ¿qué seleccionaremos? seleccionaremos de todos mis datos si hago esto ¿qué voy a decir? voy a decir seleccioname aquellos que son nulos ¿de qué columna? de la columna age esto será seleccioname los que son nulos pero yo quiero los que no son nulos es decir, quedarme con los no nulos podemos poner la exclamación y la exclamación en R significa 1 por lo tanto si yo genero esto vale un momento datos, tenemos la exclamación tenemos el isna y tenemos el datos age, vale perdón, falta decir que aunque las filas sean las que la columna age no sea nula añádeme todas las columnas con la coma y aquí no ponemos nada porque si no me va a dar error entonces nosotros ahora representamos estos datos limpios o hacemos por ejemplo el summary de datos limpios veremos que ya no tenemos esos NA representados. ¿Por qué? Porque los hemos eliminado. Si vamos a la columna H ya no vemos el NA, sino que el último valor es el máximo. Hasta aquí lo que hemos hecho es limpieza de datos nulos. Vamos a continuar con el resto. Por ejemplo, primera pregunta que nos podemos hacer es ¿cuántas personas han sobre... Dime. ¿No hubiera sido mejor reemplazarlos con lo de la media? Sí, en este caso vamos a utilizar la eliminación pero efectivamente, sí, de acuerdo lo mejor sería hacerlo con la media he utilizado la eliminación porque es más rápido para entenderlo y como ya vimos la media la anterior vez pues para no repetir, ¿vale? Pero sí, efectivamente, como son 176 de 891 al eliminar los datos nos quedaríamos o sea, sí que afectaría, podría afectar el resultado entonces lo mejor hubiese sido reemplazarlo con la media efectivamente, ¿vale? Pero bueno, en este caso la que he utilizado está porque la media ya la vimos mucho la vez pasada, ¿vale? Entonces, tendríamos que hacemos... Primera pregunta que nos podemos hacer es, vale, quiero saber exactamente cuántos sobrevivieron y cuántos fallecieron. Vale, pues entonces, ¿cómo puedo hacer eso? ¿Cómo puedo hacer una tabla de frecuencias? Utilizamos el nombre table, ¿vale? Table lo que nos va a decir es contar cuántas veces aparece cada uno de los valores. Entonces en nuestro caso será de datos limpios la columna survived, porque lo que queremos saber es cuántos sobrevivieron y cuántos no. Aquí no sé si lo veis por esto, pero si nos damos cuenta tenemos que 424 personas fallecieron y 290 personas sobrevivieron. ¿Cómo? Pues simplemente con esta sentencia que lo que nos hace es una tabla de frecuencias. Recordad que cuando suba los datos os pondré todos los comentarios de lo que estoy diciendo en palabra para que lo podáis seguir mejor. Imaginemos que yo no solo quiero los datos así, sino que quiero los datos con porcentaje. Haría prop y table. En este caso de datos limpios y el dólar, si lo encuentro, y survived. Perfecto, cuando yo hago esto... perdón, hace, vale, tenemos que hacer además el prop table de table, perdón, prop table de table, vale, si nosotros hacemos esto de aquí, ¿qué veremos? veremos el, bueno, el porcentaje, no el tanto por uno, ¿de acuerdo? Si nosotros queremos el porcentaje tendríamos que sería 59,38% y 40,61%. ¿Por qué aparecen en tanto por uno? Realmente como la probabilidad de supervivencia, de hecho podemos asemejar la probabilidad porque en matemáticas generalmente solemos hacerlo todo en tanto por uno, es raro que pasemos algo a porcentaje. entonces más que nada la probabilidad va entre 0 y 1 y esto me va a decir la probabilidad en este caso de fallecer un 0,59 y la probabilidad en este caso de haber sobrevivido sería un 0,40 hasta aquí, ¿qué tal más o menos vais? ¿Vais bien? imaginemos que ahora no solo queremos hacer la tabla de frecuencias de sobrevivir sino que queremos hacer la tabla de frecuencias de también por el género, por ejemplo entonces haríamos table y en este caso añadiríamos la segunda columna y fijaros me da esta matriz que lo que tengo es para las mujeres fallecieron 64 personas para los hombres fallecieron 360 para las mujeres sobrevivieron 197 y en el caso de los hombres sobrevivieron 93 ¿Hasta aquí más menos bien? ¿Lo seguís? ¿vale? perfecto vamos a ir ahora a la regresión logística ¿vale? ya en donde os ponga os pondré muchísimos más casos como habéis visto en las anteriores entregas que os pongo más ejemplos para que vosotros en casa reviséis los ejemplos miréis los ejemplos os lo pondré todo explicado ¿vale? vamos con la regresión logística ¿qué? ¿cómo sería? bueno, parecido a la regresión lineal nosotros hacemos necesitamos primero darle un nombre en este caso vamos a ponerle regresión logística y en el caso de la regresión logística utilizamos las tres letras glm fijaros que yo he puesto glm y ya me lo ha entendido al igual que la regresión lineal vale tenemos que decir que columna es la que yo quiero predecir que en este caso quiero clasificar en la columna survive y ahora tenemos que decirle en base a qué, en base a qué otras columnas quiero predecirlo. Por ejemplo, nosotros vamos a empezar a hacer algo muy sencillito que es quiero hacer esta clasificación en base a la columna del género, en base a la columna de la edad, por ejemplo, y en base por ejemplo a otra columna que tengamos por aquí, por ejemplo en base a la tarifa, a la FE, por poner un ejemplo. hasta aquí es muy parecido a la regresión lineal pero únicamente lo que hemos cambiado es el nombre este de GLM lo siguiente que vamos a hacer es decirle perfecto, ahora yo lo que quiero hacerlo es de manera binomial porque solo puede haber dos casos, 0 y 1 entonces family y vamos a poner la familia como tal binomial ¿Cómo se escribe binomial? Pues con la B como normalmente estamos acostumbrados y muy importante entre comillas porque es un texto. Nosotros vamos a ejecutar esto, fijaros que ya terminado es bastante rápido y podemos encontrar igual que hicimos para la regresión lineal, si nosotros hacemos el summary de regresión logística, pues aquí tendríamos el resultado. Como veis también tenemos el famoso p-valor con los códigos de significancia y las estimaciones que vendrían siendo los coeficientes. En el caso de la regresión logística no es tan sencillo hacer la fórmula como en el caso de la regresión lineal. Entonces realmente esto nos va a poder decir más o menos cuánto afecta, pero esto está elevado a una exponencial, una exponencial con un carácter negativo y además en el denominador. Por lo tanto, es un poco más complicado saber si afecta de una forma o afecta de otra. En este caso, este sería el resultado. Pero lo que vamos a hacer ahora no es simplemente eso, sino intentar encontrar. Si miramos, por ejemplo, en este caso, para enlazarlo un poco, que recuerdo que a vosotros os interesaban mucho los p-valores. De aquí, ¿qué tenemos? Tenemos la edad, tenemos el caso de sexo y fijaros que interesante. Fijaros que en el caso yo le he añadido aquí el caso de sexo y aquí la columna no se llama sexo solo, sino que se llama sexo y hombre. ¿Qué ha hecho aquí? Recordad que os he comentado que la mayoría de algoritmos necesitáis convertir la variable categórica en variable numérica. ¿Os acordáis? Sí Pues internamente ¿Qué ha hecho la variable? Ha dicho, vale, cuando yo tengo un hombre Lo que hago es, esta variable de aquí Lo ha convertido en dos variables diferentes ¿Vale? El propio algoritmo por detrás En la variable hombre Y en la variable mujer ¿Vale? En inglés Y con el título del sex De la variable de la que viene nos ha hecho sex mail y sex female vale que ha hecho entonces ha dicho vale este caso es hombre por lo tanto en donde sería un 1 el siguiente mujer sería un 0 porque nombre pues no es no es hombre por lo tanto tendríamos aquí el siguiente mujer 0 0 a tengo un hombre a que es un 11 entonces aunque nosotros no hayamos visto el propio algoritmo por detrás ha sido lo suficientemente inteligente como para crear una variable ¿vale? en la cual va recogiendo los datos, 1 si se cumple y 0 si no se cumple entonces, en base a esto y en base al p-valor ¿recordáis cuando se aceptaba una cosa y cuando no se aceptaba otra cosa? ¿os acordáis? el valor era 0,05 ¿vale? entonces, cuando es menor de 0,05 si es mayor se lo echas si es menor se lo echas Exacto. Exactamente. Entonces, ¿qué podríamos decir? Que aquí la variabilidad en este resultado, al ser mayor que 0,05, lo que nos está diciendo es que no es significativa. ¿Sí? En cambio, la variable en este caso de sexo, fijaros, sí que sería significativa. Y en este caso, la tarifa también sería significativa. ¿Vale? ¿Ha quedado claro cómo podemos analizar una regresión logística? Ya veremos cómo predecimos o clasificamos con esto. Sí. En caso del sexo, había solamente dos posibilidades, male, female. Exacto. Pero si tenemos más que dos, ¿hay que convertirlos antes en valores numéricos o igual el algoritmo lo hace por su cuenta? Vale, en teoría el algoritmo lo hace por su cuenta. Esta es la teoría, ¿vale? Sí que es cierto que los algoritmos, por ejemplo, si tú haces una regresión logística en Python, no siempre te va a permitir el que pongas variables categóricas entonces, mi recomendación personal, intentaré en una clase también enseñaros a esto yo siempre, en mi día a día paso primero las variables categóricas a textos y luego más seguro del algoritmo pero también por otro motivo en este caso ha sido muy sencillo adivinar que uno es que sea hombre y cero es que sea mujer ¿vale? pero tú imagínate otro caso completamente diferente en el que tomes un montón de valores, no siempre te va a ser tan sencillo, entonces si tú haces la conversión, personalmente tendrás la clave para poder dar marcha atrás y saber lo que significa en cada uno de los puntos mejor, ¿vale? En realidad, regresión logística en R debería funcionar bien, ¿vale? Aunque tenga más variables, pero sí que es cierto que yo personalmente siempre traduzco las variables antes en mi día a día de categóricas a numéricas y luego paso al algoritmo porque tendrás algoritmos que no te lo hagan. Entonces, como vas a tener que probar con 200 algoritmos, casi es mejor hacer algo que funcione para todos que ir intentando modificar según qué algoritmo. Entonces, al final haces la traducción antes y luego aquí la pones ya numérica. ¿Sí? No sé si te he respondido. Vale, perfecto. De acuerdo, entonces, por hoy, ¿vale? Esto es lo que vamos a ver, ¿de acuerdo? en este sentido sí que me gustaría enseñaros una cosita más pequeña que nada son cinco minutitos pero sí que me gustaría enseñaros lo que os he comentado anteriormente imaginemos que yo quiero hacer la media de la edad pero para los supervivientes y la media de la edad para los que no sobrevivieron quiero tener esta estadística ¿cómo puedo hacerlo? bueno pues esto se utiliza un paquete que tampoco viene por defecto que es deplir. Cuando vosotros hacéis la librería, la library de deplir, bueno, perdón, vosotros lo tenéis que instalar, en mi caso es que ya lo he utilizado tantas veces que ya está instalado. Esta librería lo que nos va a permitir, aparte de hacer filtrados un poco más complejos con la palabra filter, por ejemplo, podemos decir, bueno, yo tengo mis datos, pero quiero los datos de los supervivientes. ¿Qué haré? Pues voy a hacer un filtro donde la columna correspondiente de datos, por ejemplo, datos survived, sea, hemos dicho supervivientes, ¿no? Pues sea igual a igual a 1, ¿vale? Ponemos dos iguales. Vale, me está dando un error que no debería estar dando. Sí, son dos iguales, perfecto. Y la columna no debería ser survived. porque tiene una clase rara bueno voy a poner otra y ya os enseño ese otro día porque voy un poco justa de tiempo entonces ponemos la edad por ejemplo que sea mayor de 20 años entonces cuando nosotros tenemos esta edad mayor de 20 años con la palabra filter vale, espera un momento que me estoy aquí encallando y no debería ser el caso vale, esto está correcto y tenemos la palabra filter, que esto también sería correcto y te hacé una pregunta en esos casos no se tiene que usar algo como porcentaje mayor, porcentaje creo que es como para decir que está dentro del conjunto esto después cuando hagamos el group by haremos el porcentaje mayor porcentaje bien visto vale el porcentaje mayor porcentaje también es del de plis vale pero en este caso cuando utilizaremos el filtro podemos hacer bien datos porcentaje mayor porcentaje filtro creo que recordar que es también funciona pero lo que al final que se utiliza más es filtro luego pones aquí el data set que serían datos y la condición vale podemos poner ahora si me saldrá porque no estaba poniendo el el data set es urbano igual a 1, ahora sí que debería salir sin ningún tipo de problema. Si nosotros vemos datos de supervivientes, ¿qué tendremos? Tendremos todas las columnas, así se ve mejor con el view, tendremos todas las columnas en las cuales survive tiene valor 1. Esto es una de las cosas que podéis hacer con filter de manera más o menos sencilla, Ponéis el conjunto de datos que tenéis y la condición por la cual queréis filtrar. Y ahora es lo que sí que os quería comentar, que es el tema de los group by, que aquí utilizaremos los porcentajes, entonces imaginemos que nosotros queremos hacer la media para los supervivientes y la media para el caso de que hayan fallecido. entonces nosotros haríamos datos o por ejemplo estadísticas de la columna survived y que vamos a hacer tenemos que poner primero los datos estamos con datos limpios después de estos datos limpios tenemos que hacer agrupar porque vamos a hacer un conjunto de estadísticas cuando es uno y un conjunto de estadísticas cuando es cero es como estamos haciendo dos subgrupos dentro de nuestro dataset Entonces, porcentaje mayor porcentaje y aquí haremos el groupBy. Dentro del group barra baja By tenemos que especificar la columna por la cual queremos que lo haga. En este caso por la columna survived. Para completar podéis darle al tabulador y en principio os lo completa bien. Y después queremos hacer en este caso la media. Entonces utilizaremos una función que se llama summarize y tenemos que decir cómo queremos que se llame la columna de la media y luego qué tipo de métrica vamos a utilizar. Por ejemplo, en este caso sería la media de la edad, entonces media edad. Y qué vamos a poner aquí, la media de la columna, en este caso de la columna edad. Entonces haríamos media de la columna age. Nosotros esto lo generamos y ahora voy a mirar lo que está dentro de estadística Surpike, tendremos que para las personas que fallecieron la media era de 30,6 y para las personas que sobrevivieron la media es de 28,3. Podéis hacerlo con más cosas, no tiene que ser simplemente la media. Podéis decir, oye, yo quiero también la varianza. Perfecto, varianza, edad, var, age. entonces cuando hagáis esto pues tendremos la media de la edad y la varianza de la edad, ¿se ha entendido? iremos viendo este tipo de métricas también porque son bastante interesantes y bastante útiles, mientras vamos dando también el resto de programas de Machine Learning ¿vale? ¿queda claro lo que hemos visto hoy? hemos visto la regresión logística significa que para tú decir si una persona ha sobrevivido o no ha sobrevivido tú lo puedes hacer en función del sexo y en función de la tarifa aquí decís que para que tú hagas limitaciones de la regresión logística la primera de todas, solo puedes tener dos categorías, solo puedes predecir 0 y 1, sí y no, 1 o 2, cliente o no cliente, enfermo o sano, digamos que solo puedes tener dos posibles opciones. Cuando necesitas más de dos opciones, la regresión logística ya no es la mejor opción. Luego, más temas de complicaciones respecto a la regresión logística, ya estaríamos hablando que depende del contexto, el resultado de la regresión logística te va a dar mejor valor o menor valor. matemáticamente es una inversa de una exponencial más sumándose en el denominador elevado a un exponente negativo entonces por otra parte a veces es un poco complicada de interpretar si utilizamos un árbol de decisión veréis que en la mayoría de las cosas podemos llegar incluso a extraer el cómo el árbol ha dicho este va aquí o este va aquí podemos tener esas reglas En el caso de la regresión logística funciona muy bien, es bastante sencillo de aplicar, pero a veces no es tan sencillo de poder interpretar o poder deducir tú a mano exactamente lo mismo. Chega un poco las limitaciones que tiene. Pero la mayor es la de ceros y unos, tiene que ser sí o sí dos categorías. vale pues entonces os subiré este documento de acuerdo y os subiré siempre con más explicaciones ya lo sabéis y muchísimos más ejemplos para que podáis hacer en casa y os subiré otro documento bueno espera si ya os puedo miraros en la pantalla principal que os tengo aquí en esta segunda y os subiré otro documento con funcionalidades del de Plir para que lo podáis utilizar podáis probar hay algunas cositas más pero bueno para que podáis en casa a ir mirando las funcionalidades. El de PIR es interesante, sobre todo cuando quieres hacer análisis estadísticos en base a valores que ha tomado otra columna. El día de hoy. Referente a la función logística. Suponemos que yo quiero hacer una predicción. Está claro que no tenemos la fórmula, pero el algoritmo sí la tiene. Entonces yo quiero hacer predicción si va a sobrevivir o no va a sobrevivir la persona de tal edad ¿cómo se hace? vale, esto lo que hacemos es hay una función que tú con el nombre de la regresión logística luego puedes poner el predict, le das valores de las mismas columnas, en este caso por ejemplo le dices, bueno pues mi edad son 23 por ejemplo el sexo es mujer y luego te dices que la tarifa son 50 euros por ejemplo y tú cuando le hagas el predict el propio algoritmo ya te va a hacer la predicción y te va a decir pues mira 0 o 1, bueno realmente la regresión logística no da como todo el 0 y 1 porque lo que nos da es la probabilidad entonces el resultado que te dé la regresión logística luego lo redondeas a 0 o lo redondeas a 1 ¿sí? ¿te he resuelto la duda? en el archivo que va a subir tal vez podría poner este ejemplo de programación ¿ponga los dos? vale por supuesto De hecho, si queréis también, porque realmente esto es un poco lo que os comento, lo que tenemos que daros, lo que habitualmente se da en esta clase, ¿vale? Si queréis también os pongo cómo debería ser la traducción de variables categóricas a numéricas antes, para que lo tengáis también de referencia, aunque intentaré encontrar un tiempo para ponéroslo. y también os pondré la parte de descomponerlo en lo que os comentaba, el 70% en entrenamiento generamos el modelo y luego el 20% para testearlo con la matriz de confusión y así tenéis una regresión logística completa, completa, completa como la tendríais en el día a día que lo utilicéis. Porque hasta ahora hemos hecho la parte de entrenarlo con todo el conjunto de datos, pero en la vida real lo que se hace es desde todo el conjunto de datos se selecciona un 70% con el cual creas el modelo y luego seleccionas un 30% con el cual compruebas si el modelo es correcto, como con la matriz de confusión. Si os añado esto, ¿os gustaría más? En teoría, para el curso es hasta aquí, hasta lo que hemos visto el día de hoy. Pero si preferís que os dé un ejemplo completo, por mi parte no hay ningún tipo de problema. Os lo doy sin problema. Os subo los dos, si queréis. os subo la clase como tal y luego un ejemplo que sea regresión logística completo y ahí que lo tengáis creo que esa opción puede ser quizá la mejor vale, pues os subo eso, ¿de acuerdo? así que por hoy esto sería todo, espero que os haya gustado y nos vemos la siguiente clase, ¿vale? pero pensad que para la asignatura de hoy, de momento es única y exclusivamente hasta que lo hemos visto ahora, aunque luego os dé más información o cómo se haría en un caso más completo, ¿vale? así Así que nos vemos. Muchísimas gracias a todos y nos vemos el próximo día. Adiós.
