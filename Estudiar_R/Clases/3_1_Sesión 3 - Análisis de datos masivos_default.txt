Hola, buenos dias, buenas tardes, buenas noches a todos. Muchas gracias por estar en esta clase en directo, también a aquellos que veis esta grabación. El día de hoy, ¿qué vamos a hacer? Vamos a ver una parte que sería la estadística descriptiva y luego continuaremos con nuestro proyecto en el estudio. Cualquier duda, cualquier cuestión que tengáis, sin problema me lo podéis comentar y os la intentaré solucionar lo antes posible. Así que voy a empezar compartiendo pantalla. Un momentito. Y empezaremos viendo un poco la parte de teoría. Entonces, ¿a qué nos referimos cuando hablamos de estadística descriptiva? Existen varios tipos dentro de la estadística. Actualmente nos vamos a centrar en la descriptiva. Y viene siendo la estadística que conocemos todo el mundo. Lo que sería la media, moda, mediana. Esto sería la estadística descriptiva. Luego existe otro tipo que se llamaría la estadística inferencial, pero que esta en principio, al menos en esta clase, no la vamos a tocar. Vamos a repasar algunos conceptos estadísticos y la estadística aplicada a la economía muchas veces no se llama ni siquiera estadística, sino que se llama econometría. Entonces vamos a intentar ver un poco lo que sería la estadística y la econometría en las distintas empresas o en el funcionamiento de una empresa. ¿Qué es la econometría? Es una asignatura que la verdad es bastante interesante. ¿Por qué? Porque es cómo aplicamos la estadística a los ámbitos económicos. Por ejemplo, aquí cuando decimos que existe un modelo económico, por ejemplo, para predecir un indicador como puede ser el productor interior bruto, aquí estaríamos hablando de econometría porque estamos haciendo un modelo estadístico aplicado a la economía. Entonces la idea es que tenemos una serie de problemas económicos que queremos modelizar vía matemáticas o estadística y por tanto surge esta ciencia que sería como un híbrido, como una mezcla entre ambas. en este sentido también comentar que en el caso de la estadística y la econometría un poco lo que pensamos, ¿cuál va a ser nuestra base? la base son los datos, es muchísimo más el análisis que se hace de datos en estas casuísticas incluso de lo que se piensa, al final cuando nosotros estamos estableciendo un modelo o cuando estamos analizando si algo sube o algo baja a lo largo del tiempo Por ejemplo, en el caso del precio, realmente siempre lo hacemos en base a unos datos, en base a un histórico. Así que está muy relacionado con el análisis masivo de datos. En este sentido, dentro de la estadística descriptiva, ¿qué vamos a tener? Pues tenemos análisis de correlación que nos van a decir cómo están relacionadas ciertas variables. Veremos que aquí sí que quiero hacer una puntualización porque muchas veces se lleve a error. que dos variables estén correlacionadas no significa que una cause el efecto de otra sino simplemente que cuando aumenta una en el conjunto de datos que tenemos por ejemplo, se aumenta el precio por ejemplo, ¿vale? o se aumenta la calidad en el conjunto de datos que tenemos aumenta el precio habrá veces que tendrán relación entre ellas es decir, es normal que cuando aumenta la calidad de un producto evidentemente aumente el precio pero hay otras veces que simplemente puede llegar a coincidir ¿vale? que ese aumento de la calidad se produce cuando hay un aumento de temperatura, por ejemplo. Y no tiene que ser que el aumento de temperatura directamente haya influido en ese aumento de calidad. Entonces el análisis de correlación lo profundizaremos mucho más adelante, pero lo que nos indica es cómo evolucionan las variables. Si evolucionan en el mismo sentido o no evolucionan en el mismo sentido, evolucionan en sentido contrario. Tendríamos el análisis de regresión. Esto lo veremos cuando queramos predecir valores numéricos en base a un histórico. Y luego tendríamos todo el tema de los contrastes de hipótesis que no estaría dentro de la estadística descriptiva y que aquí lo que hacemos es básicamente lanzamos hipótesis e intentamos rebatirlas. Intentamos ver si se cumple o no se cumple. El día de hoy nos centraremos sobre todo en la estadística descriptiva y llegaremos a la correlación y covarianza muy probablemente. Entonces, en este sentido, ¿qué hace la estadística descriptiva? Pues nos muestra la información clave, la primera información que tenemos de nuestro conjunto de datos, ¿de acuerdo? ¿Qué conocemos por estadísticos o por momentos estadísticos? Pues lo que conocemos, ¿vale? La media, la moda, la mediana Tendríamos también los cuartiles, los cuantiles Entonces nos permite sintetizar toda esta información y es cierto que no únicamente incluye métricas o incluye fórmulas matemáticas, también incluye los gráficos, el saber representar dos variables entre sí o por ejemplo representar la frecuencia de una variable o los tipos de datos que podemos tener en una variable sería importante dentro también de la estadística descriptiva. En los siguientes casos nos vamos a centrar también sobre todo en la media varianza, moda, media y rango, aunque existen muchos más estadísticos que fijo conocéis y sí que me gustaría profundizar lo que sería el diagrama de cajas o el boxplot. Para mí es una herramienta fundamental en todo lo que queráis hacer con análisis de datos masivo porque nos aporta muchísima más información. Desde un boxplot vamos a poder, por ejemplo, encontrar puntos que son anómalos, puntos que son extraños. Vamos a poder encontrar también de un vistazo el valor de la mediana, del primer cuantil, del segundo cuantil. Tenemos también información de cómo de dispersos son los datos, entonces al final un boxplot, saber hacer correctamente un boxplot nos va a dar una información muy útil de cara al tratamiento de datos. Luego me gustaría ponernos una imagen y narrároslo, aunque luego sí que es cierto que haremos una sesión que probablemente dibujemos lo que es un boxplot y ANR. entonces, la media, tenemos este tema, ¿qué es la media? la media no es más que una forma de encontrar el valor que está en el punto medio en este punto existen varios tipos de medias, aquí tenemos dos, que es la media aritmética y la media ponderada en realidad existen muchísimas más, tenemos la media armónica, tenemos la media geométrica pero sí que es cierto que las que más se dan en lo que sería el análisis masivo de datos serían estas dos, la aritmética y la ponderada. Cuando hablamos de la media aritmética es la que conocemos siempre, sumamos todos los casos, dividimos por el total de casos y eso será nuestra media aritmética. Cuando estamos hablando de media ponderada, ¿qué hacemos? A cada uno de los valores lo vamos a multiplicar por un peso y dividimos por la suma total de los pesos. Aquí creo que hay un error, en lugar de n sería la w, porque es la suma total de los pesos que generalmente suele dar uno. ¿Qué ocurre con la media? ¿Es fiable esta variable? No. Imaginemos, pongamos un caso, ¿vale? Imaginemos que yo tengo el siguiente conjunto de datos. 1, 1, 2, 1 y 10.000 o 1.000, ¿vale? ¿Cuál será la media? Os pregunto. Podéis utilizar calculadora o lo que queráis. a ver si alguien me hace la cuenta ¿cuál crees que sería la media en este caso? pues tendríamos que sumar todo 1 más 1 más 2 más 1 más 1000 perfecto 201 entre y en este caso haríamos los 5 valores 201 ¿creéis que este valor representa bien como media este conjunto de valores? Os pregunto. No, efectivamente, ¿por qué? Porque 1000 es un punto extraño, ¿no? O sea, a priori tenemos unos, tenemos dos, tendríamos tres, pero que de unos dos es el siguiente valor sería 1000, sería un punto que es extraño, ¿vale? estos puntos que son extraños se llaman outliers o valores anómalos y no siempre significa que haya un error, ¿vale? Es decir, muchas veces o la mayoría de las veces será un error y tendremos a eliminarlos pero hay veces que no se corresponden a un error y que son datos que son fiables, ¿vale? Pero la mayoría se corresponden a un error. ¿Qué ocurre con la media? Que ante la presencia de estos valores, que los podremos ver fácilmente en un boxplot pues se distorsiona, ¿vale? Yo esperaría de aquí una media más en torno al 1 y al final he tenido una media de 201. Para ello muchas veces se utiliza la media recortada o la mediana, ¿vale? La media recortada, o sea, la mediana es quitando el 50% de los datos y la media recortada pues es quitando un porcentaje de los datos de los extremos, ¿vale? Se ordena los datos de menor a mayor y se van quitando porcentajes de los extremos, de forma que quitamos estos datos anómalos, ¿vale? El caso de la mediana, por ejemplo, para que os hagáis una idea. Imaginemos que yo tengo el siguiente conjunto de datos. Para calcular la mediana, lo primero es que tengo que ordenarlos de menor a mayor. Vamos a poner aquí que hay otro 1. Si hay dos 1, pues será 1, 1, 2. Luego tendríamos el 3, el 5, el 8 y el 7. ¿Qué hace la mediana? La mediana va tachando los elementos, entonces tacha este extremo con este extremo Perdón, he ordenado mal esto, que no he visto esta última que es el 7, aquí sería el 8 y el 7 al revés ¿Qué hace la mediana? Pues hacíamos el 1 y el 8 se me van, el 1 con el 7 se van, el 2 con el 5 se me van Y el error que queda en medio, en este caso el 3, sería la mediana. Cuando nosotros teníamos algún caso, como puede ser, sí, también se puede calcular con fórmulas. Si exigen fórmulas para calcularlo, de hecho, normalmente para la mediana lo que se suele hacer es, se selecciona el conjunto de datos, se divide entre dos y se va a buscar en qué grupo cae de frecuencia ese conjunto de datos. entonces aquí tendremos pero para que lo entendáis conceptualmente que realmente nosotros aquí no vamos a hacer ningún tipo de cálculo manual sino que lo va a hacer todo el ordenador vale entonces para que entendáis mejor que es la media y la mediana pues en este caso que haríamos 1 con 1000 se van 2 con 9 se van 3 con 7 se van vale quiero que me salga uno y aquí me quedan dos elementos entonces la mediana será la media de estos dos elementos que es 5 con 5 vale entonces ¿por qué no son sensibles outliers y por qué se utiliza la media recortada a la mediana? porque también estamos hablando de tener el valor del centro pero si os dais cuenta los outliers siempre se van quitando porque un outlier siempre es porque está muy por arriba o porque está muy por abajo con lo cual en el caso de utilizar la mediana los estamos quitando y eso hace que la mediana sea mejor o más fiable que la media en caso de tener outliers. En este punto también tendríamos la moda. La moda es básicamente el valor más frecuente o repetido y sí que es cierto que la moda se suele utilizar sobre todo para lo que son valores que son de tipo texto. De tipo texto lo que se suele utilizar es la moda, el valor que más se repite, cuántas veces se repite este valor y cuántos datos tenemos. Cuando hablamos de variables que son numéricas o de tipo número es cuando utilizamos media, media ponderada, mediana y muchísimas más cosas. Tenéis un ejemplo. En este caso de la media aritmética, ¿qué hacemos de la media aritmética? Pues vamos a sumar, quiero la cuota de mercado porque es lo que quiero saber, 12 más 5 más 3 más 4 dividido entre los posibles, pues 6. La cuota de mercado media de todos los países sería en este 6%. Ahora, ¿yo qué quiero? quiero añadirle un peso, es decir, quiero dar más importancia en vez de este 12%, yo lo que quiero dar más importancia es ahí tal, porque si os dais cuenta tenemos más ventas totales, es decir, quiero sobreponderar o dar más importancia a Italia de lo que damos a España, Francia y Portugal. Entonces, ¿qué haríamos? Fijaros, para ello se calcula un peso, ¿y cuál va a ser este el peso? Pues vamos a seleccionar cada una de estas ventas totales y lo vamos a dividir entre el total de sumar todos estos elementos, que esto es lo que nos darían estos 2.000 que veis abajo. Entonces esto es lo que yo voy a llamar WI, que eran los pesos que comentábamos. Entonces aquí tendríamos en este caso la media ponderada. Hay veces que se hace así y por tanto divides aquí entre 4, hay veces que directamente la fórmula de la ponderada es el peso y en este peso ya están dividiendo entre este 4, entonces es el peso por el x y dividido por la suma de los pesos. Hay muchas veces que es así dependiendo como os lo pregunten, pero en este caso la fórmula que os han dado es sin tener en cuenta o teniendo en cuenta la n para dividir. Si hay dudas, por favor me comentáis, sin problema. Entonces, si tenemos otro establecimiento, otro ejemplo, tenemos los establecimientos A, B, C, D, E y F, y tenemos España y Francia, y queremos saber la media aritmética de España. Pues, ¿qué haríamos? Sería sumar este 100 más el B, que es 150, 180, 150, 120, 500, y dividimos entre 6. os pregunto, ¿creéis que en España hay algún valor que podamos considerar como auto layer? ¿O anómalo? ¿Qué opináis? 500 Exacto, exacto, ¿vale? O sea, sería un número que si os dais cuenta siempre está entre los 100 y 120 y de repente serían 500 Es raro, ¿vale? Quiere decir que no es posible tener 500, por supuesto que es posible a lo mejor resulta que el establecimiento tiene una campaña de marketing tan grande que de repente tiene 500 personas. Pongamos, por ejemplo, que en vez de establecimientos estuviésemos hablando de cantantes. Si comparamos, por ejemplo, me lo estoy inventando, pero por ejemplo comparamos un cantante que puede ser tradicional de España con, por ejemplo, Taylor Swift, la diferencia sería muy grande. y eso no quiere decir que sea un dato, digamos, anómalo el hecho de los cantantes de Taylor Swift, o sea, anómalo es, pero no es de los fans, ¿vale? Anómalo sería, pero no es un error, ¿vale? Entonces, sí que es importante entender que los datos pueden ser auto-lays anómalos, pero a veces serán errores y a veces no serán errores, habrá que analizarlo, ¿vale? Perfecto. Y en el caso de Francia tendríamos que haríamos la suma de todos los valores dividido entre 6. Si os dais cuenta las medias coinciden en ambos casos serían 200 pero si vamos a ver el comportamiento de los establecimientos en Francia parece que siempre tienen mejores ventas que en España con lo cual este comportamiento sería raro. ¿Qué podemos hacer? Podemos hacer la media recortada, si seleccionamos la media recortada tenemos que especificar, que aquí no lo hemos puesto, pero tenemos que especificar de cuánto, por ejemplo la media recortada del 10% de los datos o la media recortada del 20% de los datos, pero tenemos que especificar cuánto porcentaje estamos quitando. Por ejemplo, aquí tenemos 5, partíamos de un 6, pues estamos quitando 1 entre 6, que he multiplicado por 100. 1 entre 6 sería 0, y tendríamos un 10, 10 entre 6 sería 1. Me sobraría un 4, 40 entre 6 tendríamos que sería 1, 6 por 6 es un 36. Sería 6, 6, 6 periódico. así que aquí está haciendo la media recortada al 16, o sea, quitando el 16,66% de los datos, ¿vale? porque está quitando uno es simplemente que vosotros cuando lo hagáis pues decir, pues quito un dato, pero tenéis que especificar por qué es media recortada o sea, cuántos valores quitamos gracias Jonathan que no te haya visto el 16,67 gracias vale, entonces, en este caso si os dais cuenta debería serlo, ¿vale? normalmente cuando hacemos la media recortada decimos media recortada ahora veremos en en r porque se puede hacer la media con un trim y te lo recorta de ambos lados de ambos extremos vale pero bueno en este caso lo han hecho para que entendáis más bien el caso vale así que la han recortado solo de uno pero lo normal sería que quitáramos un valor de aquí y un valor de aquí eso sería lo más lo más lo más normal dicho esto tendríamos aquí la media recortada que son 140 que sí que ya es más asemejada a la que nos reflejan los datos. Esto es importante. Ante presencia de outliers, mejor no fiarse de la media aritmética. Aquí os pone la media recortada para mi gusto y lo que se suele utilizar en el día a día es utilizar la mediana. De hecho, la media recortada os la voy a enseñar, pero no es lo que más utilice. Se suele utilizar sobre todo la mediana, que es el 50%. Ya os explicaré también qué significa la mediana y por qué es importante aparte de por esto. ¿De acuerdo? Entonces, ¿qué más opciones tenemos? Tenemos la varianza. Aquí ya no estamos en medidas de tendencia central que buscan el centro, sino que estamos mirando cómo de dispersos o concentrados están los datos. Por ejemplo, para que os deis cuenta de la idea de esto. Si nosotros analizamos el precio de una acción y yo veo que los precios de esa acción en un mismo día van del 1 al valor 100 a 100 dólares por acción, ¿creéis que sería una acción en la que invertiríais o no invertiríais? Es decir, vosotros tenéis una acción que tendríamos un dólar, de repente es un dólar, de repente son dos, de repente son 50, de repente son 20, de repente son 100 el mismo día. ¿Qué decís? ¿Invertiríais o no invertiríais? No, es muy volátil. efectivamente, dependiendo del valor de la acción efectivamente, pero es muy volátil entonces tenderíais a considerar que hay mucho riesgo de inversión ¿vale? esto de que sea muy volátil al final es que hay una gran variabilidad de los datos, es decir, los datos están muy dispersos y cuanto más variabilidad, más volatilidad lo que tendríais es que más riesgo también más riesgo implica mayor rentabilidad pero digamos que es más probable que acabéis perdiendo lo que sería un poco el dinero porque es bastante arriesgado. Entonces, la volatilidad, cuando hablamos de la volatilidad del mercado financiero, hasta cierto punto es el mismo significado que la varianza. Sí que es cierto que hay unos conceptos matemáticos subyacentes por detrás para poder decir esto, pero por eso, entre otras cosas, es importante, porque nos miden cómo de concentrados o cómo de dispersos están. Por ejemplo, otro caso. Si toda una clase saca notas, Imaginemos que sacan todos 4, ¿vale? Todos están suspensos. Unos sacan 2, otros 3, otros 4, otros 5, ¿vale? Y luego tenemos otra clase en la cual la clase B, por ejemplo, tenemos 3 10, 2 5 y 2 4 también, ¿vale? 3 10, 2 5 y 3 4. ¿qué opináis? ¿en qué clase creéis que el profesor enseña peor? os pregunto si tenemos una clase en la cual la concentración está en torno al 4 si tenemos 4, 3, 4, 5 4, 2, 4, 3, 4, 5 4, 2 y otras que tenemos 10, tenemos 5 y tenemos 4 ¿qué opináis? si os resuelvo ya la pregunta porque es un poco rara. Segunda clase. ¿Cuál? En la segunda clase donde existe mayor dispersión. Efectivamente, en la segunda clase existe mayor dispersión. Perfecto. Ahora, para mí sería peor la primera clase en el sentido de que si todo el mundo me está sacando 4, 3 y 2, es que no he dado muy bien la teoría, ¿no? Efectivamente, entonces la primera clase es más concentrada y la segunda clase es más dispersa. Aquí quiero decir que el tema de que tenga mayor variabilidad o menor variabilidad, esté más concentrado o esté más disperso, no es que una cosa siempre sea la mejor que la otra, sino que depende mucho del contexto. Pero creo que habéis entendido que es dispersión y que estén dispersos y que estén concentrados. Y para esto lo generamos con la varianza. Restamos a cada uno de los datos la media que hemos calculado previamente. A esa resta la elevamos al cuadrado y lo dividimos entre el número total de muestras. Muchas veces en vez de hablar de varianza, hablamos de desviación típica, que no es más que la raíz cuadrada. Entonces, efectivamente Jonathan en la primera. Entonces, otra opción, el rango. El rango no es más que coger el valor máximo y el valor mínimo y restarlos. Es una forma también de medir cómo de dispersa está la muestra. ¿Mejor o peor que la varianza? Bueno, diferente, ¿vale? Sí que es cierto que siempre es más rápida de calcular, pero la métrica por excelencia de la dispersión siempre va a ser la varianza, ¿vale? Y luego tenemos el coeficiente de variación muy importante, ¿vale? No de cara al examen ni nada de esto, pero muy importante el coeficiente de variación. ¿Por qué? ¿cómo sé yo que la varianza es aceptable? ¿cómo sé yo que mis datos estén muy dispersos o no muy dispersos? ¿en qué ayuda sacar de la raíz cuadrada la varianza? vale, en este caso primero imagínate que tú estás hablando de euros si tú haces la varianza al elevarlo al cuadrado si tú estás hablando de 100 euros cuando le ves al cuadrado vas a estar hablando de 10.000 vale, entonces el resultado de la varianza siempre te va a dar unas unidades muchísimo mayores y que te va a costar identificarlo. Por ejemplo, imaginemos que estamos hablando de la varianza de años de una población. ¿Qué ocurre? Que a lo mejor te sale que hay gente que se diferencian en 100 años al cuadrado. Entonces, a lo mejor te puedes confundir y me dices, ¿cómo va a salir una varianza de 100 si yo estoy hablando de años? Si no puede haber diferencia de 100 años entre personas. Eso es porque en realidad eso sería en 100 años al cuadrado. cuadrado, ¿vale? ¿Qué ocurre con la desviación típica? Que digamos que al hacerle la raíz cuadrada ya nos sale ese 10 y podemos decir, ah, vale, ya entiendo, son los 10 años que se diferencian una persona de otra, ¿vale? Entonces, en este punto, el hecho de hacer la raíz cuadrada es para poder compararlo con los datos que tenías al inicio en términos de magnitud. ¿Se ha entendido, David? Perfecto. Pero me causa duda, profe. Es que me causa duda, entonces, ¿por qué en la varianza se eleva al cuadrado en primer lugar? Vale, se eleva al cuadrado por lo siguiente, porque no es lo mismo, o sea, tú aquí lo que estás haciendo es x1 menos la media al cuadrado más x2 menos la media al cuadrado más lo que sea, ¿vale? No es lo mismo hacer la raíz cuadrada de una suma que hacer la suma, lo divides por n, esto no es lo mismo que hacer cada una de las partes por separado. ¿Sabes? No es lo mismo que hacer esta raíz cuadrada de x1 menos x barra al cuadrado. Aparte también está lo que ha comentado Jonathan, ¿vale? Del tema de eliminar los signos. Esto también lo podríamos hacer con lo que serían los cuadras, las valores absolutos, ¿eh? Pero no es lo mismo que hacer o sea, la suma, o sea, cuando haces una suma y lo divides entre n, no es lo mismo que hacer cada una de las partes. O sea, matemáticamente sí que es cierto que hay una fórmula, ¿vale? Que esto lo podemos poner o lo podemos escribir de otra manera, que si no recuerdo mal, ¿vale? Era la esperanza matemática, que es otra forma de denotar estadísticamente la media, ¿eh? La esperanza matemática de la media al cuadrado menos la media al cuadrado. Creo que era algo así, pero bueno, como no me acuerdo exactamente de la fórmula, la fórmula que siempre se da es esta, ¿vale? Pero ese es el motivo, porque matemáticamente no es lo mismo hacerlo de una forma que otra. Y efectivamente Jonathan, gracias por traducir lo que dije antes, que a veces me lío un poco las palabras, lo que os comentaba las unidades están al cuadrado, por lo tanto lo que os comentaba nos puede salir 100 porque son 100 años al cuadrado pero cuando hacemos la desviación típica ya lo asemejamos a los 10 años ¿vale? Que sería a lo mejor la dispersión o la desviación que hay en una población. Gracias. Vale, entonces, estábamos con el tema del RAT, no sé si había alguna pregunta más Ah, vale, Irina, ¿a qué valor correspondería que no existe un sesgo de dispersión significativas? Sí, aquí hay diversas tendencias, ¿vale? Lo que nos dice el, justamente creo que te voy a responder, creo que justamente es lo que iba a comentar ahora entonces el coeficiente de variación ¿qué pasa? que yo no sé exactamente cuál es el valor de la varianza para decir si está dispersa o no está dispersa entonces para eso existe el coeficiente de variación se suele tener un 0,3 y en función lo que hacemos es la desviación típica dividirla entre la media aquí no parece pero esto es una media y multiplicarlo por 100 ¿De acuerdo? Entonces, en función de si esto es, normalmente se dice 0,3, ¿vale? A menos que especifican lo contrario. Entonces, en función de si es más de 0,3 o menos de 0,3, se puede considerar, ¿vale? Aquí hay distintas posturas, ¿eh? Pero la postura más conservadora sería esa, para indicar si hay una dispersión o no hay dispersión, ¿vale? Entonces, esta sería la parte de la estadística descriptiva, ¿vale? Y veamos un ejemplo. tenemos en estadístico España y Francia, la media nos ha salido que en España tenemos 2.000 y en Francia tenemos 3.000 de media pongamos por ejemplo, me lo invento, 2.000-3.000 personas por ejemplo en las respectivas ciudades, tenemos todas las ciudades de España, hacemos la media y nos sale que el número me lo invento, o el número de niños por ciudad, el número medio serían 2.000 en España y 3.000 en Francia. Cuando hacemos la desviación típica en cada una de esas ciudades, nos sale una desviación típica de 400 y de 500. Por lo tanto, para yo poder saber qué muestra está más dispersa, fijaros que a priori diríamos, no, Francia. Francia es la muestra más dispersa. ¿Por qué? Porque tenemos que la desviación típica es 500 y es la mayor. pero sin embargo cuando lo dividimos por la media para sacar el coeficiente de variación nos podemos dar cuenta que España en realidad es más disperso aunque los otros pueden ser más pequeños pero España en este caso está siendo más disperso que Francia entonces esto es un ejemplo de por qué es importante el coeficiente de variación porque tendemos a pensar que la desviación típica lo es todo pero no es el caso de hecho este es un caso muy concreto en el que la desviación de España es menor La desviación típica es menor que en Francia, pero cuando calculamos el coeficiente de variación que me dice el porcentaje de variabilidad, tendríamos que en España es mucho más dispersa que en Francia, ¿vale? Así que esto es interesante para que lo tengáis. El coeficiente de variación también es súper importante y a veces no se le da la importancia que realmente tiene, ¿vale? Entonces nos permite comparar también varias cosas. De acuerdo, veamos ahora el tema de la correlación, ¿vale? ¿Qué es la correlación? Es un poco lo que os comentaba, la relación que existe entre dos o más variables. En este sentido, para calcular la correlación, muchas veces necesitaremos calcular la covarianza, que veremos qué es, y el coeficiente de correlación. ¿Qué es la covarianza? La covarianza es básicamente parecido a la varianza, pero lo hacemos entre dos variables diferentes. Entonces, lo que realmente creo que tenemos, no sé si tenemos la fórmula por aquí, creo que sí. ya veremos cómo se calcula pues no lo tenemos pero bueno lo que hacemos es básicamente algo parecido a lo que habéis hecho aquí de xy menos la media de x al cuadrado parecido, no igual le añadimos también las y que serían las otras variables y aquí tendríamos que conforme tenéis la covarianza ya podríamos tener una relación de las mismas pero nos pasa un poco como el coeficiente de variación que para poder medir bien bien bien a cómo de relacionadas están dos variables vamos a calcular un número que va entre menos 1 y 1. De esa forma tendremos el valor máximo que puede tomar el coeficiente de correlación, el valor mínimo y podremos decir está más cercano a 1 pues tiene una correlación fuerte positivo, está más cercano a menos 1 pues tiene una correlación fuerte negativa, negativa está más cercano a cero pues no existe correlación vale tenemos así un intervalo en función en el cual yo puedo situar mi coeficiente de correlación entonces cómo se muestra esto bueno aquí tenemos covarianzas positiva negativa y cercana a cero vale que es un poco lo mismo que en el caso del coeficiente de correlación cuando tenemos una covarianza positiva imaginemos el típico caso de que os había comentado antes tenemos un índice de calidad y un índice de precio qué ocurre que cuando yo aumento la calidad el precio aumenta esto sería una varianza una covarianza positiva que cuando aumenta una variable aumenta la otra que sería una covarianza negativa Por ejemplo, yo aumento el precio y según aumento el precio la demanda que ocurre, que tiende a bajar. Es decir, cuando yo aumento una, la otra baja. Por eso tengo esta tendencia hacia abajo. Y cuando tenemos covarianza igual a cero es que no puedo detectar una tendencia. Ni va hacia arriba ni va hacia abajo. Es como un batiburrillo, como un popurrí de cosas. Y aquí estaríamos hablando realmente que son independientes, que no tienen ningún tipo de relación entre ellas. Visualmente se ve muy bien y gráficamente, o como lo puedo ver numéricamente, pues numéricamente esto se puede ver sobre todo con el coeficiente de correlación. mide como de fuerte es esa relación que tengamos, ¿vale? Lo que os comentaba, siempre está entre menos 1 y 1. Cuando tenemos el símbolo negativo en el coeficiente de correlación, ¿qué significa? Lo que habíamos visto, que cuando aumenta una variable, disminuye la otra. Es decir, este símbolo negativo nos indica la covarianza negativa, ¿vale? Por eso tenemos este símbolo negativo. Y por lo tanto, cuando aumenta una variable, disminuye la otra. Cuando tiene un símbolo positivo estamos ante el caso de la covarianza positiva que sería el primer ejemplo. Cuando aumenta una variable aumenta la otra y cuando estamos en cero ausencia de relación entre variables. Entonces nosotros calculamos el coeficiente de correlación, se suele representar con esta letra que es la letra ρ que no es más que la covarianza, que ya la calcularemos con r, la covarianza entre dos variables divididas entre la desviación típica de x y la desviación típica de y. A veces con letras griegas se pone desviación típica con la letra y, pero esto es simplemente nomenclatura. Entonces el coeficiente de correlación es la covarianza dividida entre las distintas desviaciones típicas y esto es lo que nos da este valor entre menos 1 y 1. Cuando el valor es 1 es la correlación positiva perfecta, fijaros que es prácticamente una línea recta. Vamos disminuyendo y cada vez empieza a ser menos asemejante, o sea, se asemeja menos a una línea recta, pero aún así yo sigo viendo que existe una especie de tendencia creciente. Esto es lo que teníamos con la correlación positiva, pero ya no la vamos a llamar fuerte, la vamos a llamar débil. ¿Cuándo pasa de ser fuerte a débil? Cuando está entre 1 y 0,50 es fuerte Y por debajo de 0,50 a 0 tendríamos que sería débil Cuando es justamente 0 tenemos que no hay ninguna correlación Si os dais cuenta es una nube de puntos sin ningún tipo de relación entre ellos Y entonces empezamos con los negativos El símbolo menos lo único que indica es que cuando aumenta uno disminuye la otra no indica absolutamente nada más, entonces volvemos entre 0 y 0,5 será negativa débil y entre 0,5 y menos 1 será negativa fuerte. Lo mismo cuando sea menos 1 pues se asemejará a una línea recta y si no es menos 1 pues será una nube de puntos pero tendrá una cierta tendencia. Si voy muy rápido cualquier cosa me podéis comentar y vamos poquito a poco. De las últimas cosas que vamos a ver y que vamos a aplicar sería un poco el análisis de regresión. Este ya es uno de los métodos que se consideran dentro del Machine Learning, del aprendizaje automático, aunque existía hace mucho tiempo. Esto no se inventó cuando hablamos de Machine Learning, de inteligencia artificial, no es algo que surja ahora. El análisis de regresión se lleva haciendo toda la vida, ¿de acuerdo? y lo que hacemos es intentar aproximar los puntos que vemos aquí, los puntos que vemos anteriormente, a ver si lo encuentro aquí, todos estos puntos lo que vamos a intentar hacer con la regresión es encontrar una línea recta que aproxime esa tendencia. Entonces para hacer eso existe una fórmula en matemáticas que se llama la regresión. Esto que veis aquí tan tan tan tan raro, esto no es más que decir, imaginemos que tengamos una línea recta. ¿Cómo representábamos la línea recta cuando éramos pequeños? Decíamos y es igual a mx más n, donde m y n eran dos números. O a lo mejor la habéis visto con ax más b. Pero esto es lo que decíamos cuando era una línea recta y nos enseñaban en el colegio que se hacía de esta forma o de esta otra forma. Y la A y la B son números que conocíamos. Por ejemplo, y igual a 2x más 1. Esto era una línea recta. ¿Qué hacía? Yo le daba valores a la x, obtenía valores en la y. Y esto lo podía representar. Representaba un punto. Yo representaba un punto. Representaba el siguiente. Cuando la x es 1, la y es 5. Representaba el siguiente, por ejemplo. Unía y tenía mi línea recta. pues es un poco parecido lo que pasa que aquí yo voy a tener los valores de las x es decir voy a tener estos valores de aquí voy a tener el resultado de la y voy a tener estos valores de aquí y lo que voy a querer calcular ahora no es la y sino que son estos números que tengo aquí puestos para que entendáis un poco cuál es el concepto de la regresión y de esa forma tener este tipo de de rectas que luego me permitan predecir esto lo vamos a hacer en R, efectivamente ¿vale? y esta ecuación bueno, se puede estimar por el método de mínimos cuadrados ordinarios, es una de las formas que se va a hacer pero existen muchísimas más ¿vale? ya veréis que en R es súper sencillo, o sea ahora estamos viendo la teoría, pero no os asustéis porque en R es literalmente poner dos frases ¿vale? ¿para entender? sí, claro es como el coeficiente de determinación en el tema del análisis de regresión sí el coeficiente de determinación es una forma de analizar cómo de buena es la recta que te ha salido es decir, cuando nosotros tenemos una recta, hacemos la recta hemos calculado toda la recta y todo cuando ya queremos analizar cómo de buena es aquí calculamos un valor que es el coeficiente de determinación y que también se utiliza porque tienes unos valores específicos entre 0 y 1, no debería ser más de 1, ¿vale? Por norma general. Entonces puedes llegar a entender, vale, pues mi recta aproxima bien los puntos o mi recta no aproxima bien, que esto lo veremos, ¿vale? Entonces, nada, un poco lo que os he comentado, los coeficientes, pues son los numeritos que son esta beta 1, beta 2, beta 3 y lo que vamos a comentar en la siguiente diapositiva es nomenclatura, ¿vale? Cuando hablamos de la Y, la Y que se llama, se llama la variable dependiente comúnmente. ¿Por qué? Porque depende de estas otras variables que son las variables independientes, ¿vale? Otra forma de llamarlas, aunque menos tradicional o menos usado, sería que la variable dependiente, es decir, la Y a la que calculamos sería la endógena y las variables independientes, las X, Las que conocemos serían las exógenas. Entonces una regresión no solo es encontrar la recta para predecir, sino también llegar a entender cómo afecta cada una de esas X, cada una de esas columnas a nuestro resultado. Os voy a poner un ejemplo muy rapidito y después de esto yo creo que podremos pasar un poco a R. Entonces en este tema tenemos las ventas de automóviles en Mercedes-Benz. ¿Qué vemos? Vemos los distintos países, vemos el Producto Interior Bruto y vemos las ventas de autos. Pregunta, ¿creéis que existe alguna relación, así solo viendo el gráfico, ¿cómo creéis que es la correlación entre las ventas y el Producto Interior Bruto? Pregunto. ¿Creéis que es fuerte, que es débil? Casi cero, bien. Dime, Freddy, no te escucha muy bien. Positiva pero débil Perfecto, positiva débil Efectivamente, ¿vale? Yo también estaría más en positiva débil Porque fijaos, parece que crece, crece, crece Podría asemejar un poquito esta recta Sí que es cierto que este punto Podría considerarlo quizá como un outlier ¿Vale? Entonces estaría entre casi cero y positiva débil Por lo tanto probablemente Si a mí me lo preguntáis será un cero con Dos, cero con tres Probablemente, ¿vale? el pip per cápita sin embargo con más pip se compran ferraris probablemente y el pip per cápita sin embargo fijaros que no hay ninguna relación aquí me baja, aquí me sube, aquí tengo este que parece que se ha estancado entonces aquí sí que la veo bastante claro, que no tiene relación aunque no tenga relación nosotros sí que podemos hacer una línea recta porque al final siempre vas a poder establecer una línea recta, pero es lo que comentábamos, como de buena es la línea recta, es lo que tenemos también que comprobar con coeficiente de correlación, errores absolutos medios o errores absolutos cuadráticos. Esta sin embargo, por ejemplo, yo la recta la hubiese tirado más así, quizá, y aquí podéis hacerla así. Al final hay miles de rectas, pero hay una que es la mejor aproximación, Y cuando hacemos la recta de regresión, nuestra idea es obtener la mejor aproximación entre ellas, ¿vale? Cuando hemos obtenido estas, lo que obtendremos serán los coeficientes, que os lo explicaré muchísimo mejor, ¿vale? Y antes de pasar a los contrastes de hipótesis, que yo creo que sobre todo vamos a verlo después, sí que me gustaría que probásemos todo el tema de la regresión y todo lo que hemos comentado en R, y luego volvemos a esta diapositiva, ¿vale? Entonces, tema R. ¿Dónde nos habíamos quedado el otro día? Voy a poner esta de aquí, si no recuerdo mal. Esa es de otra asignatura. Entonces, ¿qué tenemos? Primero habíamos leído nuestros datos, recordamos que utilizábamos la librería R. Efectivamente, sustituimos los valores nulos. Lo voy a repetir simplemente porque se me ha ido todo para tenerlo. y habíamos llegado a sustituir los valores nulos, habíamos llegado a sustituir los valores nulos, ¿por qué? Por la media de esta variable, ¿vale? De esta forma cuando nosotros hacemos el summary de data, veremos que ya lo teníamos solucionado, ¿vale? fijaros aquí ya sé que nos salen todos los valores en este caso de fecha de área de average price en household pero tenemos no tenemos valores de neas porque ya tenemos todos los valientes vale sí que es cierto que me gustaría enseñaros también a hacer filtros vale qué es lo que vamos a hacer ahora y luego ya terminaríamos con las regresiones que ya veréis que es bastante interesante y las covarianzas. Entonces, vamos a hacer lo siguiente. Vamos ahora a mirar, porque hemos visto la parte, la primera opción, que era el tema de reemplazar por la media, pero nos faltaba la tercera opción, que era eliminar las celdas vacías. Es decir, podemos o bien reemplazar por un valor o bien eliminar las celdas completamente vacías. Para ello, yo lo que voy a hacer es voy a volver a leer los datos entonces voy a volver a leer los datos aquí volveré a tener celdas vacías y cómo puedo filtrar para que no me salgan esas celdas vacías cómo puedo hacer para eliminar esas celdas vacías pues lo que vamos a hacer es lo siguiente vamos a hacer data por ejemplo data sin nulos Por ejemplo, y aquí que vamos a guardar, vamos a seleccionar nuestro dataset, en este caso es data, nuestro conjunto de datas y para decirle que no queremos eliminar los valores nulos vamos a hacer un filtro. ponemos los dos corchetes y vamos a seleccionar el, la exclamación, la exclamación en R significa que eliminamos, entonces vamos a hacer is.na que la habíamos utilizado aquí y vamos a decir lo mismo, data sort, aquí le estamos diciendo que filas queremos eliminar pero hay que especificarle filas y columnas, Cuando nos queremos decir a, elimíname estas filas y todas sus columnas, cuando queremos decir todas sus columnas, lo que hacemos es poner la coma y no ponemos nada al lado, ¿vale? Entonces, si hacemos esto y ahora miramos el dataSignNulos, ¿vale? Pues, en este caso, para la columna HouseSold, que es la que estábamos considerando, se me habrán eliminado los datos, ¿vale? Dame 5 segundos, creo que había otras columnas que habíamos antes tratado, vale, entonces a ver, si ahora hago un data sin nulos y data, ¿vale? fijaros number of crimes sigue teniendo los datos los datos nulos ¿vale? porque aquí no hemos hecho nada no hemos eliminado estos casos pero en households ya no hay datos nulos ¿vale? ya no tenemos ningún dato nulo, aquí en number of crimes sí pero aquí no ¿vale? entonces esta es otra forma, cuando os aconsejo que utilizáis esta cuando no hay muchos valores nulos que eliminar, es decir si yo por ejemplo tengo dos valores nulos en un conjunto de mil datos elimino los valores nulos, no me va a afectar esta coma es porque aquí estás especificando qué filas tienes que eliminar y aquí estás especificando que quieres eliminarlo de todas las columnas porque si no te quedaría una columna con más datos que otra y tendrías un error, entonces cuando queremos especificar que son todas las columnas y no decir exactamente qué columna queremos, pones una coma y luego pones vacío. ¿Sí? ¿Se entiende, Sebastián? Nada. Perfecto. Vale, vamos a ver una cosita muy sencillita también, que es el tema del filtro. Entonces, por ejemplo, fijaros aquí tenemos una opción que es área. imaginemos que yo solo quiera el dataset donde área o sea todas las filas en las que área es brent por ejemplo entonces voy a definir una nueva variable ya sabéis que esto siempre os lo voy a os lo voy a poner después una nueva variable que es brent la puedo llamar como quiera y será mi data le voy a hacer el fill na porque me gusta más que sea con esto pero bueno me gusta a mi personalmente siempre que podáis reemplazar yo creo que es mejor que eliminar entonces voy a hacer esto para que no haya nulos y ahora que será será mi data y aquí que vamos a seleccionar vamos a hacer filtro pero tenemos que decir por qué. Entonces filtro mis corchetes y ahora vamos a decir lo siguiente, que la columna data, que es de data la columna área sea igual a nuestro valor. Comparaciones, normalmente se ponen tanto en R como en Python dos iguales, porque un igual cambia un valor, dos iguales comparo. Lo que quiero comparar es un texto, por tanto lo ponemos entre comillas. Me dice no podemos seleccionar porque tenemos aquí el data y tenemos que especificar todas las columnas. Primero seleccionamos las filas y luego hacemos todas las columnas. Ahora sí que funciona con la coma y el nada. y aquí tenemos todos los datos que son para Brent, ¿vale? No nos aparecen ningún área más. ¿Existe otra forma? Existe otra forma, ¿vale? No simplemente existe esto, nosotros podemos hacer el library, una librería que se llama depli, ¿vale? Que si no la tenéis, tenéis que hacer el install.packages depli, ¿vale? En caso de que no lo tengáis y si lo tenéis, pues simplemente lo ejecutáis y existe otra forma que es hacer brand será igual a data hacemos porcentaje mayor porcentaje por utilizar este símbolo de porcentaje mayor porcentaje es por lo que necesitáis el de play y utilizamos la función filter by y aquí tenemos que poner que el área sea lo correspondiente entonces en nuestro caso sería la columna área igual a Brent ¿cuál es mejor? lo que, perdón, igual a Brent ¿cuál es mejor? realmente lo que queráis ¿vale? no hay una opción que sea mejor y una opción que sea peor para utilizar esto, eso sí, tendréis que utilizar una librería que se llama Deplir, ¿de acuerdo? pero ambos hacen lo mismo, si ahora pongo Brent fijaros que es exactamente lo mismo, ¿vale? el dataset con todas las columnas son dos formas distintas de hacer lo mismo, bien lo hacéis de esta forma bien lo hacéis desde esta otra, la que os sea más cómodo ¿se entiende hasta aquí? si, no puede perfecto entonces de la misma forma, si nosotros solo quisiésemos obtener la fila por ejemplo, o la columna por ejemplo 3, vale, pues aquí pondríamos un 3 y esto cuando yo lo ejecuto me dará simplemente fijaros los valores de la columna AveragePrize, que era la columna 3 vale, esto lo miraremos más en profundidad según nos vaya saliendo casos, vale, aquí pensad que también podéis hacer medias, varianzas como habíamos dicho antes, ¿cómo se hace la media? pues con la palabra min min de data, por ejemplo hacemos el dólar y hacemos por ejemplo el Average Price esto que me va a dar el valor medio fijaros, ya tenemos el valor medio otra opción, la varianza pues la varianza, VAR DATA, DÓLAR AVERAGE PRICE si hacemos esto tendremos aquí la varianza fijaros aquí la diferencia de valores lo que estábamos comentando, si hacemos STD espera un momento, que siempre se me va si es con STD o si es con SD por el tema de que en Python es uno y en Error es otro. Vale, creo que es el SD, pero bueno, SD, perdonad, SD de lo mismo, ¿vale? O STD, tengo mis dudas aquí un momento, ¿eh? Vale, exactamente, SD tenemos la desviación típica. ¿Cómo podemos hacer la media recortada? haríamos la media de nuestra columna y aquí le pondríamos la opción trim 0.1 y esto lo que está haciendo es quitar el 10% de los datos por arriba y por abajo, ¿vale? Y de esta forma, perdonad, con este min y simplemente le hacemos el trim igual a 0.1, ¿vale? Tenemos que en este caso la media recortada sería este valor, ¿vale? Para que os deis cuenta de cómo podemos hacer todo el tema de las medias recortadas. ¿Qué queremos el coeficiente de variación? Se puede hacer, ¿cómo? Pues en este caso haríamos el coeficiente de variación, que es la desviación típica, dividida entre la media, y multiplicado, ¿por qué? Por 100, para tenerlo en porcentaje. Bueno, pues nosotros elaboramos esto, y miramos lo que vale nuestro coeficiente de variación. En este caso, un 71,19. Sería una opción muy dispersa. ¿Hasta aquí se entiende? Para empezar con tu varianzas y correlaciones. Perfecto. Ahora, vamos a ver la relación que existe entre dos variables. Por ejemplo, quiero ver la relación que existe en mi dataset Brent entre las casas que se han comprado y el precio. Pues haría covarianza, cop, cop de covarianza, y diría mi dataset brand. Solo quiero el household, ¿vale? El número de casas vendidas y mi dataset brand y lo que voy a querer aquí que es el average price. Bueno, pues nosotros hacemos esto, esta matriz cop, y ¿qué tendríamos? Que es un valor negativo, por lo tanto yo que sé, sé que es una relación negativa, es decir, cuando aumenta el precio nosotros compramos menos casas. Así, se queda como vector porque realmente es una matriz de covarianzas, realmente, sí, se queda como un vector. ¿Qué podemos hacer más? Podemos hacer lo siguiente, podemos hacer, claro, lo que no sabemos es cómo de fuerte es esa relación, Lo que sé es que hay una relación negativa, pero no sé cómo de fuerte sería esa relación. Para ello vamos a calcular el coeficiente de correlación. Cuidado aquí, de cof cambiamos a cor, cor de correlación. ¿Cómo lo ejecutamos? Exactamente igual que la covarianza, ¿vale? Pondríamos paréntesis y en este caso el coeficiente de correlación es de menos 0,09. Pregunta, ¿fuerte o débil? débil débil, perfecto, ¿por qué? porque está cerca de cero, ¿vale? perfecto, ¿vale? vamos a hacer dos casos más y entonces ya os hacemos una regresión muy débil efectivamente, hacemos una regresión que ya veis que sencillito, al final es un poco en el ejercicio que os pase, veréis que os pongo muchísimas más casuísticas para que en casa podáis practicar con esto, ¿vale? os pondré muchos más códigos para que veáis y analicéis si es una cosa, si es otra cosa, ¿vale? Imaginemos que ahora a mí no me interesa Brent, sino que me interesa el área, por ejemplo, un área que no tenga a poder ser Barking and Dugganham, por ejemplo. Entonces, ¿qué vamos a hacer? Vamos a hacer el dataset, por ejemplo, Barking. ¿Qué tenemos que hacer? El filtrado. ¿Cómo lo hacemos? Realmente como más cómodos os sintáis. Yo lo voy a hacer en este caso así, en este caso sería área de nuevo, igual, igual y entre las comillas ponemos el texto que hemos copiado, en este caso Barking and Dagenham. Si hacemos esta forma no se nos olvide la coma y nada después. Así tenemos Barking, fijaros que aquí tenemos el dataset de Barking y es un poco hacer lo mismo, en este caso en vez de creerlo con respecto al dataset print, Que lo que voy a hacer es copiar y pegar Barking. Cuidado cuando hacemos el copia y pega de ponerlo en los dos sitios, ¿vale? Si vamos a la covarianza, vemos que es positiva. Es decir, en el caso de Barking, cuando aumenta el precio, aumentan las casas que se compran. Lo cual es un poco ilógico, pero en el caso de Barking es lo que nos están diciendo los datos, ¿vale? Cuando vamos a la correlación, sigue siendo débil, pero un poquito más fuerte que el anterior, ¿vale? Que sería 0,11. ¿Sí? ¿Se entiende un poco lo que estamos haciendo? hasta aquí al menos lo que hemos hecho es hacer un filtro en este caso por Parking Antenna vamos a hacer una regresión para que veáis un poco como se utilizaría vamos a hacer una regresión en este caso lineal para hacer una regresión lineal escribimos LM y entre paréntesis vamos a especificar cuál es nuestra variable dependiente y cuál es nuestra variable independiente. Imaginemos que yo quiero una relación entre las casas que se han comprado en Brent y el precio que tiene en Brent. Creamos un nuevo dataset porque a mí me interesa guardarlo para luego poder aplicarlo aquí. ¿Por qué me interesa guardarlo? Porque fíjate, si yo lo hiciese para todos los áreas a la vez, ¿qué ocurre? Que si te das cuenta hay unas que están relacionadas positivamente y unas que están relacionadas negativamente. Por lo tanto, a la hora de hacer la regresión no me va a dar bien. esto es por lo que te comento en el caso por ejemplo de Brent cuando aumentaba el precio disminuía la compra y sin embargo en el caso de Barking & Dagenham cuando aumenta el precio aumenta la compra entonces en este sentido lo que nos interesa que es para cada uno de estos barrios vamos a hacer una vamos a hacer una recta y podremos evaluar como de bien o de mal funciona no siempre se crea no creo el dataset cuando hago el filtro o sea aquí es cierto que sí que creo el dataset pero lo guardo cuando hago la asignación con este igual ¿vale? no, para el cálculo de CoffeeCore no hay que llamar no hay que llamar a deplear ¿con cuál estás haciendo el NA? fíjate que yo antes, ¿vale? para que no me saliese ese NA, antes he vuelto a ejecutar en mi caso la de reemplazar los valores nulos por la media ¿vale Jonathan? sí de pli lo necesitarás cuando utilicemos esto y esto os voy a enseñar que es cuando hacemos agrupaciones o sea queremos la media por ejemplo por grupos y no la media de todo el dataset sino que queremos la media por ejemplo por grupos vale por ejemplo esto no estaba contemplado que os lo diese hoy ¿vale? pero si hago imaginemos que yo quiero la media por cada tipo de área ¿qué haríamos? seleccionaríamos nuestro data el símbolo del deplear por eso necesitamos el deplear haríamos el group by aquí especificaríamos nuestra columna en este caso sería la columna area y además aquí queremos aplicarle la media entonces hay una opción que es summarize que también es con el deplear y aquí tenemos que poner si no recuerdo mal el nombre que quiero que le dé y el valor que sería min de la columna average price vale ahora ya queda así perfecto entonces fijaros aquí en vez de hacer la media de todo el dataset me da el valor de la media para cada uno de los barrios Entonces cuando utilizas este simbolito, este porcentaje mayor porcentaje Es cuando vas a utilizar la librería de PLEED ¿Sí? ¿Queda claro? Sí, esto ya os lo explicaré más adelante, no se suponía que os lo tenía que explicar hoy Pero bueno, es una cosa que está bastante bien, sería como hacer tablas dinámicas en Excel Vale, yo os lo dejo aquí, aunque no era lo que se suponía que se iba a explicar Vale, pero para que veáis cuando utilizar el de PLEED Cuando necesitéis ese simbolito, utilizáis el de PLEAR. Vale, volvemos a la regresión lineal. Entonces, ¿qué es lo que yo quiero estimar? Yo lo que quiero estimar es el número de casos que se venden. Entonces, de mi dataset, por ejemplo, Brent, voy a especificar mi variable SOLT, ¿vale? Esta es la variable dependiente, esta es la Y que estábamos considerando, ¿vale? Y ojo aquí, cuidado. Para mí es el ALT-GR y el 4, ¿vale? Necesito este simbolito. Es como la tilde que va encima de la ñ. O sea, la rayita que va encima de la ñ. Para mí es el Alt-G-R, la tecla que pone Alt-G-R, y el número 4 que tenemos arriba del teclado. De todas formas, como suele ser complicado, os lo paso por aquí. Podéis copiarlo hasta que encontréis la combinación. Ya os digo que para mí es el Alt-G-R y el 4. ¿Y aquí qué vamos a poner? la combinación o todas las variables que intervienen, en este caso será de mi dataset brand, las dependientes, ¿vale? Haríamos el average price. Cuando nosotros generamos esto, esto me da un resultado, ¿vale? Que es este resultado de aquí. ¿Qué me está diciendo? Fijaros, me está diciendo el término, el intercept, es el numerito raro, ¿vale? que teníamos. Cuando pone este por e elevado a la 0,2 ¿habéis visto alguna notación científica? Pregunto. En algún momento de vuestra vida. Vale. Informáticamente e 0,2 es lo mismo que 10 elevado a 2. Entonces tenéis que estar pensando que aquí es 3,576 por 10 elevado a 2 que es 100. Entonces, ¿qué estamos diciendo aquí? que realmente la recta que sería el precio del household es igual a 3,57 por 100 es 357,6 menos y fijaros aquí es por elevado a menos 0,4 es decir, esta esto lo veremos mejor también y lo repasaremos el próximo día pero este puntito hacemos una posición hacia aquí 2, 3, 4 y rellenamos con 0, es decir, estaríamos diciendo que es menos 0.00002241, ¿por qué? Por el precio medio. bien, entonces estos valores que nos están dando aquí es el que está siempre en el intercept el que está siempre en el intercept estaríamos hablando que es el número como tal, el número suelto, el que no multiplica nada y luego los que están debajo de las columnas corresponderían al coeficiente que tiene esa columna ¿se entiende? ¿Queréis hacer otro ejemplo? Por mí no hay problema, pero me sabe mal porque ya estamos pasando de la hora y no sé si alguno tiene algo que hacer, pero si no os hago otro ejemplo. Sí, sí, la regresión lineal es con este lm. Este lm implica linear model, que es la regresión lineal en este caso. Entonces, lo que hacemos es, esta es la variable que yo quiero predecir, ¿En función de qué? En función de esta otra variable que estoy estudiando aquí. Entonces lo que hace es, los coeficientes de esta función son el valor sin nada, que es este 357 que viene de este intercepto, y luego tenemos aquí el brand. ¿Hacemos otro ejemplo? Perfecto. Vale, pongamos entonces, ¿cómo creéis que será? Vale, yo os lo voy a preguntar a vosotros. ¿Cómo creéis que será si nosotros, en vez de querer hacer esta regresión lineal, en vez de hacer la regresión lineal de Brent, hacéis la regresión lineal de Barking? ¿Cómo creéis que será? Pregunto. A ver si me lo sabéis escribir. Lo mismo, ¿eh? De las casas, de la venta de las casas y del precio medio. a ver quién se atreve se pone barking es la misma función efectivamente entonces se pone barking sería exactamente lo mismo voy a comentaros esto efectivamente Efectivamente sería con Barking y vamos a ver cuál es el resultado que nos da. Entonces en este caso... Vale, tenemos esto. Tenemos estos resultados. Faltó cambiar Brent. Ay, perdón, gracias. Gracias, gracias, gracias. Aquí. ¿Alguien me sabría decir entonces qué recta me está dando en este caso? a ver si se os ocurre que recta me está dando en este caso os ayudo tendríamos primero el término independiente que es el intercepto por ese e elevado a 0,2 que es por 10 elevado al cuadrado. 10 elevado al cuadrado es 100, por lo tanto hay que multiplicar ese 1,51 por 100. 151,4 más, porque este es el término independiente, más, ya tenemos este valor que es con e elevado a menos 0,4. Entonces hay que mover esta coma ¿cuántas veces? Después será 1, estaría aquí, 2, 3, 4. La coma tiene que estar aquí, relleno 0, 0, 0 y 0. Por lo tanto, mi valor será más, porque es positivo, 0,0004512 por el precio. en barco ¿qué quiere decir esto? que cuando yo aumento en una unidad si aumento en una unidad el average price es decir, si yo subo un euro al precio medio ¿cuántas casas venderé? pues ¿qué tendría que hacer? haría lo siguiente pues venderé las siguientes casas será copiar esto y cuando yo aumento en 1 sería ver cuánto es esto pues si nosotros ejecutamos esto perdón, es que tengo aquí una coma y es un punto por el tema de ser decimal fijaros, el hecho de que aumente un euro, ¿vale? nuestro precio aumenta en este caso las casas 151,4005 ¿Se entiende? Más o menos puede Solamente se toma en cuenta el coeficiente B 151 no participa en esta análisis solamente se participa en el análisis 0,0045 participa eso es lo que aumentaría no, aumentaría sí, pero sí, sí, sí no, no, sí, sí, sí, está bien el tema es que si aumentas si yo tengo un precio si mi precio si mi precio medio es uno ¿cuántas serán las casas que yo compro? ¿cuántas serán las casas? o el household, ¿cuál será el valor del household? Pues será el valor de hacer el resultado de estos 151,4 que es lo que siempre hay más el porcentaje por el average price, pero este 151 sí que interviene cuando queremos saber el precio, ¿de acuerdo? Cuando nosotros fijamos un precio, ¿vale? bueno en este caso vale es el caso que os hemos puesto en este caso tendríamos que mirar el tema de datas y miramos un poco el household vale en este caso no es una muy buena media pero si te das cuenta si que hay valores de casas de 169 141 vale entonces en este caso si que aumenta pero porque aumenta porque bueno yo no te lo he comentado vale por el tema de la correlación y por este tema Así que es algo que nos cuesta un poco a veces verlo y decir, si aumenta el precio, aumenta las casas vendidas. Es raro, pero imagínate que estemos hablando de una urbanización de lujo, ¿vale? De mucho, mucho, mucho, mucho lujo. Ahí normalmente las casas que más precio tienen son las que se venden, ¿vale? Porque suelen ser las más lujosas. Entonces ya depende del barrio. Muy probablemente, sabiendo esto, y no lo sé, pero muy probablemente si habremos de Brent sea un barrio más típico, que cuando aumentan el precio de las casas hay menos demanda, pero en este caso parece que Barking se comporta al revés, que cuanto más aumentan el precio de las casas, pues más gente compra ahí. ¿Raro? Lo sé. ¿Contra natura? Lo sé, pero es lo que nos dicen los datos. De aquí la importancia de analizar los datos en el sentido de que a veces nos demuestran cosas o nos muestran cosas que se escapan a nuestra razón. y si efectivamente Jonathan te lo ha comentado el valor de correlación lo tenías de aquí abajo y ahí es donde te salía que tenías un valor positivo ¿sí? ¿se entiende un poco? el próximo día aunque os lo dejaré ahora en este código el próximo día veremos porque si os estamos dando cuenta le estamos diciendo bueno aumenta en un euro aumenta en una casa o cosas así pero que ocurre si yo quiero decir, oye, si el precio sube un 10%, ¿cómo me afecta? Entonces, en este caso no utilizaremos simplemente esta regresión lineal. Sí, sí se puede graficar, se puede graficar y lo graficaremos. Cuando vayamos a la parte ya de gráficos, pues graficaremos todo el tema de puntos y ya haremos predicciones y ya haremos este tipo de cosas. Por esta parte, tranquilidad, que yo creo que tenéis un tema bastante complejo. pero cuando nosotros no queremos saber como tal si sube una casa, si sube un euro el precio, etc lo que normalmente, y queremos saber de porcentajes, pues aumentas un 10% ¿cómo aumenta el porcentaje de casas vendidas? aquí solemos tirar de aplicar la regresión lineal, pero transformando las variables a logaritmos ¿vale? esto de momento yo os voy a poner en el archivo que os suba para que lo veáis y podéis ejecutarlo y podéis hacer vuestras prácticas, o sea, tenéis muchos barrios y tenéis muchas columnas, pero vas a hacer, por ejemplo, el número de crímenes con respecto al área o el número de crímenes con respecto a las casas vendidas y al precio o el número de casas vendidas con respecto, por ejemplo, al número de crímenes. Jugad con todo esto, ¿vale? Pero para hacer ese tema de porcentajes se suelen aplicar logaritmos. Yo en el ejercicio que os ponga os pondré las dos cosas, tanto cómo hacer regresiones lineales con más de una variable, como cómo hacer regresiones lineales con esto de aplicando logaritmos, ¿vale? Y os explicaré el por qué. Lo veremos más en detalle el próximo día, pero jugad con el código que yo os dé, ¿vale? así como deberes para ir un poco practicando, porque aquí parece que no pero hemos visto bastantes cosas, hemos visto filtros, hemos visto bastantes bastantes cosas, ¿vale? todo el tema de regresión lineal, el tema de estadísticos concretos el tema de covarianzas el tema de correlaciones, ¿vale? entonces fugaz con ello intentar mirar cómo se relaciona ¿vale? ¿sí? ¿todo bien? ¿más o menos? entonces sí, sí, sí, sí, sí, os voy a dejar el código y el dataset en principio lo tenéis, si yo voy aquí, confirmadme vais aquí a este apartado que pone documentación y en documentación tenéis número de archivos, sí, sí, os lo voy a pasar Luis, no sé si llamarte Luis o María comentadme, bueno, todos los que tengáis dos nombres y me decís con cuáles queréis que os llame, ¿vale? mucho mejor porque hay veces que os gusta el primer nombre y no el segundo y otras que no el primero y el segundo yo lo hago con toda mi buena intención pero si a alguien le molesta alguno me lo comentáis aquí en documentación lo tengo estructurado como códigos en R, los datos y las presentaciones, os voy colgando todo aquí vale, gracias lo voy colgando todo aquí entonces hoy os subiré el correspondiente a la clase 3, que ya os digo que os pondré esas cositas de más también para que podáis profundizar y jugar y el dataset que estamos utilizando en todo caso es este de aquí ¿vale? perfecto, entonces por hoy esto es todo, ahora subiré el nuevo archivo con estas casuísticas y poniendo todo el tema de comentarios para que lo podáis ver bien y nos vemos el próximo día, espero que la clase os haya gustado y que os parezca práctica lo suficientemente práctica ¿vale? y que estéis más o menos motivados con la asignatura, nos vemos el próximo día ¿de acuerdo? muchas gracias adiós Gracias.
