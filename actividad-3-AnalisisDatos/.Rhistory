#| include: false
# cargamos datos
datos <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "Var Discreta Adq Bicicleta")
getwd()
setwd("/Users/alejandrocamposlamas/Proyectos/ACTIVIDADES_UNIR/actividad-3-AnalisisDatos")
library(readxl)
library(dplyr)
library(caret) # para matriz de confusión
library(rpart) #Para realizar el árbol
library(rpart.plot) #Para dibujar el árbol
library(factoextra) # para clusteres
library(NbClust)
library(zoo) # para ts diario
library(forecast)
library(dplyr)
library(lubridate)
getwd()
set.seed(123)
datos <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "Var Discreta Adq Bicicleta")
# str(datos)
# unique(datos$Country)
#| include: false
# cargamos datos
datos <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "Var Discreta Adq Bicicleta")
# vemos la estructura y convertimos los datos a su formato adecuado
# str(datos)
#colSums(is.na(datos)) # verificamos que no existe ningun null
# datos[is.na(datos)] <- 0 # valores nulos se reemplazarían por 0
# Quitamos la columna PersonType dado que todos su valores son IN
datos <- datos%>% select(!PersonType)
#quitamos aquellas paises que son agrupaciones
datos <- datos %>%
filter(!(Country %in% c("Northwest", "Southeast", "Central", "Southwest", "Northeast")))
# a factores datos que son categorías
datos$Education <- as.factor(datos$Education)
datos$PersonID <- as.factor(datos$PersonID)
datos$CustomerID <- as.factor(datos$CustomerID)
# Los booleanos le creamos una columna condicional
#BikePurchase
#HomeOwnerFlag
datos <- datos %>%
mutate(
BikePurchase_f = factor(BikePurchase, labels=c("FALSE", "TRUE")),
HomeOwnerFlag_f = factor(HomeOwnerFlag, labels=c("FALSE", "TRUE"))
)
print(datos)
# describimos los estadísticos numéricos
datos %>% select(where(is.numeric)) %>% summary(use="complete.obs")
# observamos cómo se relacionan las variables
datos %>% select(where(is.numeric)) %>% cor(use="complete.obs")
# Ver qué variables usó realmente el árbol y cuánto importaron
modelo_arbol$variable.importance
getwd()
setwd("/Users/alejandrocamposlamas/Proyectos/ACTIVIDADES_UNIR/actividad-3-AnalisisDatos")
library(readxl)
library(dplyr)
library(caret) # para matriz de confusión
library(rpart) #Para realizar el árbol
library(rpart.plot) #Para dibujar el árbol
library(factoextra) # para clusteres
library(NbClust)
library(zoo) # para ts diario
library(forecast)
library(dplyr)
library(lubridate)
getwd()
set.seed(123)
datos <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "Var Discreta Adq Bicicleta")
# str(datos)
# unique(datos$Country)
#| include: false
# cargamos datos
datos <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "Var Discreta Adq Bicicleta")
# vemos la estructura y convertimos los datos a su formato adecuado
# str(datos)
#colSums(is.na(datos)) # verificamos que no existe ningun null
# datos[is.na(datos)] <- 0 # valores nulos se reemplazarían por 0
# Quitamos la columna PersonType dado que todos su valores son IN
datos <- datos%>% select(!PersonType)
#quitamos aquellas paises que son agrupaciones
datos <- datos %>%
filter(!(Country %in% c("Northwest", "Southeast", "Central", "Southwest", "Northeast")))
# a factores datos que son categorías
datos$Education <- as.factor(datos$Education)
datos$PersonID <- as.factor(datos$PersonID)
datos$CustomerID <- as.factor(datos$CustomerID)
# Los booleanos le creamos una columna condicional
#BikePurchase
#HomeOwnerFlag
datos <- datos %>%
mutate(
BikePurchase_f = factor(BikePurchase, labels=c("FALSE", "TRUE")),
HomeOwnerFlag_f = factor(HomeOwnerFlag, labels=c("FALSE", "TRUE"))
)
print(datos)
# describimos los estadísticos numéricos
datos %>% select(where(is.numeric)) %>% summary(use="complete.obs")
# observamos cómo se relacionan las variables
datos %>% select(where(is.numeric)) %>% cor(use="complete.obs")
#split: seleccionamos el monto de entrenamiento y lo guardamos en la variabble de train
indice <- sample(1:nrow(datos), size = 0.8 * nrow(datos))
# Train: entrenamos al modelo con el subset de testeo
train <- datos[indice, ]
# test: tomamos el monto a testar
test <- datos[-indice, ]
modelo_logit <- glm(BikePurchase ~ Country + MaritalStatus + HomeOwnerFlag_f + Education + YearlyIncome + Occupation, data = train, family = "binomial")
summary(modelo_logit)
# 1. Ajuste del modelo
modelo_arbol <- rpart(BikePurchase ~ Country + MaritalStatus + HomeOwnerFlag_f +  Education + YearlyIncome + Occupation,
data = train,
method = "class")
# 2. Visualización
rpart.plot(modelo_arbol,main = "Árbol de Decisión: Predicción de Bike Purchase",
type = 2,
extra = 104,
nn = TRUE)
pred_logit_prob <- predict(modelo_logit, newdata = test, type = "response")
# 1# 1. Convertimos tus probabilidades a clases (0 o 1) con el corte de 0.5
pred_clase <- ifelse(pred_logit_prob > 0.5, 1, 0)
# 2. Convertimos AMBOS a factor asegurando que tengan los mismos niveles
pred_factor <- factor(pred_clase, levels = c("0", "1"))
real_factor <- factor(test$BikePurchase, levels = c("0", "1"))
# 3. Magia: Generamos la matriz completa
confusionMatrix(data = pred_factor, reference = real_factor)
# 1. Pide la clase directamente (type = "class")
pred_clase_arbol <- predict(modelo_arbol, newdata = test, type = "class")
# 2. Aseguramos que sea factor y tenga los mismos niveles que la realidad
# Nota: predict con type="class" ya suele devolver factor, pero esto es doble seguridad
pred_factor_arbol <- factor(pred_clase_arbol, levels = c("0", "1"))
real_factor_arbol <- factor(test$BikePurchase, levels = c("0", "1"))
# 3. Matriz
confusionMatrix(data = pred_factor_arbol, reference = real_factor_arbol)
# Ver qué variables usó realmente el árbol y cuánto importaron
modelo_arbol$variable.importance
resumen_clusters <- datos_cluster_input %>%
mutate(Cluster = clusterizacion$cluster) %>%
group_by(Cluster) %>%
summarise(across(everything(), mean))
datos_cluster_input <- datos %>%
select(where(is.numeric)) %>%
select(-BikePurchase)
datos_escalados <- scale(datos_cluster_input)
clusterizacion <- kmeans(datos_escalados, centers = 4, nstart = 25)
resumen_clusters <- datos_cluster_input %>%
mutate(Cluster = clusterizacion$cluster) %>%
group_by(Cluster) %>%
summarise(across(everything(), mean))
print(resumen_clusters)
ventas <- read_excel("datos/DataSet SQL_Act3_ADMN.xlsx",
sheet = "ST Ventas Totales ")
#colnames(ventas)
class(ventas$OrderDate) # Nos aseguramos que la columna de fecha está bien factorizada en fecha
min(ventas$OrderDate)
#unique(ventas$OrderDate)
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
# 2. Crear la serie temporal
# ¡OJO! Aquí usamos TotalSales, que es el nombre que definiste arriba
series_ventas <- ts(ventas_mensuales$TotalSales, start = c(2011, 5), frequency = 12)
# 3. Graficar la serie
plot(series_ventas, main="Ventas Mensuales", col="blue", lwd=2)
ventas_mensuales <- ventas %>%
mutate(Mes = floor_date(OrderDate, "month")) %>%
group_by(Mes) %>%
summarise(TotalSales = sum(Sales...2, na.rm = TRUE))
# 2. Crear la serie temporal
series_ventas <- ts(ventas_mensuales$TotalSales, start = c(2011, 5), frequency = 12)
# 3. Graficar la serie
plot(series_ventas, main="Ventas Mensuales", col="blue", lwd=2)
# Realizar la predicción
modelo <- auto.arima(series_ventas)
prediccion <- forecast(modelo, h = 2) # h=2 son los 2 meses que te piden
# Ver los valores de la predicción
print(prediccion)
# Graficar la predicción
plot(prediccion, main="Predicción Ventas Próximos 2 Meses")
